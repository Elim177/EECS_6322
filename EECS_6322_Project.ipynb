{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kBRMHLScUqPh"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/EECS_6322/Final_Project')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_SgSplom-r1",
        "outputId": "b2105045-f66c-4aa7-ebe0-633e293e5131"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HjCp-VBgZ7Y",
        "outputId": "041bb8f2-2ccf-49a1-cefd-ebc1cc7f99f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m{'setup': 'simclr', 'backbone': 'resnet18', 'model_kwargs': {'head': 'mlp', 'features_dim': 128}, 'train_db_name': 'cifar-10', 'val_db_name': 'cifar-10', 'num_classes': 10, 'criterion': 'simclr', 'criterion_kwargs': {'temperature': 0.1}, 'epochs': 100, 'optimizer': 'sgd', 'optimizer_kwargs': {'nesterov': False, 'weight_decay': 0.0001, 'momentum': 0.9, 'lr': 0.4}, 'scheduler': 'cosine', 'scheduler_kwargs': {'lr_decay_rate': 0.1}, 'batch_size': 512, 'num_workers': 8, 'augmentation_strategy': 'simclr', 'augmentation_kwargs': {'random_resized_crop': {'size': 32, 'scale': [0.2, 1.0]}, 'color_jitter_random_apply': {'p': 0.8}, 'color_jitter': {'brightness': 0.4, 'contrast': 0.4, 'saturation': 0.4, 'hue': 0.1}, 'random_grayscale': {'p': 0.2}, 'normalize': {'mean': [0.4914, 0.4822, 0.4465], 'std': [0.2023, 0.1994, 0.201]}}, 'transformation_kwargs': {'crop_size': 32, 'normalize': {'mean': [0.4914, 0.4822, 0.4465], 'std': [0.2023, 0.1994, 0.201]}}, 'pretext_dir': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/pretext', 'pretext_checkpoint': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/pretext/checkpoint.pth.tar', 'pretext_model': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/pretext/model.pth.tar', 'topk_neighbors_train_path': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/pretext/topk-train-neighbors.npy', 'topk_neighbors_val_path': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/pretext/topk-val-neighbors.npy'}\u001b[0m\n",
            "\u001b[34mRetrieve model\u001b[0m\n",
            "Model is ContrastiveModel\n",
            "Model parameters: 11.50M\n",
            "ContrastiveModel(\n",
            "  (backbone): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  )\n",
            "  (contrastive_head): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "  )\n",
            ")\n",
            "\u001b[34mSet CuDNN benchmark\u001b[0m\n",
            "\u001b[34mRetrieve dataset\u001b[0m\n",
            "Train transforms: Compose(\n",
            "    RandomResizedCrop(size=(32, 32), scale=(0.2, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=warn)\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomApply(\n",
            "    p=0.8\n",
            "    ColorJitter(brightness=(0.6, 1.4), contrast=(0.6, 1.4), saturation=(0.6, 1.4), hue=(-0.1, 0.1))\n",
            ")\n",
            "    RandomGrayscale(p=0.2)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])\n",
            ")\n",
            "Validation transforms: Compose(\n",
            "    CenterCrop(size=(32, 32))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])\n",
            ")\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /path/to/cifar-10/cifar-10-python.tar.gz\n",
            "100% 170498071/170498071 [00:05<00:00, 29742460.93it/s]\n",
            "Extracting /path/to/cifar-10/cifar-10-python.tar.gz to /path/to/cifar-10/\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Dataset contains 50000/10000 train/val samples\n",
            "\u001b[34mBuild MemoryBank\u001b[0m\n",
            "Files already downloaded and verified\n",
            "\u001b[34mRetrieve criterion\u001b[0m\n",
            "Criterion is SimCLRLoss\n",
            "\u001b[34mRetrieve optimizer\u001b[0m\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    lr: 0.4\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0001\n",
            ")\n",
            "\u001b[34mNo checkpoint file at /content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/pretext/checkpoint.pth.tar\u001b[0m\n",
            "\u001b[34mStarting main loop\u001b[0m\n",
            "\u001b[33mEpoch 0/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.40000\n",
            "Train ...\n",
            "Epoch: [0][ 0/97]\tLoss 6.8589e+00 (6.8589e+00)\n",
            "Epoch: [0][25/97]\tLoss 6.9258e+00 (6.9512e+00)\n",
            "Epoch: [0][50/97]\tLoss 6.9132e+00 (6.9357e+00)\n",
            "Epoch: [0][75/97]\tLoss 6.8815e+00 (6.9238e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 21.26\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 1/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.39990\n",
            "Train ...\n",
            "Epoch: [1][ 0/97]\tLoss 6.8293e+00 (6.8293e+00)\n",
            "Epoch: [1][25/97]\tLoss 6.7121e+00 (6.7735e+00)\n",
            "Epoch: [1][50/97]\tLoss 6.5826e+00 (6.7131e+00)\n",
            "Epoch: [1][75/97]\tLoss 6.5823e+00 (6.6719e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 22.48\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 2/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.39961\n",
            "Train ...\n",
            "Epoch: [2][ 0/97]\tLoss 6.5195e+00 (6.5195e+00)\n",
            "Epoch: [2][25/97]\tLoss 6.5477e+00 (6.5156e+00)\n",
            "Epoch: [2][50/97]\tLoss 6.4300e+00 (6.5005e+00)\n",
            "Epoch: [2][75/97]\tLoss 6.4687e+00 (6.4850e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 22.46\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 3/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.39911\n",
            "Train ...\n",
            "Epoch: [3][ 0/97]\tLoss 6.4390e+00 (6.4390e+00)\n",
            "Epoch: [3][25/97]\tLoss 6.3865e+00 (6.4481e+00)\n",
            "Epoch: [3][50/97]\tLoss 6.3703e+00 (6.4180e+00)\n",
            "Epoch: [3][75/97]\tLoss 6.3510e+00 (6.4068e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 22.31\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 4/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.39842\n",
            "Train ...\n",
            "Epoch: [4][ 0/97]\tLoss 6.3355e+00 (6.3355e+00)\n",
            "Epoch: [4][25/97]\tLoss 6.3663e+00 (6.3390e+00)\n",
            "Epoch: [4][50/97]\tLoss 6.2292e+00 (6.3219e+00)\n",
            "Epoch: [4][75/97]\tLoss 6.2984e+00 (6.3099e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 25.51\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 5/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.39754\n",
            "Train ...\n",
            "Epoch: [5][ 0/97]\tLoss 6.2141e+00 (6.2141e+00)\n",
            "Epoch: [5][25/97]\tLoss 6.1881e+00 (6.2353e+00)\n",
            "Epoch: [5][50/97]\tLoss 6.1337e+00 (6.2265e+00)\n",
            "Epoch: [5][75/97]\tLoss 6.1766e+00 (6.2144e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 26.86\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 6/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.39646\n",
            "Train ...\n",
            "Epoch: [6][ 0/97]\tLoss 6.1800e+00 (6.1800e+00)\n",
            "Epoch: [6][25/97]\tLoss 6.3179e+00 (6.1582e+00)\n",
            "Epoch: [6][50/97]\tLoss 6.1649e+00 (6.1481e+00)\n",
            "Epoch: [6][75/97]\tLoss 6.0840e+00 (6.1408e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 26.92\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 7/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.39519\n",
            "Train ...\n",
            "Epoch: [7][ 0/97]\tLoss 6.0759e+00 (6.0759e+00)\n",
            "Epoch: [7][25/97]\tLoss 6.0864e+00 (6.1075e+00)\n",
            "Epoch: [7][50/97]\tLoss 6.0881e+00 (6.0975e+00)\n",
            "Epoch: [7][75/97]\tLoss 6.1575e+00 (6.0925e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 28.05\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 8/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.39372\n",
            "Train ...\n",
            "Epoch: [8][ 0/97]\tLoss 6.0360e+00 (6.0360e+00)\n",
            "Epoch: [8][25/97]\tLoss 6.0947e+00 (6.0662e+00)\n",
            "Epoch: [8][50/97]\tLoss 6.0778e+00 (6.0702e+00)\n",
            "Epoch: [8][75/97]\tLoss 6.0518e+00 (6.0665e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 29.36\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 9/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.39207\n",
            "Train ...\n",
            "Epoch: [9][ 0/97]\tLoss 6.0610e+00 (6.0610e+00)\n",
            "Epoch: [9][25/97]\tLoss 6.0064e+00 (6.0351e+00)\n",
            "Epoch: [9][50/97]\tLoss 6.0497e+00 (6.0442e+00)\n",
            "Epoch: [9][75/97]\tLoss 6.0151e+00 (6.0384e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 31.65\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 10/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.39022\n",
            "Train ...\n",
            "Epoch: [10][ 0/97]\tLoss 5.8693e+00 (5.8693e+00)\n",
            "Epoch: [10][25/97]\tLoss 5.6378e+00 (5.7832e+00)\n",
            "Epoch: [10][50/97]\tLoss 5.6988e+00 (5.7253e+00)\n",
            "Epoch: [10][75/97]\tLoss 5.5529e+00 (5.6786e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 33.27\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 11/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.38819\n",
            "Train ...\n",
            "Epoch: [11][ 0/97]\tLoss 5.5023e+00 (5.5023e+00)\n",
            "Epoch: [11][25/97]\tLoss 5.5322e+00 (5.5122e+00)\n",
            "Epoch: [11][50/97]\tLoss 5.5905e+00 (5.4972e+00)\n",
            "Epoch: [11][75/97]\tLoss 5.4917e+00 (5.4990e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 35.59\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 12/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.38597\n",
            "Train ...\n",
            "Epoch: [12][ 0/97]\tLoss 5.4187e+00 (5.4187e+00)\n",
            "Epoch: [12][25/97]\tLoss 5.3881e+00 (5.4496e+00)\n",
            "Epoch: [12][50/97]\tLoss 5.4301e+00 (5.4362e+00)\n",
            "Epoch: [12][75/97]\tLoss 5.4587e+00 (5.4402e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 37.06\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 13/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.38357\n",
            "Train ...\n",
            "Epoch: [13][ 0/97]\tLoss 5.5071e+00 (5.5071e+00)\n",
            "Epoch: [13][25/97]\tLoss 5.4354e+00 (5.3799e+00)\n",
            "Epoch: [13][50/97]\tLoss 5.2618e+00 (5.3480e+00)\n",
            "Epoch: [13][75/97]\tLoss 5.0140e+00 (5.2693e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 41.27\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 14/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.38098\n",
            "Train ...\n",
            "Epoch: [14][ 0/97]\tLoss 5.0315e+00 (5.0315e+00)\n",
            "Epoch: [14][25/97]\tLoss 4.9359e+00 (4.9212e+00)\n",
            "Epoch: [14][50/97]\tLoss 4.8945e+00 (4.9091e+00)\n",
            "Epoch: [14][75/97]\tLoss 4.8778e+00 (4.8955e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 39.57\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 15/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.37822\n",
            "Train ...\n",
            "Epoch: [15][ 0/97]\tLoss 4.7591e+00 (4.7591e+00)\n",
            "Epoch: [15][25/97]\tLoss 4.8077e+00 (4.8122e+00)\n",
            "Epoch: [15][50/97]\tLoss 4.7594e+00 (4.8090e+00)\n",
            "Epoch: [15][75/97]\tLoss 4.8192e+00 (4.8065e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 42.66\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 16/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.37529\n",
            "Train ...\n",
            "Epoch: [16][ 0/97]\tLoss 4.6343e+00 (4.6343e+00)\n",
            "Epoch: [16][25/97]\tLoss 4.6520e+00 (4.6944e+00)\n",
            "Epoch: [16][50/97]\tLoss 4.4681e+00 (4.6327e+00)\n",
            "Epoch: [16][75/97]\tLoss 4.5417e+00 (4.5886e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 46.96\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 17/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.37218\n",
            "Train ...\n",
            "Epoch: [17][ 0/97]\tLoss 4.3934e+00 (4.3934e+00)\n",
            "Epoch: [17][25/97]\tLoss 4.4189e+00 (4.4026e+00)\n",
            "Epoch: [17][50/97]\tLoss 4.4314e+00 (4.3549e+00)\n",
            "Epoch: [17][75/97]\tLoss 4.2307e+00 (4.3220e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 47.74\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 18/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.36890\n",
            "Train ...\n",
            "Epoch: [18][ 0/97]\tLoss 4.3716e+00 (4.3716e+00)\n",
            "Epoch: [18][25/97]\tLoss 4.3356e+00 (4.2832e+00)\n",
            "Epoch: [18][50/97]\tLoss 4.2312e+00 (4.2785e+00)\n",
            "Epoch: [18][75/97]\tLoss 4.1363e+00 (4.2516e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 47.70\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 19/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.36545\n",
            "Train ...\n",
            "Epoch: [19][ 0/97]\tLoss 4.1512e+00 (4.1512e+00)\n",
            "Epoch: [19][25/97]\tLoss 4.2334e+00 (4.1728e+00)\n",
            "Epoch: [19][50/97]\tLoss 4.2271e+00 (4.1619e+00)\n",
            "Epoch: [19][75/97]\tLoss 4.3216e+00 (4.1643e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 50.71\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 20/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.36184\n",
            "Train ...\n",
            "Epoch: [20][ 0/97]\tLoss 4.1056e+00 (4.1056e+00)\n",
            "Epoch: [20][25/97]\tLoss 4.1625e+00 (4.1253e+00)\n",
            "Epoch: [20][50/97]\tLoss 4.1481e+00 (4.1293e+00)\n",
            "Epoch: [20][75/97]\tLoss 4.0712e+00 (4.1278e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 50.91\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 21/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.35807\n",
            "Train ...\n",
            "Epoch: [21][ 0/97]\tLoss 4.2103e+00 (4.2103e+00)\n",
            "Epoch: [21][25/97]\tLoss 4.1732e+00 (4.1464e+00)\n",
            "Epoch: [21][50/97]\tLoss 4.1796e+00 (4.1326e+00)\n",
            "Epoch: [21][75/97]\tLoss 4.0944e+00 (4.1269e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 52.22\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 22/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.35415\n",
            "Train ...\n",
            "Epoch: [22][ 0/97]\tLoss 4.1789e+00 (4.1789e+00)\n",
            "Epoch: [22][25/97]\tLoss 4.1390e+00 (4.0905e+00)\n",
            "Epoch: [22][50/97]\tLoss 4.1388e+00 (4.0953e+00)\n",
            "Epoch: [22][75/97]\tLoss 3.9343e+00 (4.0892e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 53.38\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 23/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.35007\n",
            "Train ...\n",
            "Epoch: [23][ 0/97]\tLoss 4.0771e+00 (4.0771e+00)\n",
            "Epoch: [23][25/97]\tLoss 4.0353e+00 (4.0455e+00)\n",
            "Epoch: [23][50/97]\tLoss 3.9383e+00 (4.0372e+00)\n",
            "Epoch: [23][75/97]\tLoss 4.0153e+00 (4.0413e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 52.47\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 24/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.34585\n",
            "Train ...\n",
            "Epoch: [24][ 0/97]\tLoss 4.0032e+00 (4.0032e+00)\n",
            "Epoch: [24][25/97]\tLoss 3.9559e+00 (4.0086e+00)\n",
            "Epoch: [24][50/97]\tLoss 4.0926e+00 (4.0078e+00)\n",
            "Epoch: [24][75/97]\tLoss 4.0562e+00 (4.0221e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 54.84\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 25/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.34148\n",
            "Train ...\n",
            "Epoch: [25][ 0/97]\tLoss 3.9577e+00 (3.9577e+00)\n",
            "Epoch: [25][25/97]\tLoss 4.0647e+00 (3.9995e+00)\n",
            "Epoch: [25][50/97]\tLoss 3.9029e+00 (3.9972e+00)\n",
            "Epoch: [25][75/97]\tLoss 4.0019e+00 (4.0004e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 54.77\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 26/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.33697\n",
            "Train ...\n",
            "Epoch: [26][ 0/97]\tLoss 3.8729e+00 (3.8729e+00)\n",
            "Epoch: [26][25/97]\tLoss 3.9542e+00 (3.9635e+00)\n",
            "Epoch: [26][50/97]\tLoss 4.0048e+00 (3.9657e+00)\n",
            "Epoch: [26][75/97]\tLoss 3.9130e+00 (3.9653e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 54.39\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 27/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.33233\n",
            "Train ...\n",
            "Epoch: [27][ 0/97]\tLoss 3.9692e+00 (3.9692e+00)\n",
            "Epoch: [27][25/97]\tLoss 3.9632e+00 (3.9663e+00)\n",
            "Epoch: [27][50/97]\tLoss 4.0176e+00 (3.9558e+00)\n",
            "Epoch: [27][75/97]\tLoss 3.9969e+00 (3.9486e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 55.07\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 28/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.32756\n",
            "Train ...\n",
            "Epoch: [28][ 0/97]\tLoss 3.9854e+00 (3.9854e+00)\n",
            "Epoch: [28][25/97]\tLoss 4.0125e+00 (3.9534e+00)\n",
            "Epoch: [28][50/97]\tLoss 3.8424e+00 (3.9448e+00)\n",
            "Epoch: [28][75/97]\tLoss 3.9599e+00 (3.9462e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 55.19\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 29/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.32266\n",
            "Train ...\n",
            "Epoch: [29][ 0/97]\tLoss 3.9202e+00 (3.9202e+00)\n",
            "Epoch: [29][25/97]\tLoss 3.9403e+00 (3.9177e+00)\n",
            "Epoch: [29][50/97]\tLoss 4.0233e+00 (3.9312e+00)\n",
            "Epoch: [29][75/97]\tLoss 3.8714e+00 (3.9360e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 55.95\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 30/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.31764\n",
            "Train ...\n",
            "Epoch: [30][ 0/97]\tLoss 3.9209e+00 (3.9209e+00)\n",
            "Epoch: [30][25/97]\tLoss 3.8497e+00 (3.9257e+00)\n",
            "Epoch: [30][50/97]\tLoss 3.8952e+00 (3.9165e+00)\n",
            "Epoch: [30][75/97]\tLoss 3.9448e+00 (3.9109e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 56.58\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 31/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.31250\n",
            "Train ...\n",
            "Epoch: [31][ 0/97]\tLoss 3.9117e+00 (3.9117e+00)\n",
            "Epoch: [31][25/97]\tLoss 3.9103e+00 (3.9129e+00)\n",
            "Epoch: [31][50/97]\tLoss 3.8741e+00 (3.9033e+00)\n",
            "Epoch: [31][75/97]\tLoss 3.8689e+00 (3.9017e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 56.83\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 32/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.30726\n",
            "Train ...\n",
            "Epoch: [32][ 0/97]\tLoss 3.8449e+00 (3.8449e+00)\n",
            "Epoch: [32][25/97]\tLoss 3.8680e+00 (3.9177e+00)\n",
            "Epoch: [32][50/97]\tLoss 3.8075e+00 (3.8899e+00)\n",
            "Epoch: [32][75/97]\tLoss 3.8255e+00 (3.8910e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 56.02\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 33/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.30191\n",
            "Train ...\n",
            "Epoch: [33][ 0/97]\tLoss 3.9079e+00 (3.9079e+00)\n",
            "Epoch: [33][25/97]\tLoss 3.8455e+00 (3.8908e+00)\n",
            "Epoch: [33][50/97]\tLoss 3.9577e+00 (3.8841e+00)\n",
            "Epoch: [33][75/97]\tLoss 3.9432e+00 (3.8783e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 57.16\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 34/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.29645\n",
            "Train ...\n",
            "Epoch: [34][ 0/97]\tLoss 3.6691e+00 (3.6691e+00)\n",
            "Epoch: [34][25/97]\tLoss 3.6977e+00 (3.8232e+00)\n",
            "Epoch: [34][50/97]\tLoss 3.6261e+00 (3.7798e+00)\n",
            "Epoch: [34][75/97]\tLoss 3.6730e+00 (3.7175e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 59.07\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 35/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.29091\n",
            "Train ...\n",
            "Epoch: [35][ 0/97]\tLoss 3.5463e+00 (3.5463e+00)\n",
            "Epoch: [35][25/97]\tLoss 3.4982e+00 (3.5070e+00)\n",
            "Epoch: [35][50/97]\tLoss 3.4103e+00 (3.4873e+00)\n",
            "Epoch: [35][75/97]\tLoss 3.6027e+00 (3.4829e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 60.47\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 36/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.28527\n",
            "Train ...\n",
            "Epoch: [36][ 0/97]\tLoss 3.4752e+00 (3.4752e+00)\n",
            "Epoch: [36][25/97]\tLoss 3.4999e+00 (3.4826e+00)\n",
            "Epoch: [36][50/97]\tLoss 3.4685e+00 (3.4749e+00)\n",
            "Epoch: [36][75/97]\tLoss 3.4312e+00 (3.4581e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 61.55\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 37/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.27955\n",
            "Train ...\n",
            "Epoch: [37][ 0/97]\tLoss 3.2215e+00 (3.2215e+00)\n",
            "Epoch: [37][25/97]\tLoss 3.2185e+00 (3.2085e+00)\n",
            "Epoch: [37][50/97]\tLoss 3.1230e+00 (3.1933e+00)\n",
            "Epoch: [37][75/97]\tLoss 3.2286e+00 (3.1934e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 62.69\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 38/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.27375\n",
            "Train ...\n",
            "Epoch: [38][ 0/97]\tLoss 3.1949e+00 (3.1949e+00)\n",
            "Epoch: [38][25/97]\tLoss 3.0711e+00 (3.1244e+00)\n",
            "Epoch: [38][50/97]\tLoss 3.0868e+00 (3.1188e+00)\n",
            "Epoch: [38][75/97]\tLoss 3.0044e+00 (3.1271e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 62.89\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 39/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.26788\n",
            "Train ...\n",
            "Epoch: [39][ 0/97]\tLoss 3.1356e+00 (3.1356e+00)\n",
            "Epoch: [39][25/97]\tLoss 3.1000e+00 (3.1129e+00)\n",
            "Epoch: [39][50/97]\tLoss 3.0493e+00 (3.1040e+00)\n",
            "Epoch: [39][75/97]\tLoss 3.1286e+00 (3.1025e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 63.21\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 40/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.26194\n",
            "Train ...\n",
            "Epoch: [40][ 0/97]\tLoss 2.9975e+00 (2.9975e+00)\n",
            "Epoch: [40][25/97]\tLoss 3.0126e+00 (3.0832e+00)\n",
            "Epoch: [40][50/97]\tLoss 3.1105e+00 (3.0916e+00)\n",
            "Epoch: [40][75/97]\tLoss 3.0048e+00 (3.0905e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 63.14\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 41/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.25594\n",
            "Train ...\n",
            "Epoch: [41][ 0/97]\tLoss 3.0837e+00 (3.0837e+00)\n",
            "Epoch: [41][25/97]\tLoss 3.1224e+00 (3.0758e+00)\n",
            "Epoch: [41][50/97]\tLoss 3.1203e+00 (3.0780e+00)\n",
            "Epoch: [41][75/97]\tLoss 3.0891e+00 (3.0773e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 63.37\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 42/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.24989\n",
            "Train ...\n",
            "Epoch: [42][ 0/97]\tLoss 3.0880e+00 (3.0880e+00)\n",
            "Epoch: [42][25/97]\tLoss 2.9910e+00 (3.0570e+00)\n",
            "Epoch: [42][50/97]\tLoss 3.0463e+00 (3.0492e+00)\n",
            "Epoch: [42][75/97]\tLoss 3.0347e+00 (3.0374e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 64.34\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 43/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.24379\n",
            "Train ...\n",
            "Epoch: [43][ 0/97]\tLoss 3.0070e+00 (3.0070e+00)\n",
            "Epoch: [43][25/97]\tLoss 3.0159e+00 (2.8826e+00)\n",
            "Epoch: [43][50/97]\tLoss 2.7853e+00 (2.8631e+00)\n",
            "Epoch: [43][75/97]\tLoss 2.8548e+00 (2.8575e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 64.46\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 44/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.23764\n",
            "Train ...\n",
            "Epoch: [44][ 0/97]\tLoss 2.7954e+00 (2.7954e+00)\n",
            "Epoch: [44][25/97]\tLoss 2.8407e+00 (2.8105e+00)\n",
            "Epoch: [44][50/97]\tLoss 2.7885e+00 (2.8011e+00)\n",
            "Epoch: [44][75/97]\tLoss 2.8413e+00 (2.7956e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 64.57\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 45/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.23146\n",
            "Train ...\n",
            "Epoch: [45][ 0/97]\tLoss 2.7282e+00 (2.7282e+00)\n",
            "Epoch: [45][25/97]\tLoss 2.6380e+00 (2.7263e+00)\n",
            "Epoch: [45][50/97]\tLoss 2.6601e+00 (2.7071e+00)\n",
            "Epoch: [45][75/97]\tLoss 2.6625e+00 (2.6896e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 65.17\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 46/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.22524\n",
            "Train ...\n",
            "Epoch: [46][ 0/97]\tLoss 2.5959e+00 (2.5959e+00)\n",
            "Epoch: [46][25/97]\tLoss 2.4819e+00 (2.6068e+00)\n",
            "Epoch: [46][50/97]\tLoss 2.5921e+00 (2.5949e+00)\n",
            "Epoch: [46][75/97]\tLoss 2.5886e+00 (2.5915e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 65.49\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 47/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.21900\n",
            "Train ...\n",
            "Epoch: [47][ 0/97]\tLoss 2.6528e+00 (2.6528e+00)\n",
            "Epoch: [47][25/97]\tLoss 2.5905e+00 (2.5777e+00)\n",
            "Epoch: [47][50/97]\tLoss 2.4695e+00 (2.5809e+00)\n",
            "Epoch: [47][75/97]\tLoss 2.5530e+00 (2.5854e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 65.66\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 48/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.21275\n",
            "Train ...\n",
            "Epoch: [48][ 0/97]\tLoss 2.5587e+00 (2.5587e+00)\n",
            "Epoch: [48][25/97]\tLoss 2.5177e+00 (2.5576e+00)\n",
            "Epoch: [48][50/97]\tLoss 2.4921e+00 (2.5554e+00)\n",
            "Epoch: [48][75/97]\tLoss 2.4786e+00 (2.5497e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 66.26\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 49/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.20648\n",
            "Train ...\n",
            "Epoch: [49][ 0/97]\tLoss 2.5064e+00 (2.5064e+00)\n",
            "Epoch: [49][25/97]\tLoss 2.4682e+00 (2.4985e+00)\n",
            "Epoch: [49][50/97]\tLoss 2.4137e+00 (2.4832e+00)\n",
            "Epoch: [49][75/97]\tLoss 2.4255e+00 (2.4658e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 66.25\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 50/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.20020\n",
            "Train ...\n",
            "Epoch: [50][ 0/97]\tLoss 2.3551e+00 (2.3551e+00)\n",
            "Epoch: [50][25/97]\tLoss 2.4622e+00 (2.4143e+00)\n",
            "Epoch: [50][50/97]\tLoss 2.4000e+00 (2.4045e+00)\n",
            "Epoch: [50][75/97]\tLoss 2.3403e+00 (2.3945e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 67.05\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 51/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.19392\n",
            "Train ...\n",
            "Epoch: [51][ 0/97]\tLoss 2.2352e+00 (2.2352e+00)\n",
            "Epoch: [51][25/97]\tLoss 2.2895e+00 (2.3419e+00)\n",
            "Epoch: [51][50/97]\tLoss 2.2981e+00 (2.3241e+00)\n",
            "Epoch: [51][75/97]\tLoss 2.2791e+00 (2.3266e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 68.15\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 52/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.18765\n",
            "Train ...\n",
            "Epoch: [52][ 0/97]\tLoss 2.3667e+00 (2.3667e+00)\n",
            "Epoch: [52][25/97]\tLoss 2.0846e+00 (2.2575e+00)\n",
            "Epoch: [52][50/97]\tLoss 2.3420e+00 (2.2507e+00)\n",
            "Epoch: [52][75/97]\tLoss 2.2008e+00 (2.2405e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 68.11\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 53/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.18140\n",
            "Train ...\n",
            "Epoch: [53][ 0/97]\tLoss 2.1914e+00 (2.1914e+00)\n",
            "Epoch: [53][25/97]\tLoss 2.2522e+00 (2.2288e+00)\n",
            "Epoch: [53][50/97]\tLoss 2.2421e+00 (2.2209e+00)\n",
            "Epoch: [53][75/97]\tLoss 2.0791e+00 (2.2145e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 68.24\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 54/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.17516\n",
            "Train ...\n",
            "Epoch: [54][ 0/97]\tLoss 2.1467e+00 (2.1467e+00)\n",
            "Epoch: [54][25/97]\tLoss 2.1172e+00 (2.1771e+00)\n",
            "Epoch: [54][50/97]\tLoss 2.1352e+00 (2.1590e+00)\n",
            "Epoch: [54][75/97]\tLoss 2.1044e+00 (2.1521e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 68.65\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 55/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.16894\n",
            "Train ...\n",
            "Epoch: [55][ 0/97]\tLoss 2.2478e+00 (2.2478e+00)\n",
            "Epoch: [55][25/97]\tLoss 2.1049e+00 (2.1198e+00)\n",
            "Epoch: [55][50/97]\tLoss 2.1367e+00 (2.0971e+00)\n",
            "Epoch: [55][75/97]\tLoss 2.0229e+00 (2.0905e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 69.70\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 56/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.16276\n",
            "Train ...\n",
            "Epoch: [56][ 0/97]\tLoss 2.0032e+00 (2.0032e+00)\n",
            "Epoch: [56][25/97]\tLoss 1.9843e+00 (2.0388e+00)\n",
            "Epoch: [56][50/97]\tLoss 2.0652e+00 (2.0395e+00)\n",
            "Epoch: [56][75/97]\tLoss 2.0212e+00 (2.0388e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 70.00\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 57/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.15661\n",
            "Train ...\n",
            "Epoch: [57][ 0/97]\tLoss 2.1094e+00 (2.1094e+00)\n",
            "Epoch: [57][25/97]\tLoss 2.0979e+00 (2.0246e+00)\n",
            "Epoch: [57][50/97]\tLoss 1.9635e+00 (2.0196e+00)\n",
            "Epoch: [57][75/97]\tLoss 1.9453e+00 (2.0070e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 69.62\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 58/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.15051\n",
            "Train ...\n",
            "Epoch: [58][ 0/97]\tLoss 1.9660e+00 (1.9660e+00)\n",
            "Epoch: [58][25/97]\tLoss 1.9253e+00 (1.9581e+00)\n",
            "Epoch: [58][50/97]\tLoss 1.9152e+00 (1.9513e+00)\n",
            "Epoch: [58][75/97]\tLoss 1.9782e+00 (1.9490e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 70.67\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 59/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.14446\n",
            "Train ...\n",
            "Epoch: [59][ 0/97]\tLoss 1.9585e+00 (1.9585e+00)\n",
            "Epoch: [59][25/97]\tLoss 1.8829e+00 (1.8961e+00)\n",
            "Epoch: [59][50/97]\tLoss 1.9638e+00 (1.9064e+00)\n",
            "Epoch: [59][75/97]\tLoss 1.9437e+00 (1.9167e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 70.27\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 60/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.13846\n",
            "Train ...\n",
            "Epoch: [60][ 0/97]\tLoss 1.8641e+00 (1.8641e+00)\n",
            "Epoch: [60][25/97]\tLoss 2.0198e+00 (1.8965e+00)\n",
            "Epoch: [60][50/97]\tLoss 1.8630e+00 (1.8943e+00)\n",
            "Epoch: [60][75/97]\tLoss 1.8862e+00 (1.8892e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 70.58\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 61/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.13252\n",
            "Train ...\n",
            "Epoch: [61][ 0/97]\tLoss 1.9406e+00 (1.9406e+00)\n",
            "Epoch: [61][25/97]\tLoss 1.8759e+00 (1.8898e+00)\n",
            "Epoch: [61][50/97]\tLoss 1.8752e+00 (1.8753e+00)\n",
            "Epoch: [61][75/97]\tLoss 1.9349e+00 (1.8762e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 71.10\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 62/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.12665\n",
            "Train ...\n",
            "Epoch: [62][ 0/97]\tLoss 1.7865e+00 (1.7865e+00)\n",
            "Epoch: [62][25/97]\tLoss 1.7923e+00 (1.8256e+00)\n",
            "Epoch: [62][50/97]\tLoss 1.8769e+00 (1.8208e+00)\n",
            "Epoch: [62][75/97]\tLoss 1.8911e+00 (1.8186e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 71.43\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 63/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.12085\n",
            "Train ...\n",
            "Epoch: [63][ 0/97]\tLoss 1.7927e+00 (1.7927e+00)\n",
            "Epoch: [63][25/97]\tLoss 1.7443e+00 (1.7936e+00)\n",
            "Epoch: [63][50/97]\tLoss 1.7375e+00 (1.7901e+00)\n",
            "Epoch: [63][75/97]\tLoss 1.8339e+00 (1.7843e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 72.22\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 64/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.11513\n",
            "Train ...\n",
            "Epoch: [64][ 0/97]\tLoss 1.7057e+00 (1.7057e+00)\n",
            "Epoch: [64][25/97]\tLoss 1.6753e+00 (1.7324e+00)\n",
            "Epoch: [64][50/97]\tLoss 1.7199e+00 (1.7307e+00)\n",
            "Epoch: [64][75/97]\tLoss 1.7152e+00 (1.7311e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 72.39\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 65/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.10949\n",
            "Train ...\n",
            "Epoch: [65][ 0/97]\tLoss 1.7237e+00 (1.7237e+00)\n",
            "Epoch: [65][25/97]\tLoss 1.6934e+00 (1.6974e+00)\n",
            "Epoch: [65][50/97]\tLoss 1.6642e+00 (1.7008e+00)\n",
            "Epoch: [65][75/97]\tLoss 1.7281e+00 (1.6970e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 72.67\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 66/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.10395\n",
            "Train ...\n",
            "Epoch: [66][ 0/97]\tLoss 1.6731e+00 (1.6731e+00)\n",
            "Epoch: [66][25/97]\tLoss 1.7357e+00 (1.6835e+00)\n",
            "Epoch: [66][50/97]\tLoss 1.7234e+00 (1.6778e+00)\n",
            "Epoch: [66][75/97]\tLoss 1.6539e+00 (1.6766e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 72.71\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 67/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.09849\n",
            "Train ...\n",
            "Epoch: [67][ 0/97]\tLoss 1.6588e+00 (1.6588e+00)\n",
            "Epoch: [67][25/97]\tLoss 1.6194e+00 (1.6639e+00)\n",
            "Epoch: [67][50/97]\tLoss 1.6766e+00 (1.6584e+00)\n",
            "Epoch: [67][75/97]\tLoss 1.6737e+00 (1.6616e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 72.62\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 68/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.09314\n",
            "Train ...\n",
            "Epoch: [68][ 0/97]\tLoss 1.6149e+00 (1.6149e+00)\n",
            "Epoch: [68][25/97]\tLoss 1.6898e+00 (1.6486e+00)\n",
            "Epoch: [68][50/97]\tLoss 1.6833e+00 (1.6420e+00)\n",
            "Epoch: [68][75/97]\tLoss 1.6113e+00 (1.6435e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 72.95\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 69/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.08790\n",
            "Train ...\n",
            "Epoch: [69][ 0/97]\tLoss 1.5643e+00 (1.5643e+00)\n",
            "Epoch: [69][25/97]\tLoss 1.5134e+00 (1.6232e+00)\n",
            "Epoch: [69][50/97]\tLoss 1.5839e+00 (1.6276e+00)\n",
            "Epoch: [69][75/97]\tLoss 1.6292e+00 (1.6315e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 72.88\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 70/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.08276\n",
            "Train ...\n",
            "Epoch: [70][ 0/97]\tLoss 1.7051e+00 (1.7051e+00)\n",
            "Epoch: [70][25/97]\tLoss 1.7002e+00 (1.6139e+00)\n",
            "Epoch: [70][50/97]\tLoss 1.6039e+00 (1.6102e+00)\n",
            "Epoch: [70][75/97]\tLoss 1.5944e+00 (1.6089e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 72.91\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 71/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.07774\n",
            "Train ...\n",
            "Epoch: [71][ 0/97]\tLoss 1.5326e+00 (1.5326e+00)\n",
            "Epoch: [71][25/97]\tLoss 1.5049e+00 (1.5788e+00)\n",
            "Epoch: [71][50/97]\tLoss 1.6324e+00 (1.5807e+00)\n",
            "Epoch: [71][75/97]\tLoss 1.5679e+00 (1.5876e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 73.53\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 72/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.07284\n",
            "Train ...\n",
            "Epoch: [72][ 0/97]\tLoss 1.5990e+00 (1.5990e+00)\n",
            "Epoch: [72][25/97]\tLoss 1.6391e+00 (1.6002e+00)\n",
            "Epoch: [72][50/97]\tLoss 1.5277e+00 (1.5819e+00)\n",
            "Epoch: [72][75/97]\tLoss 1.5462e+00 (1.5752e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 73.34\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 73/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.06807\n",
            "Train ...\n",
            "Epoch: [73][ 0/97]\tLoss 1.5522e+00 (1.5522e+00)\n",
            "Epoch: [73][25/97]\tLoss 1.5614e+00 (1.5527e+00)\n",
            "Epoch: [73][50/97]\tLoss 1.4638e+00 (1.5469e+00)\n",
            "Epoch: [73][75/97]\tLoss 1.4979e+00 (1.5441e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 73.86\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 74/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.06343\n",
            "Train ...\n",
            "Epoch: [74][ 0/97]\tLoss 1.5320e+00 (1.5320e+00)\n",
            "Epoch: [74][25/97]\tLoss 1.5409e+00 (1.5237e+00)\n",
            "Epoch: [74][50/97]\tLoss 1.5479e+00 (1.5244e+00)\n",
            "Epoch: [74][75/97]\tLoss 1.5093e+00 (1.5286e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 74.21\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 75/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.05892\n",
            "Train ...\n",
            "Epoch: [75][ 0/97]\tLoss 1.5294e+00 (1.5294e+00)\n",
            "Epoch: [75][25/97]\tLoss 1.5080e+00 (1.5010e+00)\n",
            "Epoch: [75][50/97]\tLoss 1.5754e+00 (1.4993e+00)\n",
            "Epoch: [75][75/97]\tLoss 1.4655e+00 (1.4939e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 74.63\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 76/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.05455\n",
            "Train ...\n",
            "Epoch: [76][ 0/97]\tLoss 1.5046e+00 (1.5046e+00)\n",
            "Epoch: [76][25/97]\tLoss 1.5447e+00 (1.4737e+00)\n",
            "Epoch: [76][50/97]\tLoss 1.5268e+00 (1.4721e+00)\n",
            "Epoch: [76][75/97]\tLoss 1.4791e+00 (1.4703e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 74.70\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 77/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.05033\n",
            "Train ...\n",
            "Epoch: [77][ 0/97]\tLoss 1.4471e+00 (1.4471e+00)\n",
            "Epoch: [77][25/97]\tLoss 1.4270e+00 (1.4420e+00)\n",
            "Epoch: [77][50/97]\tLoss 1.4371e+00 (1.4523e+00)\n",
            "Epoch: [77][75/97]\tLoss 1.5655e+00 (1.4528e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 74.59\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 78/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.04625\n",
            "Train ...\n",
            "Epoch: [78][ 0/97]\tLoss 1.4729e+00 (1.4729e+00)\n",
            "Epoch: [78][25/97]\tLoss 1.4326e+00 (1.4389e+00)\n",
            "Epoch: [78][50/97]\tLoss 1.4651e+00 (1.4412e+00)\n",
            "Epoch: [78][75/97]\tLoss 1.4181e+00 (1.4438e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 75.21\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 79/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.04233\n",
            "Train ...\n",
            "Epoch: [79][ 0/97]\tLoss 1.3691e+00 (1.3691e+00)\n",
            "Epoch: [79][25/97]\tLoss 1.3983e+00 (1.4325e+00)\n",
            "Epoch: [79][50/97]\tLoss 1.4232e+00 (1.4241e+00)\n",
            "Epoch: [79][75/97]\tLoss 1.3518e+00 (1.4306e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 75.01\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 80/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.03856\n",
            "Train ...\n",
            "Epoch: [80][ 0/97]\tLoss 1.3957e+00 (1.3957e+00)\n",
            "Epoch: [80][25/97]\tLoss 1.3657e+00 (1.4080e+00)\n",
            "Epoch: [80][50/97]\tLoss 1.4533e+00 (1.4207e+00)\n",
            "Epoch: [80][75/97]\tLoss 1.4715e+00 (1.4214e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 75.16\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 81/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.03495\n",
            "Train ...\n",
            "Epoch: [81][ 0/97]\tLoss 1.3581e+00 (1.3581e+00)\n",
            "Epoch: [81][25/97]\tLoss 1.4875e+00 (1.4187e+00)\n",
            "Epoch: [81][50/97]\tLoss 1.4283e+00 (1.4124e+00)\n",
            "Epoch: [81][75/97]\tLoss 1.3700e+00 (1.4113e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 75.44\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 82/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.03150\n",
            "Train ...\n",
            "Epoch: [82][ 0/97]\tLoss 1.3573e+00 (1.3573e+00)\n",
            "Epoch: [82][25/97]\tLoss 1.3965e+00 (1.4108e+00)\n",
            "Epoch: [82][50/97]\tLoss 1.3424e+00 (1.4081e+00)\n",
            "Epoch: [82][75/97]\tLoss 1.3949e+00 (1.4084e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 75.55\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 83/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.02822\n",
            "Train ...\n",
            "Epoch: [83][ 0/97]\tLoss 1.3692e+00 (1.3692e+00)\n",
            "Epoch: [83][25/97]\tLoss 1.4320e+00 (1.3728e+00)\n",
            "Epoch: [83][50/97]\tLoss 1.4089e+00 (1.3873e+00)\n",
            "Epoch: [83][75/97]\tLoss 1.4519e+00 (1.3921e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 75.74\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 84/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.02511\n",
            "Train ...\n",
            "Epoch: [84][ 0/97]\tLoss 1.4006e+00 (1.4006e+00)\n",
            "Epoch: [84][25/97]\tLoss 1.3357e+00 (1.3781e+00)\n",
            "Epoch: [84][50/97]\tLoss 1.3641e+00 (1.3843e+00)\n",
            "Epoch: [84][75/97]\tLoss 1.3791e+00 (1.3903e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 75.60\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 85/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.02218\n",
            "Train ...\n",
            "Epoch: [85][ 0/97]\tLoss 1.3481e+00 (1.3481e+00)\n",
            "Epoch: [85][25/97]\tLoss 1.2891e+00 (1.3655e+00)\n",
            "Epoch: [85][50/97]\tLoss 1.3611e+00 (1.3689e+00)\n",
            "Epoch: [85][75/97]\tLoss 1.3605e+00 (1.3661e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 75.99\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 86/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.01942\n",
            "Train ...\n",
            "Epoch: [86][ 0/97]\tLoss 1.3786e+00 (1.3786e+00)\n",
            "Epoch: [86][25/97]\tLoss 1.3462e+00 (1.3766e+00)\n",
            "Epoch: [86][50/97]\tLoss 1.3485e+00 (1.3814e+00)\n",
            "Epoch: [86][75/97]\tLoss 1.3898e+00 (1.3828e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 75.81\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 87/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.01683\n",
            "Train ...\n",
            "Epoch: [87][ 0/97]\tLoss 1.3323e+00 (1.3323e+00)\n",
            "Epoch: [87][25/97]\tLoss 1.3718e+00 (1.3663e+00)\n",
            "Epoch: [87][50/97]\tLoss 1.3372e+00 (1.3602e+00)\n",
            "Epoch: [87][75/97]\tLoss 1.4044e+00 (1.3623e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 76.02\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 88/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.01443\n",
            "Train ...\n",
            "Epoch: [88][ 0/97]\tLoss 1.2836e+00 (1.2836e+00)\n",
            "Epoch: [88][25/97]\tLoss 1.3856e+00 (1.3601e+00)\n",
            "Epoch: [88][50/97]\tLoss 1.3294e+00 (1.3663e+00)\n",
            "Epoch: [88][75/97]\tLoss 1.3971e+00 (1.3650e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 76.07\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 89/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.01221\n",
            "Train ...\n",
            "Epoch: [89][ 0/97]\tLoss 1.3289e+00 (1.3289e+00)\n",
            "Epoch: [89][25/97]\tLoss 1.3367e+00 (1.3596e+00)\n",
            "Epoch: [89][50/97]\tLoss 1.4002e+00 (1.3540e+00)\n",
            "Epoch: [89][75/97]\tLoss 1.3919e+00 (1.3560e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 76.20\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 90/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.01018\n",
            "Train ...\n",
            "Epoch: [90][ 0/97]\tLoss 1.3286e+00 (1.3286e+00)\n",
            "Epoch: [90][25/97]\tLoss 1.2733e+00 (1.3517e+00)\n",
            "Epoch: [90][50/97]\tLoss 1.2961e+00 (1.3489e+00)\n",
            "Epoch: [90][75/97]\tLoss 1.2904e+00 (1.3488e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 76.02\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 91/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00833\n",
            "Train ...\n",
            "Epoch: [91][ 0/97]\tLoss 1.3191e+00 (1.3191e+00)\n",
            "Epoch: [91][25/97]\tLoss 1.4545e+00 (1.3606e+00)\n",
            "Epoch: [91][50/97]\tLoss 1.3918e+00 (1.3539e+00)\n",
            "Epoch: [91][75/97]\tLoss 1.3679e+00 (1.3512e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 75.83\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 92/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00668\n",
            "Train ...\n",
            "Epoch: [92][ 0/97]\tLoss 1.2911e+00 (1.2911e+00)\n",
            "Epoch: [92][25/97]\tLoss 1.3236e+00 (1.3355e+00)\n",
            "Epoch: [92][50/97]\tLoss 1.3694e+00 (1.3375e+00)\n",
            "Epoch: [92][75/97]\tLoss 1.3930e+00 (1.3374e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 76.02\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 93/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00521\n",
            "Train ...\n",
            "Epoch: [93][ 0/97]\tLoss 1.2930e+00 (1.2930e+00)\n",
            "Epoch: [93][25/97]\tLoss 1.3270e+00 (1.3393e+00)\n",
            "Epoch: [93][50/97]\tLoss 1.3911e+00 (1.3375e+00)\n",
            "Epoch: [93][75/97]\tLoss 1.4258e+00 (1.3413e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 76.04\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 94/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00394\n",
            "Train ...\n",
            "Epoch: [94][ 0/97]\tLoss 1.4197e+00 (1.4197e+00)\n",
            "Epoch: [94][25/97]\tLoss 1.2668e+00 (1.3418e+00)\n",
            "Epoch: [94][50/97]\tLoss 1.3177e+00 (1.3432e+00)\n",
            "Epoch: [94][75/97]\tLoss 1.3326e+00 (1.3411e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 76.30\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 95/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00286\n",
            "Train ...\n",
            "Epoch: [95][ 0/97]\tLoss 1.3467e+00 (1.3467e+00)\n",
            "Epoch: [95][25/97]\tLoss 1.3612e+00 (1.3296e+00)\n",
            "Epoch: [95][50/97]\tLoss 1.2890e+00 (1.3377e+00)\n",
            "Epoch: [95][75/97]\tLoss 1.3092e+00 (1.3380e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 76.07\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 96/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00198\n",
            "Train ...\n",
            "Epoch: [96][ 0/97]\tLoss 1.3810e+00 (1.3810e+00)\n",
            "Epoch: [96][25/97]\tLoss 1.3266e+00 (1.3191e+00)\n",
            "Epoch: [96][50/97]\tLoss 1.2939e+00 (1.3234e+00)\n",
            "Epoch: [96][75/97]\tLoss 1.2477e+00 (1.3235e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 76.03\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 97/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00129\n",
            "Train ...\n",
            "Epoch: [97][ 0/97]\tLoss 1.3266e+00 (1.3266e+00)\n",
            "Epoch: [97][25/97]\tLoss 1.3168e+00 (1.3171e+00)\n",
            "Epoch: [97][50/97]\tLoss 1.3560e+00 (1.3252e+00)\n",
            "Epoch: [97][75/97]\tLoss 1.3111e+00 (1.3283e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 76.07\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 98/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00079\n",
            "Train ...\n",
            "Epoch: [98][ 0/97]\tLoss 1.2800e+00 (1.2800e+00)\n",
            "Epoch: [98][25/97]\tLoss 1.3006e+00 (1.3376e+00)\n",
            "Epoch: [98][50/97]\tLoss 1.3582e+00 (1.3336e+00)\n",
            "Epoch: [98][75/97]\tLoss 1.3403e+00 (1.3329e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 76.06\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 99/100\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00050\n",
            "Train ...\n",
            "Epoch: [99][ 0/97]\tLoss 1.2985e+00 (1.2985e+00)\n",
            "Epoch: [99][25/97]\tLoss 1.3132e+00 (1.3201e+00)\n",
            "Epoch: [99][50/97]\tLoss 1.2596e+00 (1.3158e+00)\n",
            "Epoch: [99][75/97]\tLoss 1.3842e+00 (1.3248e+00)\n",
            "Fill memory bank for kNN...\n",
            "Fill Memory Bank [0/98]\n",
            "Evaluate ...\n",
            "Result of kNN evaluation is 76.06\n",
            "Checkpoint ...\n",
            "\u001b[34mFill memory bank for mining the nearest neighbors (train) ...\u001b[0m\n",
            "Fill Memory Bank [0/98]\n",
            "Mine the nearest neighbors (Top-20)\n",
            "Accuracy of top-20 nearest neighbors on train set is 62.43\n",
            "\u001b[34mFill memory bank for mining the nearest neighbors (val) ...\u001b[0m\n",
            "Fill Memory Bank [0/20]\n",
            "Mine the nearest neighbors (Top-5)\n",
            "Accuracy of top-5 nearest neighbors on val set is 60.84\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/EECS_6322/Final_Project/train_SimCLR.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5RtJOR2pvKv",
        "outputId": "41fc60c2-59ac-4f5f-c0f4-122ef75a5bf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m{'setup': 'scan', 'criterion': 'scan', 'criterion_kwargs': {'entropy_weight': 5.0}, 'update_cluster_head_only': False, 'num_heads': 1, 'backbone': 'resnet18', 'train_db_name': 'cifar-10', 'val_db_name': 'cifar-10', 'num_classes': 10, 'num_neighbors': 20, 'augmentation_strategy': 'ours', 'augmentation_kwargs': {'crop_size': 32, 'normalize': {'mean': [0.4914, 0.4822, 0.4465], 'std': [0.2023, 0.1994, 0.201]}, 'num_strong_augs': 4, 'cutout_kwargs': {'n_holes': 1, 'length': 16, 'random': True}}, 'transformation_kwargs': {'crop_size': 32, 'normalize': {'mean': [0.4914, 0.4822, 0.4465], 'std': [0.2023, 0.1994, 0.201]}}, 'optimizer': 'adam', 'optimizer_kwargs': {'lr': 0.0001, 'weight_decay': 0.0001}, 'epochs': 50, 'batch_size': 128, 'num_workers': 8, 'scheduler': 'constant', 'pretext_dir': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/pretext', 'pretext_checkpoint': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/pretext/checkpoint.pth.tar', 'pretext_model': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/pretext/model.pth.tar', 'topk_neighbors_train_path': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/pretext/topk-train-neighbors.npy', 'topk_neighbors_val_path': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/pretext/topk-val-neighbors.npy', 'scan_dir': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/scan', 'scan_checkpoint': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/scan/checkpoint.pth.tar', 'scan_model': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/scan/model.pth.tar', 'selflabel_dir': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/selflabel', 'selflabel_checkpoint': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/selflabel/checkpoint.pth.tar', 'selflabel_model': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/selflabel/model.pth.tar'}\u001b[0m\n",
            "\u001b[34mGet dataset and dataloaders\u001b[0m\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train transforms: Compose(\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomCrop(size=(32, 32), padding=None)\n",
            "    <data.augment.Augment object at 0x7fb269fce130>\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])\n",
            "    <data.augment.Cutout object at 0x7fb269fce250>\n",
            ")\n",
            "Validation transforms: Compose(\n",
            "    CenterCrop(size=(32, 32))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])\n",
            ")\n",
            "Train samples 50000 - Val samples 10000\n",
            "\u001b[34mGet model\u001b[0m\n",
            "ClusteringModel(\n",
            "  (backbone): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  )\n",
            "  (cluster_head): ModuleList(\n",
            "    (0): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\u001b[34mGet optimizer\u001b[0m\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0.0001\n",
            ")\n",
            "\u001b[34mGet loss\u001b[0m\n",
            "SCANLoss(\n",
            "  (softmax): Softmax(dim=1)\n",
            "  (bce): BCELoss()\n",
            ")\n",
            "\u001b[34mNo checkpoint file at /content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/scan/checkpoint.pth.tar\u001b[0m\n",
            "\u001b[34mStarting main loop\u001b[0m\n",
            "\u001b[33mEpoch 1/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "Epoch: [0][  0/390]\tTotal Loss -9.2086e+00 (-9.2086e+00)\tConsistency Loss 2.2992e+00 (2.2992e+00)\tEntropy 2.3016e+00 (2.3016e+00)\n",
            "Epoch: [0][ 25/390]\tTotal Loss -9.2965e+00 (-9.2393e+00)\tConsistency Loss 2.1984e+00 (2.2688e+00)\tEntropy 2.2990e+00 (2.3016e+00)\n",
            "Epoch: [0][ 50/390]\tTotal Loss -9.4117e+00 (-9.2972e+00)\tConsistency Loss 2.0580e+00 (2.1986e+00)\tEntropy 2.2939e+00 (2.2992e+00)\n",
            "Epoch: [0][ 75/390]\tTotal Loss -9.6038e+00 (-9.3651e+00)\tConsistency Loss 1.8734e+00 (2.1232e+00)\tEntropy 2.2954e+00 (2.2977e+00)\n",
            "Epoch: [0][100/390]\tTotal Loss -9.6598e+00 (-9.4317e+00)\tConsistency Loss 1.8124e+00 (2.0532e+00)\tEntropy 2.2944e+00 (2.2970e+00)\n",
            "Epoch: [0][125/390]\tTotal Loss -9.8075e+00 (-9.4964e+00)\tConsistency Loss 1.6668e+00 (1.9866e+00)\tEntropy 2.2949e+00 (2.2966e+00)\n",
            "Epoch: [0][150/390]\tTotal Loss -9.8778e+00 (-9.5567e+00)\tConsistency Loss 1.6093e+00 (1.9271e+00)\tEntropy 2.2974e+00 (2.2968e+00)\n",
            "Epoch: [0][175/390]\tTotal Loss -1.0067e+01 (-9.6128e+00)\tConsistency Loss 1.4278e+00 (1.8723e+00)\tEntropy 2.2991e+00 (2.2970e+00)\n",
            "Epoch: [0][200/390]\tTotal Loss -1.0148e+01 (-9.6614e+00)\tConsistency Loss 1.3390e+00 (1.8251e+00)\tEntropy 2.2974e+00 (2.2973e+00)\n",
            "Epoch: [0][225/390]\tTotal Loss -9.9293e+00 (-9.7048e+00)\tConsistency Loss 1.5782e+00 (1.7829e+00)\tEntropy 2.3015e+00 (2.2975e+00)\n",
            "Epoch: [0][250/390]\tTotal Loss -1.0054e+01 (-9.7432e+00)\tConsistency Loss 1.4482e+00 (1.7456e+00)\tEntropy 2.3005e+00 (2.2978e+00)\n",
            "Epoch: [0][275/390]\tTotal Loss -9.9953e+00 (-9.7782e+00)\tConsistency Loss 1.5023e+00 (1.7114e+00)\tEntropy 2.2995e+00 (2.2979e+00)\n",
            "Epoch: [0][300/390]\tTotal Loss -1.0115e+01 (-9.8088e+00)\tConsistency Loss 1.3887e+00 (1.6816e+00)\tEntropy 2.3007e+00 (2.2981e+00)\n",
            "Epoch: [0][325/390]\tTotal Loss -1.0325e+01 (-9.8371e+00)\tConsistency Loss 1.1783e+00 (1.6536e+00)\tEntropy 2.3008e+00 (2.2981e+00)\n",
            "Epoch: [0][350/390]\tTotal Loss -1.0210e+01 (-9.8628e+00)\tConsistency Loss 1.2835e+00 (1.6279e+00)\tEntropy 2.2987e+00 (2.2981e+00)\n",
            "Epoch: [0][375/390]\tTotal Loss -1.0220e+01 (-9.8852e+00)\tConsistency Loss 1.2779e+00 (1.6054e+00)\tEntropy 2.2996e+00 (2.2981e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.292437791824341, 'consistency': 0.8687899112701416, 'total_loss': -1.4236478805541992}], 'lowest_loss_head': 0, 'lowest_loss': -1.4236478805541992}\n",
            "New lowest loss on validation set: 10000.0000 -> -1.4236\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.56, 'ARI': 0.37382347372063457, 'NMI': 0.476288935228622, 'ACC Top-5': 0.9419, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 2/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [1][  0/390]\tTotal Loss -1.0067e+01 (-1.0067e+01)\tConsistency Loss 1.4415e+00 (1.4415e+00)\tEntropy 2.3016e+00 (2.3016e+00)\n",
            "Epoch: [1][ 25/390]\tTotal Loss -1.0229e+01 (-1.0197e+01)\tConsistency Loss 1.2571e+00 (1.2895e+00)\tEntropy 2.2972e+00 (2.2972e+00)\n",
            "Epoch: [1][ 50/390]\tTotal Loss -1.0231e+01 (-1.0205e+01)\tConsistency Loss 1.2558e+00 (1.2797e+00)\tEntropy 2.2973e+00 (2.2970e+00)\n",
            "Epoch: [1][ 75/390]\tTotal Loss -1.0321e+01 (-1.0224e+01)\tConsistency Loss 1.1710e+00 (1.2637e+00)\tEntropy 2.2984e+00 (2.2975e+00)\n",
            "Epoch: [1][100/390]\tTotal Loss -1.0323e+01 (-1.0245e+01)\tConsistency Loss 1.1453e+00 (1.2427e+00)\tEntropy 2.2936e+00 (2.2975e+00)\n",
            "Epoch: [1][125/390]\tTotal Loss -1.0194e+01 (-1.0247e+01)\tConsistency Loss 1.3000e+00 (1.2402e+00)\tEntropy 2.2987e+00 (2.2974e+00)\n",
            "Epoch: [1][150/390]\tTotal Loss -1.0179e+01 (-1.0251e+01)\tConsistency Loss 1.3263e+00 (1.2366e+00)\tEntropy 2.3011e+00 (2.2975e+00)\n",
            "Epoch: [1][175/390]\tTotal Loss -1.0259e+01 (-1.0255e+01)\tConsistency Loss 1.2342e+00 (1.2331e+00)\tEntropy 2.2986e+00 (2.2976e+00)\n",
            "Epoch: [1][200/390]\tTotal Loss -1.0325e+01 (-1.0257e+01)\tConsistency Loss 1.1597e+00 (1.2306e+00)\tEntropy 2.2969e+00 (2.2975e+00)\n",
            "Epoch: [1][225/390]\tTotal Loss -1.0304e+01 (-1.0260e+01)\tConsistency Loss 1.1718e+00 (1.2275e+00)\tEntropy 2.2951e+00 (2.2975e+00)\n",
            "Epoch: [1][250/390]\tTotal Loss -1.0413e+01 (-1.0264e+01)\tConsistency Loss 1.0853e+00 (1.2230e+00)\tEntropy 2.2997e+00 (2.2975e+00)\n",
            "Epoch: [1][275/390]\tTotal Loss -1.0321e+01 (-1.0266e+01)\tConsistency Loss 1.1333e+00 (1.2210e+00)\tEntropy 2.2909e+00 (2.2974e+00)\n",
            "Epoch: [1][300/390]\tTotal Loss -1.0306e+01 (-1.0271e+01)\tConsistency Loss 1.1737e+00 (1.2153e+00)\tEntropy 2.2959e+00 (2.2974e+00)\n",
            "Epoch: [1][325/390]\tTotal Loss -1.0165e+01 (-1.0275e+01)\tConsistency Loss 1.3208e+00 (1.2114e+00)\tEntropy 2.2971e+00 (2.2973e+00)\n",
            "Epoch: [1][350/390]\tTotal Loss -1.0356e+01 (-1.0278e+01)\tConsistency Loss 1.0961e+00 (1.2077e+00)\tEntropy 2.2905e+00 (2.2972e+00)\n",
            "Epoch: [1][375/390]\tTotal Loss -1.0432e+01 (-1.0281e+01)\tConsistency Loss 1.0708e+00 (1.2047e+00)\tEntropy 2.3005e+00 (2.2972e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.2951536178588867, 'consistency': 0.7808784246444702, 'total_loss': -1.5142751932144165}], 'lowest_loss_head': 0, 'lowest_loss': -1.5142751932144165}\n",
            "New lowest loss on validation set: -1.4236 -> -1.5143\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.5971, 'ARI': 0.4084752130657965, 'NMI': 0.5012789317123494, 'ACC Top-5': 0.9463, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 3/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [2][  0/390]\tTotal Loss -1.0371e+01 (-1.0371e+01)\tConsistency Loss 1.1164e+00 (1.1164e+00)\tEntropy 2.2974e+00 (2.2974e+00)\n",
            "Epoch: [2][ 25/390]\tTotal Loss -1.0417e+01 (-1.0342e+01)\tConsistency Loss 1.0702e+00 (1.1442e+00)\tEntropy 2.2974e+00 (2.2972e+00)\n",
            "Epoch: [2][ 50/390]\tTotal Loss -1.0409e+01 (-1.0351e+01)\tConsistency Loss 1.0242e+00 (1.1354e+00)\tEntropy 2.2867e+00 (2.2973e+00)\n",
            "Epoch: [2][ 75/390]\tTotal Loss -1.0407e+01 (-1.0348e+01)\tConsistency Loss 1.0471e+00 (1.1372e+00)\tEntropy 2.2909e+00 (2.2971e+00)\n",
            "Epoch: [2][100/390]\tTotal Loss -1.0317e+01 (-1.0349e+01)\tConsistency Loss 1.1875e+00 (1.1354e+00)\tEntropy 2.3008e+00 (2.2968e+00)\n",
            "Epoch: [2][125/390]\tTotal Loss -1.0471e+01 (-1.0353e+01)\tConsistency Loss 1.0108e+00 (1.1307e+00)\tEntropy 2.2963e+00 (2.2968e+00)\n",
            "Epoch: [2][150/390]\tTotal Loss -1.0493e+01 (-1.0358e+01)\tConsistency Loss 9.9536e-01 (1.1261e+00)\tEntropy 2.2977e+00 (2.2968e+00)\n",
            "Epoch: [2][175/390]\tTotal Loss -1.0372e+01 (-1.0355e+01)\tConsistency Loss 1.1262e+00 (1.1296e+00)\tEntropy 2.2997e+00 (2.2969e+00)\n",
            "Epoch: [2][200/390]\tTotal Loss -1.0323e+01 (-1.0354e+01)\tConsistency Loss 1.1624e+00 (1.1302e+00)\tEntropy 2.2971e+00 (2.2969e+00)\n",
            "Epoch: [2][225/390]\tTotal Loss -1.0454e+01 (-1.0355e+01)\tConsistency Loss 1.0451e+00 (1.1296e+00)\tEntropy 2.2998e+00 (2.2968e+00)\n",
            "Epoch: [2][250/390]\tTotal Loss -1.0188e+01 (-1.0356e+01)\tConsistency Loss 1.3013e+00 (1.1278e+00)\tEntropy 2.2978e+00 (2.2968e+00)\n",
            "Epoch: [2][275/390]\tTotal Loss -1.0521e+01 (-1.0356e+01)\tConsistency Loss 9.6863e-01 (1.1285e+00)\tEntropy 2.2980e+00 (2.2968e+00)\n",
            "Epoch: [2][300/390]\tTotal Loss -1.0413e+01 (-1.0357e+01)\tConsistency Loss 1.0696e+00 (1.1268e+00)\tEntropy 2.2965e+00 (2.2968e+00)\n",
            "Epoch: [2][325/390]\tTotal Loss -1.0556e+01 (-1.0360e+01)\tConsistency Loss 9.3905e-01 (1.1244e+00)\tEntropy 2.2989e+00 (2.2968e+00)\n",
            "Epoch: [2][350/390]\tTotal Loss -1.0544e+01 (-1.0361e+01)\tConsistency Loss 9.5247e-01 (1.1235e+00)\tEntropy 2.2993e+00 (2.2968e+00)\n",
            "Epoch: [2][375/390]\tTotal Loss -1.0550e+01 (-1.0364e+01)\tConsistency Loss 9.4425e-01 (1.1204e+00)\tEntropy 2.2988e+00 (2.2968e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.298189878463745, 'consistency': 0.7527008056640625, 'total_loss': -1.5454890727996826}], 'lowest_loss_head': 0, 'lowest_loss': -1.5454890727996826}\n",
            "New lowest loss on validation set: -1.5143 -> -1.5455\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6162, 'ARI': 0.42087535487988187, 'NMI': 0.5102277404814516, 'ACC Top-5': 0.9489, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 4/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [3][  0/390]\tTotal Loss -1.0394e+01 (-1.0394e+01)\tConsistency Loss 1.0991e+00 (1.0991e+00)\tEntropy 2.2987e+00 (2.2987e+00)\n",
            "Epoch: [3][ 25/390]\tTotal Loss -1.0303e+01 (-1.0378e+01)\tConsistency Loss 1.1827e+00 (1.1082e+00)\tEntropy 2.2971e+00 (2.2973e+00)\n",
            "Epoch: [3][ 50/390]\tTotal Loss -1.0256e+01 (-1.0361e+01)\tConsistency Loss 1.2282e+00 (1.1213e+00)\tEntropy 2.2969e+00 (2.2965e+00)\n",
            "Epoch: [3][ 75/390]\tTotal Loss -1.0306e+01 (-1.0374e+01)\tConsistency Loss 1.1605e+00 (1.1084e+00)\tEntropy 2.2933e+00 (2.2965e+00)\n",
            "Epoch: [3][100/390]\tTotal Loss -1.0468e+01 (-1.0376e+01)\tConsistency Loss 1.0260e+00 (1.1074e+00)\tEntropy 2.2989e+00 (2.2966e+00)\n",
            "Epoch: [3][125/390]\tTotal Loss -1.0443e+01 (-1.0376e+01)\tConsistency Loss 1.0471e+00 (1.1062e+00)\tEntropy 2.2980e+00 (2.2964e+00)\n",
            "Epoch: [3][150/390]\tTotal Loss -1.0502e+01 (-1.0384e+01)\tConsistency Loss 9.7212e-01 (1.0981e+00)\tEntropy 2.2949e+00 (2.2964e+00)\n",
            "Epoch: [3][175/390]\tTotal Loss -1.0514e+01 (-1.0389e+01)\tConsistency Loss 9.7441e-01 (1.0935e+00)\tEntropy 2.2977e+00 (2.2964e+00)\n",
            "Epoch: [3][200/390]\tTotal Loss -1.0378e+01 (-1.0391e+01)\tConsistency Loss 1.1039e+00 (1.0912e+00)\tEntropy 2.2964e+00 (2.2964e+00)\n",
            "Epoch: [3][225/390]\tTotal Loss -1.0369e+01 (-1.0396e+01)\tConsistency Loss 1.1157e+00 (1.0863e+00)\tEntropy 2.2970e+00 (2.2964e+00)\n",
            "Epoch: [3][250/390]\tTotal Loss -1.0438e+01 (-1.0395e+01)\tConsistency Loss 1.0336e+00 (1.0874e+00)\tEntropy 2.2944e+00 (2.2964e+00)\n",
            "Epoch: [3][275/390]\tTotal Loss -1.0302e+01 (-1.0395e+01)\tConsistency Loss 1.1673e+00 (1.0868e+00)\tEntropy 2.2939e+00 (2.2964e+00)\n",
            "Epoch: [3][300/390]\tTotal Loss -1.0183e+01 (-1.0395e+01)\tConsistency Loss 1.2963e+00 (1.0873e+00)\tEntropy 2.2958e+00 (2.2965e+00)\n",
            "Epoch: [3][325/390]\tTotal Loss -1.0264e+01 (-1.0395e+01)\tConsistency Loss 1.2176e+00 (1.0873e+00)\tEntropy 2.2962e+00 (2.2964e+00)\n",
            "Epoch: [3][350/390]\tTotal Loss -1.0402e+01 (-1.0397e+01)\tConsistency Loss 1.0776e+00 (1.0852e+00)\tEntropy 2.2960e+00 (2.2965e+00)\n",
            "Epoch: [3][375/390]\tTotal Loss -1.0434e+01 (-1.0395e+01)\tConsistency Loss 1.0672e+00 (1.0876e+00)\tEntropy 2.3003e+00 (2.2965e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.2963778972625732, 'consistency': 0.7357701659202576, 'total_loss': -1.5606077313423157}], 'lowest_loss_head': 0, 'lowest_loss': -1.5606077313423157}\n",
            "New lowest loss on validation set: -1.5455 -> -1.5606\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6185, 'ARI': 0.42335984949484967, 'NMI': 0.5169253550284002, 'ACC Top-5': 0.9328, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 8), (4, 3), (5, 0), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 5/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [4][  0/390]\tTotal Loss -1.0318e+01 (-1.0318e+01)\tConsistency Loss 1.1632e+00 (1.1632e+00)\tEntropy 2.2962e+00 (2.2962e+00)\n",
            "Epoch: [4][ 25/390]\tTotal Loss -1.0424e+01 (-1.0394e+01)\tConsistency Loss 1.0688e+00 (1.0898e+00)\tEntropy 2.2986e+00 (2.2968e+00)\n",
            "Epoch: [4][ 50/390]\tTotal Loss -1.0462e+01 (-1.0404e+01)\tConsistency Loss 1.0128e+00 (1.0787e+00)\tEntropy 2.2950e+00 (2.2965e+00)\n",
            "Epoch: [4][ 75/390]\tTotal Loss -1.0455e+01 (-1.0411e+01)\tConsistency Loss 1.0240e+00 (1.0707e+00)\tEntropy 2.2958e+00 (2.2964e+00)\n",
            "Epoch: [4][100/390]\tTotal Loss -1.0486e+01 (-1.0410e+01)\tConsistency Loss 9.9067e-01 (1.0716e+00)\tEntropy 2.2953e+00 (2.2964e+00)\n",
            "Epoch: [4][125/390]\tTotal Loss -1.0472e+01 (-1.0410e+01)\tConsistency Loss 9.7197e-01 (1.0709e+00)\tEntropy 2.2888e+00 (2.2962e+00)\n",
            "Epoch: [4][150/390]\tTotal Loss -1.0247e+01 (-1.0408e+01)\tConsistency Loss 1.1921e+00 (1.0734e+00)\tEntropy 2.2879e+00 (2.2962e+00)\n",
            "Epoch: [4][175/390]\tTotal Loss -1.0508e+01 (-1.0408e+01)\tConsistency Loss 9.7075e-01 (1.0729e+00)\tEntropy 2.2958e+00 (2.2962e+00)\n",
            "Epoch: [4][200/390]\tTotal Loss -1.0402e+01 (-1.0410e+01)\tConsistency Loss 1.0941e+00 (1.0713e+00)\tEntropy 2.2992e+00 (2.2962e+00)\n",
            "Epoch: [4][225/390]\tTotal Loss -1.0511e+01 (-1.0409e+01)\tConsistency Loss 9.7300e-01 (1.0722e+00)\tEntropy 2.2968e+00 (2.2962e+00)\n",
            "Epoch: [4][250/390]\tTotal Loss -1.0279e+01 (-1.0410e+01)\tConsistency Loss 1.2077e+00 (1.0703e+00)\tEntropy 2.2974e+00 (2.2961e+00)\n",
            "Epoch: [4][275/390]\tTotal Loss -1.0524e+01 (-1.0410e+01)\tConsistency Loss 9.6399e-01 (1.0706e+00)\tEntropy 2.2975e+00 (2.2960e+00)\n",
            "Epoch: [4][300/390]\tTotal Loss -1.0429e+01 (-1.0410e+01)\tConsistency Loss 1.0199e+00 (1.0700e+00)\tEntropy 2.2898e+00 (2.2961e+00)\n",
            "Epoch: [4][325/390]\tTotal Loss -1.0497e+01 (-1.0413e+01)\tConsistency Loss 1.0039e+00 (1.0670e+00)\tEntropy 2.3001e+00 (2.2961e+00)\n",
            "Epoch: [4][350/390]\tTotal Loss -1.0464e+01 (-1.0416e+01)\tConsistency Loss 1.0351e+00 (1.0644e+00)\tEntropy 2.2998e+00 (2.2960e+00)\n",
            "Epoch: [4][375/390]\tTotal Loss -1.0434e+01 (-1.0418e+01)\tConsistency Loss 1.0437e+00 (1.0624e+00)\tEntropy 2.2955e+00 (2.2961e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.3010427951812744, 'consistency': 0.7273049354553223, 'total_loss': -1.5737378597259521}], 'lowest_loss_head': 0, 'lowest_loss': -1.5737378597259521}\n",
            "New lowest loss on validation set: -1.5606 -> -1.5737\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6119, 'ARI': 0.4124476450783779, 'NMI': 0.5094496646690894, 'ACC Top-5': 0.937, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 8), (4, 3), (5, 0), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 6/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [5][  0/390]\tTotal Loss -1.0404e+01 (-1.0404e+01)\tConsistency Loss 1.0929e+00 (1.0929e+00)\tEntropy 2.2994e+00 (2.2994e+00)\n",
            "Epoch: [5][ 25/390]\tTotal Loss -1.0280e+01 (-1.0440e+01)\tConsistency Loss 1.2059e+00 (1.0451e+00)\tEntropy 2.2972e+00 (2.2970e+00)\n",
            "Epoch: [5][ 50/390]\tTotal Loss -1.0525e+01 (-1.0433e+01)\tConsistency Loss 9.5017e-01 (1.0483e+00)\tEntropy 2.2949e+00 (2.2962e+00)\n",
            "Epoch: [5][ 75/390]\tTotal Loss -1.0370e+01 (-1.0434e+01)\tConsistency Loss 1.1187e+00 (1.0475e+00)\tEntropy 2.2977e+00 (2.2962e+00)\n",
            "Epoch: [5][100/390]\tTotal Loss -1.0493e+01 (-1.0437e+01)\tConsistency Loss 1.0055e+00 (1.0447e+00)\tEntropy 2.2997e+00 (2.2963e+00)\n",
            "Epoch: [5][125/390]\tTotal Loss -1.0437e+01 (-1.0436e+01)\tConsistency Loss 1.0151e+00 (1.0455e+00)\tEntropy 2.2904e+00 (2.2962e+00)\n",
            "Epoch: [5][150/390]\tTotal Loss -1.0249e+01 (-1.0431e+01)\tConsistency Loss 1.2355e+00 (1.0498e+00)\tEntropy 2.2970e+00 (2.2963e+00)\n",
            "Epoch: [5][175/390]\tTotal Loss -1.0503e+01 (-1.0433e+01)\tConsistency Loss 9.8280e-01 (1.0479e+00)\tEntropy 2.2971e+00 (2.2962e+00)\n",
            "Epoch: [5][200/390]\tTotal Loss -1.0350e+01 (-1.0433e+01)\tConsistency Loss 1.1420e+00 (1.0483e+00)\tEntropy 2.2985e+00 (2.2962e+00)\n",
            "Epoch: [5][225/390]\tTotal Loss -1.0462e+01 (-1.0434e+01)\tConsistency Loss 1.0211e+00 (1.0473e+00)\tEntropy 2.2967e+00 (2.2962e+00)\n",
            "Epoch: [5][250/390]\tTotal Loss -1.0404e+01 (-1.0432e+01)\tConsistency Loss 1.0954e+00 (1.0488e+00)\tEntropy 2.2999e+00 (2.2962e+00)\n",
            "Epoch: [5][275/390]\tTotal Loss -1.0538e+01 (-1.0434e+01)\tConsistency Loss 9.4919e-01 (1.0470e+00)\tEntropy 2.2975e+00 (2.2962e+00)\n",
            "Epoch: [5][300/390]\tTotal Loss -1.0366e+01 (-1.0434e+01)\tConsistency Loss 1.1055e+00 (1.0469e+00)\tEntropy 2.2942e+00 (2.2962e+00)\n",
            "Epoch: [5][325/390]\tTotal Loss -1.0378e+01 (-1.0435e+01)\tConsistency Loss 1.1127e+00 (1.0457e+00)\tEntropy 2.2982e+00 (2.2962e+00)\n",
            "Epoch: [5][350/390]\tTotal Loss -1.0418e+01 (-1.0436e+01)\tConsistency Loss 1.0401e+00 (1.0454e+00)\tEntropy 2.2917e+00 (2.2963e+00)\n",
            "Epoch: [5][375/390]\tTotal Loss -1.0432e+01 (-1.0437e+01)\tConsistency Loss 1.0654e+00 (1.0437e+00)\tEntropy 2.2995e+00 (2.2962e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.2989683151245117, 'consistency': 0.7220466136932373, 'total_loss': -1.5769217014312744}], 'lowest_loss_head': 0, 'lowest_loss': -1.5769217014312744}\n",
            "New lowest loss on validation set: -1.5737 -> -1.5769\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6106, 'ARI': 0.4189214291732467, 'NMI': 0.5130446087559488, 'ACC Top-5': 0.9412, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 7/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [6][  0/390]\tTotal Loss -1.0438e+01 (-1.0438e+01)\tConsistency Loss 1.0277e+00 (1.0277e+00)\tEntropy 2.2931e+00 (2.2931e+00)\n",
            "Epoch: [6][ 25/390]\tTotal Loss -1.0513e+01 (-1.0483e+01)\tConsistency Loss 9.6603e-01 (1.0022e+00)\tEntropy 2.2958e+00 (2.2970e+00)\n",
            "Epoch: [6][ 50/390]\tTotal Loss -1.0385e+01 (-1.0470e+01)\tConsistency Loss 1.0947e+00 (1.0126e+00)\tEntropy 2.2960e+00 (2.2965e+00)\n",
            "Epoch: [6][ 75/390]\tTotal Loss -1.0359e+01 (-1.0441e+01)\tConsistency Loss 1.0861e+00 (1.0373e+00)\tEntropy 2.2890e+00 (2.2957e+00)\n",
            "Epoch: [6][100/390]\tTotal Loss -1.0586e+01 (-1.0440e+01)\tConsistency Loss 8.7323e-01 (1.0392e+00)\tEntropy 2.2918e+00 (2.2959e+00)\n",
            "Epoch: [6][125/390]\tTotal Loss -1.0268e+01 (-1.0447e+01)\tConsistency Loss 1.1941e+00 (1.0329e+00)\tEntropy 2.2924e+00 (2.2960e+00)\n",
            "Epoch: [6][150/390]\tTotal Loss -1.0401e+01 (-1.0443e+01)\tConsistency Loss 1.0674e+00 (1.0370e+00)\tEntropy 2.2936e+00 (2.2961e+00)\n",
            "Epoch: [6][175/390]\tTotal Loss -1.0417e+01 (-1.0439e+01)\tConsistency Loss 1.0681e+00 (1.0414e+00)\tEntropy 2.2971e+00 (2.2961e+00)\n",
            "Epoch: [6][200/390]\tTotal Loss -1.0395e+01 (-1.0441e+01)\tConsistency Loss 1.0828e+00 (1.0395e+00)\tEntropy 2.2957e+00 (2.2961e+00)\n",
            "Epoch: [6][225/390]\tTotal Loss -1.0411e+01 (-1.0441e+01)\tConsistency Loss 1.0674e+00 (1.0393e+00)\tEntropy 2.2957e+00 (2.2961e+00)\n",
            "Epoch: [6][250/390]\tTotal Loss -1.0345e+01 (-1.0442e+01)\tConsistency Loss 1.0877e+00 (1.0381e+00)\tEntropy 2.2866e+00 (2.2961e+00)\n",
            "Epoch: [6][275/390]\tTotal Loss -1.0344e+01 (-1.0443e+01)\tConsistency Loss 1.1058e+00 (1.0377e+00)\tEntropy 2.2900e+00 (2.2961e+00)\n",
            "Epoch: [6][300/390]\tTotal Loss -1.0457e+01 (-1.0444e+01)\tConsistency Loss 1.0366e+00 (1.0365e+00)\tEntropy 2.2987e+00 (2.2961e+00)\n",
            "Epoch: [6][325/390]\tTotal Loss -1.0421e+01 (-1.0444e+01)\tConsistency Loss 1.0741e+00 (1.0363e+00)\tEntropy 2.2991e+00 (2.2960e+00)\n",
            "Epoch: [6][350/390]\tTotal Loss -1.0382e+01 (-1.0444e+01)\tConsistency Loss 1.1030e+00 (1.0355e+00)\tEntropy 2.2971e+00 (2.2960e+00)\n",
            "Epoch: [6][375/390]\tTotal Loss -1.0345e+01 (-1.0446e+01)\tConsistency Loss 1.1341e+00 (1.0343e+00)\tEntropy 2.2958e+00 (2.2960e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.296900510787964, 'consistency': 0.7131608128547668, 'total_loss': -1.583739697933197}], 'lowest_loss_head': 0, 'lowest_loss': -1.583739697933197}\n",
            "New lowest loss on validation set: -1.5769 -> -1.5837\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6377, 'ARI': 0.4264408625693443, 'NMI': 0.5216185360887736, 'ACC Top-5': 0.9412, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 8), (4, 3), (5, 0), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 8/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [7][  0/390]\tTotal Loss -1.0471e+01 (-1.0471e+01)\tConsistency Loss 1.0035e+00 (1.0035e+00)\tEntropy 2.2949e+00 (2.2949e+00)\n",
            "Epoch: [7][ 25/390]\tTotal Loss -1.0514e+01 (-1.0479e+01)\tConsistency Loss 9.5747e-01 (9.9891e-01)\tEntropy 2.2943e+00 (2.2955e+00)\n",
            "Epoch: [7][ 50/390]\tTotal Loss -1.0367e+01 (-1.0472e+01)\tConsistency Loss 1.0670e+00 (1.0066e+00)\tEntropy 2.2868e+00 (2.2957e+00)\n",
            "Epoch: [7][ 75/390]\tTotal Loss -1.0573e+01 (-1.0462e+01)\tConsistency Loss 9.1737e-01 (1.0179e+00)\tEntropy 2.2981e+00 (2.2959e+00)\n",
            "Epoch: [7][100/390]\tTotal Loss -1.0449e+01 (-1.0466e+01)\tConsistency Loss 1.0428e+00 (1.0140e+00)\tEntropy 2.2984e+00 (2.2961e+00)\n",
            "Epoch: [7][125/390]\tTotal Loss -1.0491e+01 (-1.0467e+01)\tConsistency Loss 9.8833e-01 (1.0139e+00)\tEntropy 2.2958e+00 (2.2962e+00)\n",
            "Epoch: [7][150/390]\tTotal Loss -1.0341e+01 (-1.0461e+01)\tConsistency Loss 1.1297e+00 (1.0204e+00)\tEntropy 2.2941e+00 (2.2962e+00)\n",
            "Epoch: [7][175/390]\tTotal Loss -1.0478e+01 (-1.0460e+01)\tConsistency Loss 1.0178e+00 (1.0207e+00)\tEntropy 2.2993e+00 (2.2962e+00)\n",
            "Epoch: [7][200/390]\tTotal Loss -1.0427e+01 (-1.0462e+01)\tConsistency Loss 1.0666e+00 (1.0193e+00)\tEntropy 2.2987e+00 (2.2963e+00)\n",
            "Epoch: [7][225/390]\tTotal Loss -1.0569e+01 (-1.0461e+01)\tConsistency Loss 9.3496e-01 (1.0203e+00)\tEntropy 2.3008e+00 (2.2962e+00)\n",
            "Epoch: [7][250/390]\tTotal Loss -1.0493e+01 (-1.0461e+01)\tConsistency Loss 9.8759e-01 (1.0202e+00)\tEntropy 2.2961e+00 (2.2962e+00)\n",
            "Epoch: [7][275/390]\tTotal Loss -1.0455e+01 (-1.0460e+01)\tConsistency Loss 1.0349e+00 (1.0213e+00)\tEntropy 2.2980e+00 (2.2963e+00)\n",
            "Epoch: [7][300/390]\tTotal Loss -1.0467e+01 (-1.0460e+01)\tConsistency Loss 1.0172e+00 (1.0216e+00)\tEntropy 2.2968e+00 (2.2963e+00)\n",
            "Epoch: [7][325/390]\tTotal Loss -1.0586e+01 (-1.0460e+01)\tConsistency Loss 9.1817e-01 (1.0218e+00)\tEntropy 2.3009e+00 (2.2964e+00)\n",
            "Epoch: [7][350/390]\tTotal Loss -1.0447e+01 (-1.0460e+01)\tConsistency Loss 1.0379e+00 (1.0217e+00)\tEntropy 2.2970e+00 (2.2964e+00)\n",
            "Epoch: [7][375/390]\tTotal Loss -1.0435e+01 (-1.0459e+01)\tConsistency Loss 1.0458e+00 (1.0228e+00)\tEntropy 2.2962e+00 (2.2964e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.2975947856903076, 'consistency': 0.7117058038711548, 'total_loss': -1.5858889818191528}], 'lowest_loss_head': 0, 'lowest_loss': -1.5858889818191528}\n",
            "New lowest loss on validation set: -1.5837 -> -1.5859\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6152, 'ARI': 0.4166848434676041, 'NMI': 0.5137876113228717, 'ACC Top-5': 0.9336, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 8), (4, 3), (5, 0), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 9/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [8][  0/390]\tTotal Loss -1.0700e+01 (-1.0700e+01)\tConsistency Loss 7.9698e-01 (7.9698e-01)\tEntropy 2.2994e+00 (2.2994e+00)\n",
            "Epoch: [8][ 25/390]\tTotal Loss -1.0542e+01 (-1.0492e+01)\tConsistency Loss 9.4579e-01 (9.8708e-01)\tEntropy 2.2975e+00 (2.2959e+00)\n",
            "Epoch: [8][ 50/390]\tTotal Loss -1.0217e+01 (-1.0474e+01)\tConsistency Loss 1.2514e+00 (1.0044e+00)\tEntropy 2.2936e+00 (2.2957e+00)\n",
            "Epoch: [8][ 75/390]\tTotal Loss -1.0277e+01 (-1.0471e+01)\tConsistency Loss 1.2247e+00 (1.0090e+00)\tEntropy 2.3004e+00 (2.2959e+00)\n",
            "Epoch: [8][100/390]\tTotal Loss -1.0416e+01 (-1.0465e+01)\tConsistency Loss 1.0707e+00 (1.0159e+00)\tEntropy 2.2973e+00 (2.2962e+00)\n",
            "Epoch: [8][125/390]\tTotal Loss -1.0503e+01 (-1.0467e+01)\tConsistency Loss 9.3627e-01 (1.0132e+00)\tEntropy 2.2878e+00 (2.2961e+00)\n",
            "Epoch: [8][150/390]\tTotal Loss -1.0266e+01 (-1.0467e+01)\tConsistency Loss 1.1999e+00 (1.0130e+00)\tEntropy 2.2932e+00 (2.2961e+00)\n",
            "Epoch: [8][175/390]\tTotal Loss -1.0523e+01 (-1.0467e+01)\tConsistency Loss 9.5913e-01 (1.0139e+00)\tEntropy 2.2965e+00 (2.2962e+00)\n",
            "Epoch: [8][200/390]\tTotal Loss -1.0485e+01 (-1.0466e+01)\tConsistency Loss 9.8270e-01 (1.0157e+00)\tEntropy 2.2936e+00 (2.2963e+00)\n",
            "Epoch: [8][225/390]\tTotal Loss -1.0486e+01 (-1.0466e+01)\tConsistency Loss 1.0038e+00 (1.0154e+00)\tEntropy 2.2980e+00 (2.2963e+00)\n",
            "Epoch: [8][250/390]\tTotal Loss -1.0555e+01 (-1.0467e+01)\tConsistency Loss 9.3655e-01 (1.0139e+00)\tEntropy 2.2984e+00 (2.2963e+00)\n",
            "Epoch: [8][275/390]\tTotal Loss -1.0392e+01 (-1.0467e+01)\tConsistency Loss 1.0788e+00 (1.0135e+00)\tEntropy 2.2942e+00 (2.2962e+00)\n",
            "Epoch: [8][300/390]\tTotal Loss -1.0437e+01 (-1.0467e+01)\tConsistency Loss 1.0333e+00 (1.0143e+00)\tEntropy 2.2940e+00 (2.2962e+00)\n",
            "Epoch: [8][325/390]\tTotal Loss -1.0536e+01 (-1.0468e+01)\tConsistency Loss 9.5639e-01 (1.0133e+00)\tEntropy 2.2984e+00 (2.2963e+00)\n",
            "Epoch: [8][350/390]\tTotal Loss -1.0330e+01 (-1.0466e+01)\tConsistency Loss 1.1251e+00 (1.0154e+00)\tEntropy 2.2911e+00 (2.2962e+00)\n",
            "Epoch: [8][375/390]\tTotal Loss -1.0491e+01 (-1.0468e+01)\tConsistency Loss 9.8992e-01 (1.0133e+00)\tEntropy 2.2962e+00 (2.2963e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.2970404624938965, 'consistency': 0.7189801335334778, 'total_loss': -1.5780603289604187}], 'lowest_loss_head': 0, 'lowest_loss': -1.5780603289604187}\n",
            "No new lowest loss on validation set: -1.5859 -> -1.5781\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6166, 'ARI': 0.41746176848316596, 'NMI': 0.5158149862732391, 'ACC Top-5': 0.9368, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 8), (4, 3), (5, 0), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 10/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [9][  0/390]\tTotal Loss -1.0596e+01 (-1.0596e+01)\tConsistency Loss 9.0356e-01 (9.0356e-01)\tEntropy 2.2999e+00 (2.2999e+00)\n",
            "Epoch: [9][ 25/390]\tTotal Loss -1.0453e+01 (-1.0446e+01)\tConsistency Loss 1.0323e+00 (1.0289e+00)\tEntropy 2.2970e+00 (2.2950e+00)\n",
            "Epoch: [9][ 50/390]\tTotal Loss -1.0560e+01 (-1.0475e+01)\tConsistency Loss 8.9476e-01 (1.0042e+00)\tEntropy 2.2909e+00 (2.2958e+00)\n",
            "Epoch: [9][ 75/390]\tTotal Loss -1.0502e+01 (-1.0475e+01)\tConsistency Loss 9.8825e-01 (1.0061e+00)\tEntropy 2.2981e+00 (2.2962e+00)\n",
            "Epoch: [9][100/390]\tTotal Loss -1.0587e+01 (-1.0475e+01)\tConsistency Loss 9.0092e-01 (1.0067e+00)\tEntropy 2.2976e+00 (2.2963e+00)\n",
            "Epoch: [9][125/390]\tTotal Loss -1.0548e+01 (-1.0471e+01)\tConsistency Loss 9.3706e-01 (1.0109e+00)\tEntropy 2.2969e+00 (2.2965e+00)\n",
            "Epoch: [9][150/390]\tTotal Loss -1.0500e+01 (-1.0474e+01)\tConsistency Loss 9.7296e-01 (1.0082e+00)\tEntropy 2.2946e+00 (2.2965e+00)\n",
            "Epoch: [9][175/390]\tTotal Loss -1.0594e+01 (-1.0476e+01)\tConsistency Loss 9.1056e-01 (1.0070e+00)\tEntropy 2.3009e+00 (2.2965e+00)\n",
            "Epoch: [9][200/390]\tTotal Loss -1.0457e+01 (-1.0477e+01)\tConsistency Loss 1.0214e+00 (1.0057e+00)\tEntropy 2.2957e+00 (2.2965e+00)\n",
            "Epoch: [9][225/390]\tTotal Loss -1.0455e+01 (-1.0477e+01)\tConsistency Loss 1.0253e+00 (1.0055e+00)\tEntropy 2.2960e+00 (2.2966e+00)\n",
            "Epoch: [9][250/390]\tTotal Loss -1.0410e+01 (-1.0479e+01)\tConsistency Loss 1.0886e+00 (1.0033e+00)\tEntropy 2.2997e+00 (2.2965e+00)\n",
            "Epoch: [9][275/390]\tTotal Loss -1.0423e+01 (-1.0478e+01)\tConsistency Loss 1.0718e+00 (1.0044e+00)\tEntropy 2.2989e+00 (2.2964e+00)\n",
            "Epoch: [9][300/390]\tTotal Loss -1.0579e+01 (-1.0479e+01)\tConsistency Loss 9.0879e-01 (1.0028e+00)\tEntropy 2.2975e+00 (2.2964e+00)\n",
            "Epoch: [9][325/390]\tTotal Loss -1.0427e+01 (-1.0480e+01)\tConsistency Loss 1.0610e+00 (1.0026e+00)\tEntropy 2.2977e+00 (2.2965e+00)\n",
            "Epoch: [9][350/390]\tTotal Loss -1.0493e+01 (-1.0481e+01)\tConsistency Loss 9.9747e-01 (1.0017e+00)\tEntropy 2.2980e+00 (2.2964e+00)\n",
            "Epoch: [9][375/390]\tTotal Loss -1.0610e+01 (-1.0481e+01)\tConsistency Loss 8.8420e-01 (1.0008e+00)\tEntropy 2.2988e+00 (2.2964e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.2975211143493652, 'consistency': 0.7137712240219116, 'total_loss': -1.5837498903274536}], 'lowest_loss_head': 0, 'lowest_loss': -1.5837498903274536}\n",
            "No new lowest loss on validation set: -1.5859 -> -1.5837\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6153, 'ARI': 0.4244172666908215, 'NMI': 0.5171961480466161, 'ACC Top-5': 0.9391, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 11/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [10][  0/390]\tTotal Loss -1.0419e+01 (-1.0419e+01)\tConsistency Loss 1.0687e+00 (1.0687e+00)\tEntropy 2.2976e+00 (2.2976e+00)\n",
            "Epoch: [10][ 25/390]\tTotal Loss -1.0486e+01 (-1.0453e+01)\tConsistency Loss 1.0026e+00 (1.0274e+00)\tEntropy 2.2977e+00 (2.2960e+00)\n",
            "Epoch: [10][ 50/390]\tTotal Loss -1.0600e+01 (-1.0474e+01)\tConsistency Loss 8.9632e-01 (1.0055e+00)\tEntropy 2.2993e+00 (2.2959e+00)\n",
            "Epoch: [10][ 75/390]\tTotal Loss -1.0583e+01 (-1.0472e+01)\tConsistency Loss 9.1535e-01 (1.0091e+00)\tEntropy 2.2997e+00 (2.2962e+00)\n",
            "Epoch: [10][100/390]\tTotal Loss -1.0489e+01 (-1.0465e+01)\tConsistency Loss 9.9576e-01 (1.0149e+00)\tEntropy 2.2970e+00 (2.2960e+00)\n",
            "Epoch: [10][125/390]\tTotal Loss -1.0633e+01 (-1.0474e+01)\tConsistency Loss 8.4228e-01 (1.0058e+00)\tEntropy 2.2951e+00 (2.2960e+00)\n",
            "Epoch: [10][150/390]\tTotal Loss -1.0348e+01 (-1.0473e+01)\tConsistency Loss 1.1384e+00 (1.0064e+00)\tEntropy 2.2972e+00 (2.2960e+00)\n",
            "Epoch: [10][175/390]\tTotal Loss -1.0435e+01 (-1.0476e+01)\tConsistency Loss 1.0356e+00 (1.0034e+00)\tEntropy 2.2942e+00 (2.2960e+00)\n",
            "Epoch: [10][200/390]\tTotal Loss -1.0630e+01 (-1.0478e+01)\tConsistency Loss 8.4460e-01 (1.0021e+00)\tEntropy 2.2949e+00 (2.2961e+00)\n",
            "Epoch: [10][225/390]\tTotal Loss -1.0479e+01 (-1.0481e+01)\tConsistency Loss 1.0026e+00 (9.9907e-01)\tEntropy 2.2962e+00 (2.2960e+00)\n",
            "Epoch: [10][250/390]\tTotal Loss -1.0537e+01 (-1.0482e+01)\tConsistency Loss 9.6105e-01 (9.9765e-01)\tEntropy 2.2996e+00 (2.2960e+00)\n",
            "Epoch: [10][275/390]\tTotal Loss -1.0480e+01 (-1.0483e+01)\tConsistency Loss 1.0153e+00 (9.9710e-01)\tEntropy 2.2991e+00 (2.2960e+00)\n",
            "Epoch: [10][300/390]\tTotal Loss -1.0376e+01 (-1.0484e+01)\tConsistency Loss 1.0925e+00 (9.9602e-01)\tEntropy 2.2936e+00 (2.2960e+00)\n",
            "Epoch: [10][325/390]\tTotal Loss -1.0537e+01 (-1.0486e+01)\tConsistency Loss 9.5000e-01 (9.9493e-01)\tEntropy 2.2975e+00 (2.2961e+00)\n",
            "Epoch: [10][350/390]\tTotal Loss -1.0545e+01 (-1.0486e+01)\tConsistency Loss 9.4256e-01 (9.9512e-01)\tEntropy 2.2976e+00 (2.2962e+00)\n",
            "Epoch: [10][375/390]\tTotal Loss -1.0492e+01 (-1.0486e+01)\tConsistency Loss 9.5028e-01 (9.9537e-01)\tEntropy 2.2884e+00 (2.2962e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.3003175258636475, 'consistency': 0.7024412751197815, 'total_loss': -1.597876250743866}], 'lowest_loss_head': 0, 'lowest_loss': -1.597876250743866}\n",
            "New lowest loss on validation set: -1.5859 -> -1.5979\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6224, 'ARI': 0.4307754453928074, 'NMI': 0.5217161458053372, 'ACC Top-5': 0.943, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 12/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [11][  0/390]\tTotal Loss -1.0334e+01 (-1.0334e+01)\tConsistency Loss 1.1220e+00 (1.1220e+00)\tEntropy 2.2913e+00 (2.2913e+00)\n",
            "Epoch: [11][ 25/390]\tTotal Loss -1.0482e+01 (-1.0482e+01)\tConsistency Loss 9.8815e-01 (1.0015e+00)\tEntropy 2.2940e+00 (2.2968e+00)\n",
            "Epoch: [11][ 50/390]\tTotal Loss -1.0567e+01 (-1.0499e+01)\tConsistency Loss 9.0412e-01 (9.8573e-01)\tEntropy 2.2942e+00 (2.2969e+00)\n",
            "Epoch: [11][ 75/390]\tTotal Loss -1.0521e+01 (-1.0500e+01)\tConsistency Loss 9.8482e-01 (9.8183e-01)\tEntropy 2.3011e+00 (2.2964e+00)\n",
            "Epoch: [11][100/390]\tTotal Loss -1.0417e+01 (-1.0507e+01)\tConsistency Loss 1.0726e+00 (9.7530e-01)\tEntropy 2.2979e+00 (2.2964e+00)\n",
            "Epoch: [11][125/390]\tTotal Loss -1.0515e+01 (-1.0504e+01)\tConsistency Loss 9.7545e-01 (9.7714e-01)\tEntropy 2.2982e+00 (2.2963e+00)\n",
            "Epoch: [11][150/390]\tTotal Loss -1.0523e+01 (-1.0501e+01)\tConsistency Loss 9.5309e-01 (9.8157e-01)\tEntropy 2.2952e+00 (2.2965e+00)\n",
            "Epoch: [11][175/390]\tTotal Loss -1.0614e+01 (-1.0501e+01)\tConsistency Loss 8.6039e-01 (9.8120e-01)\tEntropy 2.2949e+00 (2.2965e+00)\n",
            "Epoch: [11][200/390]\tTotal Loss -1.0491e+01 (-1.0495e+01)\tConsistency Loss 1.0091e+00 (9.8679e-01)\tEntropy 2.3000e+00 (2.2964e+00)\n",
            "Epoch: [11][225/390]\tTotal Loss -1.0487e+01 (-1.0497e+01)\tConsistency Loss 9.7443e-01 (9.8544e-01)\tEntropy 2.2923e+00 (2.2965e+00)\n",
            "Epoch: [11][250/390]\tTotal Loss -1.0532e+01 (-1.0497e+01)\tConsistency Loss 9.4066e-01 (9.8524e-01)\tEntropy 2.2945e+00 (2.2964e+00)\n",
            "Epoch: [11][275/390]\tTotal Loss -1.0450e+01 (-1.0496e+01)\tConsistency Loss 1.0450e+00 (9.8630e-01)\tEntropy 2.2989e+00 (2.2965e+00)\n",
            "Epoch: [11][300/390]\tTotal Loss -1.0428e+01 (-1.0497e+01)\tConsistency Loss 1.0499e+00 (9.8557e-01)\tEntropy 2.2956e+00 (2.2965e+00)\n",
            "Epoch: [11][325/390]\tTotal Loss -1.0548e+01 (-1.0498e+01)\tConsistency Loss 9.4461e-01 (9.8415e-01)\tEntropy 2.2986e+00 (2.2965e+00)\n",
            "Epoch: [11][350/390]\tTotal Loss -1.0577e+01 (-1.0498e+01)\tConsistency Loss 8.9688e-01 (9.8492e-01)\tEntropy 2.2948e+00 (2.2965e+00)\n",
            "Epoch: [11][375/390]\tTotal Loss -1.0516e+01 (-1.0496e+01)\tConsistency Loss 9.7678e-01 (9.8656e-01)\tEntropy 2.2986e+00 (2.2965e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.2966723442077637, 'consistency': 0.6936085224151611, 'total_loss': -1.6030638217926025}], 'lowest_loss_head': 0, 'lowest_loss': -1.6030638217926025}\n",
            "New lowest loss on validation set: -1.5979 -> -1.6031\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6142, 'ARI': 0.4241371191221226, 'NMI': 0.5153865876592083, 'ACC Top-5': 0.9214, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 13/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [12][  0/390]\tTotal Loss -1.0425e+01 (-1.0425e+01)\tConsistency Loss 1.0631e+00 (1.0631e+00)\tEntropy 2.2977e+00 (2.2977e+00)\n",
            "Epoch: [12][ 25/390]\tTotal Loss -1.0510e+01 (-1.0497e+01)\tConsistency Loss 9.7747e-01 (9.8266e-01)\tEntropy 2.2975e+00 (2.2958e+00)\n",
            "Epoch: [12][ 50/390]\tTotal Loss -1.0333e+01 (-1.0499e+01)\tConsistency Loss 1.1534e+00 (9.8045e-01)\tEntropy 2.2972e+00 (2.2959e+00)\n",
            "Epoch: [12][ 75/390]\tTotal Loss -1.0553e+01 (-1.0499e+01)\tConsistency Loss 9.2011e-01 (9.8212e-01)\tEntropy 2.2946e+00 (2.2961e+00)\n",
            "Epoch: [12][100/390]\tTotal Loss -1.0461e+01 (-1.0494e+01)\tConsistency Loss 9.8947e-01 (9.8707e-01)\tEntropy 2.2900e+00 (2.2962e+00)\n",
            "Epoch: [12][125/390]\tTotal Loss -1.0351e+01 (-1.0489e+01)\tConsistency Loss 1.1312e+00 (9.9199e-01)\tEntropy 2.2964e+00 (2.2963e+00)\n",
            "Epoch: [12][150/390]\tTotal Loss -1.0643e+01 (-1.0491e+01)\tConsistency Loss 8.3707e-01 (9.9019e-01)\tEntropy 2.2960e+00 (2.2963e+00)\n",
            "Epoch: [12][175/390]\tTotal Loss -1.0477e+01 (-1.0489e+01)\tConsistency Loss 1.0048e+00 (9.9280e-01)\tEntropy 2.2963e+00 (2.2964e+00)\n",
            "Epoch: [12][200/390]\tTotal Loss -1.0558e+01 (-1.0492e+01)\tConsistency Loss 9.3754e-01 (9.8933e-01)\tEntropy 2.2991e+00 (2.2964e+00)\n",
            "Epoch: [12][225/390]\tTotal Loss -1.0505e+01 (-1.0496e+01)\tConsistency Loss 9.7690e-01 (9.8492e-01)\tEntropy 2.2963e+00 (2.2962e+00)\n",
            "Epoch: [12][250/390]\tTotal Loss -1.0597e+01 (-1.0497e+01)\tConsistency Loss 8.9272e-01 (9.8465e-01)\tEntropy 2.2979e+00 (2.2962e+00)\n",
            "Epoch: [12][275/390]\tTotal Loss -1.0595e+01 (-1.0497e+01)\tConsistency Loss 8.6149e-01 (9.8457e-01)\tEntropy 2.2912e+00 (2.2963e+00)\n",
            "Epoch: [12][300/390]\tTotal Loss -1.0630e+01 (-1.0495e+01)\tConsistency Loss 8.4630e-01 (9.8613e-01)\tEntropy 2.2953e+00 (2.2962e+00)\n",
            "Epoch: [12][325/390]\tTotal Loss -1.0472e+01 (-1.0496e+01)\tConsistency Loss 9.8522e-01 (9.8498e-01)\tEntropy 2.2914e+00 (2.2962e+00)\n",
            "Epoch: [12][350/390]\tTotal Loss -1.0449e+01 (-1.0497e+01)\tConsistency Loss 1.0125e+00 (9.8378e-01)\tEntropy 2.2924e+00 (2.2962e+00)\n",
            "Epoch: [12][375/390]\tTotal Loss -1.0472e+01 (-1.0500e+01)\tConsistency Loss 9.9935e-01 (9.8088e-01)\tEntropy 2.2942e+00 (2.2962e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.296665906906128, 'consistency': 0.6974533796310425, 'total_loss': -1.5992125272750854}], 'lowest_loss_head': 0, 'lowest_loss': -1.5992125272750854}\n",
            "No new lowest loss on validation set: -1.6031 -> -1.5992\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6203, 'ARI': 0.43057228540068765, 'NMI': 0.5205036950185075, 'ACC Top-5': 0.9304, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 14/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [13][  0/390]\tTotal Loss -1.0502e+01 (-1.0502e+01)\tConsistency Loss 9.9122e-01 (9.9122e-01)\tEntropy 2.2985e+00 (2.2985e+00)\n",
            "Epoch: [13][ 25/390]\tTotal Loss -1.0518e+01 (-1.0474e+01)\tConsistency Loss 9.7251e-01 (1.0067e+00)\tEntropy 2.2981e+00 (2.2962e+00)\n",
            "Epoch: [13][ 50/390]\tTotal Loss -1.0350e+01 (-1.0471e+01)\tConsistency Loss 1.1372e+00 (1.0131e+00)\tEntropy 2.2974e+00 (2.2968e+00)\n",
            "Epoch: [13][ 75/390]\tTotal Loss -1.0544e+01 (-1.0480e+01)\tConsistency Loss 9.3629e-01 (1.0033e+00)\tEntropy 2.2961e+00 (2.2966e+00)\n",
            "Epoch: [13][100/390]\tTotal Loss -1.0376e+01 (-1.0489e+01)\tConsistency Loss 1.0854e+00 (9.9373e-01)\tEntropy 2.2923e+00 (2.2966e+00)\n",
            "Epoch: [13][125/390]\tTotal Loss -1.0374e+01 (-1.0492e+01)\tConsistency Loss 1.0970e+00 (9.8981e-01)\tEntropy 2.2942e+00 (2.2963e+00)\n",
            "Epoch: [13][150/390]\tTotal Loss -1.0525e+01 (-1.0492e+01)\tConsistency Loss 9.8168e-01 (9.8958e-01)\tEntropy 2.3013e+00 (2.2963e+00)\n",
            "Epoch: [13][175/390]\tTotal Loss -1.0470e+01 (-1.0492e+01)\tConsistency Loss 9.9641e-01 (9.9014e-01)\tEntropy 2.2932e+00 (2.2964e+00)\n",
            "Epoch: [13][200/390]\tTotal Loss -1.0505e+01 (-1.0493e+01)\tConsistency Loss 9.8807e-01 (9.8903e-01)\tEntropy 2.2986e+00 (2.2965e+00)\n",
            "Epoch: [13][225/390]\tTotal Loss -1.0442e+01 (-1.0495e+01)\tConsistency Loss 1.0398e+00 (9.8781e-01)\tEntropy 2.2964e+00 (2.2965e+00)\n",
            "Epoch: [13][250/390]\tTotal Loss -1.0473e+01 (-1.0497e+01)\tConsistency Loss 1.0069e+00 (9.8543e-01)\tEntropy 2.2961e+00 (2.2965e+00)\n",
            "Epoch: [13][275/390]\tTotal Loss -1.0396e+01 (-1.0495e+01)\tConsistency Loss 1.0792e+00 (9.8737e-01)\tEntropy 2.2950e+00 (2.2965e+00)\n",
            "Epoch: [13][300/390]\tTotal Loss -1.0692e+01 (-1.0496e+01)\tConsistency Loss 7.8128e-01 (9.8638e-01)\tEntropy 2.2946e+00 (2.2965e+00)\n",
            "Epoch: [13][325/390]\tTotal Loss -1.0558e+01 (-1.0496e+01)\tConsistency Loss 9.2766e-01 (9.8591e-01)\tEntropy 2.2971e+00 (2.2964e+00)\n",
            "Epoch: [13][350/390]\tTotal Loss -1.0546e+01 (-1.0497e+01)\tConsistency Loss 9.3826e-01 (9.8484e-01)\tEntropy 2.2969e+00 (2.2964e+00)\n",
            "Epoch: [13][375/390]\tTotal Loss -1.0501e+01 (-1.0499e+01)\tConsistency Loss 9.7015e-01 (9.8347e-01)\tEntropy 2.2942e+00 (2.2965e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.3007078170776367, 'consistency': 0.7001842260360718, 'total_loss': -1.600523591041565}], 'lowest_loss_head': 0, 'lowest_loss': -1.600523591041565}\n",
            "No new lowest loss on validation set: -1.6031 -> -1.6005\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6218, 'ARI': 0.4305292381541232, 'NMI': 0.5233301030987705, 'ACC Top-5': 0.9354, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 15/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [14][  0/390]\tTotal Loss -1.0471e+01 (-1.0471e+01)\tConsistency Loss 1.0113e+00 (1.0113e+00)\tEntropy 2.2964e+00 (2.2964e+00)\n",
            "Epoch: [14][ 25/390]\tTotal Loss -1.0594e+01 (-1.0532e+01)\tConsistency Loss 8.8682e-01 (9.5034e-01)\tEntropy 2.2961e+00 (2.2964e+00)\n",
            "Epoch: [14][ 50/390]\tTotal Loss -1.0252e+01 (-1.0528e+01)\tConsistency Loss 1.1968e+00 (9.5348e-01)\tEntropy 2.2897e+00 (2.2962e+00)\n",
            "Epoch: [14][ 75/390]\tTotal Loss -1.0396e+01 (-1.0516e+01)\tConsistency Loss 1.0621e+00 (9.6583e-01)\tEntropy 2.2917e+00 (2.2964e+00)\n",
            "Epoch: [14][100/390]\tTotal Loss -1.0436e+01 (-1.0519e+01)\tConsistency Loss 1.0515e+00 (9.6222e-01)\tEntropy 2.2975e+00 (2.2963e+00)\n",
            "Epoch: [14][125/390]\tTotal Loss -1.0559e+01 (-1.0522e+01)\tConsistency Loss 9.0774e-01 (9.5952e-01)\tEntropy 2.2934e+00 (2.2962e+00)\n",
            "Epoch: [14][150/390]\tTotal Loss -1.0388e+01 (-1.0520e+01)\tConsistency Loss 1.0845e+00 (9.6080e-01)\tEntropy 2.2945e+00 (2.2961e+00)\n",
            "Epoch: [14][175/390]\tTotal Loss -1.0489e+01 (-1.0517e+01)\tConsistency Loss 9.9726e-01 (9.6409e-01)\tEntropy 2.2973e+00 (2.2963e+00)\n",
            "Epoch: [14][200/390]\tTotal Loss -1.0612e+01 (-1.0522e+01)\tConsistency Loss 8.7201e-01 (9.5938e-01)\tEntropy 2.2968e+00 (2.2963e+00)\n",
            "Epoch: [14][225/390]\tTotal Loss -1.0601e+01 (-1.0522e+01)\tConsistency Loss 8.6992e-01 (9.5988e-01)\tEntropy 2.2941e+00 (2.2963e+00)\n",
            "Epoch: [14][250/390]\tTotal Loss -1.0589e+01 (-1.0520e+01)\tConsistency Loss 9.1520e-01 (9.6155e-01)\tEntropy 2.3009e+00 (2.2964e+00)\n",
            "Epoch: [14][275/390]\tTotal Loss -1.0528e+01 (-1.0520e+01)\tConsistency Loss 9.6489e-01 (9.6146e-01)\tEntropy 2.2985e+00 (2.2964e+00)\n",
            "Epoch: [14][300/390]\tTotal Loss -1.0416e+01 (-1.0518e+01)\tConsistency Loss 1.0606e+00 (9.6359e-01)\tEntropy 2.2954e+00 (2.2964e+00)\n",
            "Epoch: [14][325/390]\tTotal Loss -1.0483e+01 (-1.0518e+01)\tConsistency Loss 1.0031e+00 (9.6424e-01)\tEntropy 2.2972e+00 (2.2964e+00)\n",
            "Epoch: [14][350/390]\tTotal Loss -1.0565e+01 (-1.0515e+01)\tConsistency Loss 9.3295e-01 (9.6651e-01)\tEntropy 2.2997e+00 (2.2964e+00)\n",
            "Epoch: [14][375/390]\tTotal Loss -1.0516e+01 (-1.0516e+01)\tConsistency Loss 9.6169e-01 (9.6651e-01)\tEntropy 2.2954e+00 (2.2965e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.2994465827941895, 'consistency': 0.7007215023040771, 'total_loss': -1.5987250804901123}], 'lowest_loss_head': 0, 'lowest_loss': -1.5987250804901123}\n",
            "No new lowest loss on validation set: -1.6031 -> -1.5987\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6231, 'ARI': 0.4331321487838085, 'NMI': 0.5199313761459108, 'ACC Top-5': 0.9315, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 16/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [15][  0/390]\tTotal Loss -1.0534e+01 (-1.0534e+01)\tConsistency Loss 9.6059e-01 (9.6059e-01)\tEntropy 2.2989e+00 (2.2989e+00)\n",
            "Epoch: [15][ 25/390]\tTotal Loss -1.0496e+01 (-1.0504e+01)\tConsistency Loss 9.8510e-01 (9.7881e-01)\tEntropy 2.2962e+00 (2.2965e+00)\n",
            "Epoch: [15][ 50/390]\tTotal Loss -1.0363e+01 (-1.0511e+01)\tConsistency Loss 1.1058e+00 (9.6981e-01)\tEntropy 2.2938e+00 (2.2962e+00)\n",
            "Epoch: [15][ 75/390]\tTotal Loss -1.0507e+01 (-1.0505e+01)\tConsistency Loss 9.8556e-01 (9.7755e-01)\tEntropy 2.2985e+00 (2.2965e+00)\n",
            "Epoch: [15][100/390]\tTotal Loss -1.0498e+01 (-1.0507e+01)\tConsistency Loss 9.6612e-01 (9.7433e-01)\tEntropy 2.2928e+00 (2.2963e+00)\n",
            "Epoch: [15][125/390]\tTotal Loss -1.0537e+01 (-1.0511e+01)\tConsistency Loss 9.5444e-01 (9.7096e-01)\tEntropy 2.2983e+00 (2.2964e+00)\n",
            "Epoch: [15][150/390]\tTotal Loss -1.0398e+01 (-1.0512e+01)\tConsistency Loss 1.1098e+00 (9.7041e-01)\tEntropy 2.3015e+00 (2.2965e+00)\n",
            "Epoch: [15][175/390]\tTotal Loss -1.0505e+01 (-1.0515e+01)\tConsistency Loss 9.7156e-01 (9.6718e-01)\tEntropy 2.2953e+00 (2.2965e+00)\n",
            "Epoch: [15][200/390]\tTotal Loss -1.0609e+01 (-1.0518e+01)\tConsistency Loss 8.8156e-01 (9.6446e-01)\tEntropy 2.2981e+00 (2.2966e+00)\n",
            "Epoch: [15][225/390]\tTotal Loss -1.0333e+01 (-1.0521e+01)\tConsistency Loss 1.1499e+00 (9.6194e-01)\tEntropy 2.2965e+00 (2.2966e+00)\n",
            "Epoch: [15][250/390]\tTotal Loss -1.0492e+01 (-1.0519e+01)\tConsistency Loss 9.6073e-01 (9.6419e-01)\tEntropy 2.2905e+00 (2.2966e+00)\n",
            "Epoch: [15][275/390]\tTotal Loss -1.0635e+01 (-1.0518e+01)\tConsistency Loss 8.6357e-01 (9.6478e-01)\tEntropy 2.2998e+00 (2.2965e+00)\n",
            "Epoch: [15][300/390]\tTotal Loss -1.0488e+01 (-1.0519e+01)\tConsistency Loss 1.0049e+00 (9.6347e-01)\tEntropy 2.2985e+00 (2.2965e+00)\n",
            "Epoch: [15][325/390]\tTotal Loss -1.0610e+01 (-1.0518e+01)\tConsistency Loss 8.8129e-01 (9.6428e-01)\tEntropy 2.2982e+00 (2.2965e+00)\n",
            "Epoch: [15][350/390]\tTotal Loss -1.0471e+01 (-1.0518e+01)\tConsistency Loss 1.0088e+00 (9.6396e-01)\tEntropy 2.2960e+00 (2.2965e+00)\n",
            "Epoch: [15][375/390]\tTotal Loss -1.0260e+01 (-1.0519e+01)\tConsistency Loss 1.2003e+00 (9.6342e-01)\tEntropy 2.2921e+00 (2.2964e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.301312208175659, 'consistency': 0.7012115120887756, 'total_loss': -1.6001006960868835}], 'lowest_loss_head': 0, 'lowest_loss': -1.6001006960868835}\n",
            "No new lowest loss on validation set: -1.6031 -> -1.6001\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.619, 'ARI': 0.42927289305229877, 'NMI': 0.5188486007543867, 'ACC Top-5': 0.9359, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 17/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [16][  0/390]\tTotal Loss -1.0410e+01 (-1.0410e+01)\tConsistency Loss 1.0297e+00 (1.0297e+00)\tEntropy 2.2880e+00 (2.2880e+00)\n",
            "Epoch: [16][ 25/390]\tTotal Loss -1.0392e+01 (-1.0522e+01)\tConsistency Loss 1.0751e+00 (9.5831e-01)\tEntropy 2.2935e+00 (2.2960e+00)\n",
            "Epoch: [16][ 50/390]\tTotal Loss -1.0491e+01 (-1.0511e+01)\tConsistency Loss 9.9922e-01 (9.6593e-01)\tEntropy 2.2980e+00 (2.2955e+00)\n",
            "Epoch: [16][ 75/390]\tTotal Loss -1.0566e+01 (-1.0520e+01)\tConsistency Loss 9.1287e-01 (9.5966e-01)\tEntropy 2.2958e+00 (2.2960e+00)\n",
            "Epoch: [16][100/390]\tTotal Loss -1.0658e+01 (-1.0523e+01)\tConsistency Loss 8.1856e-01 (9.5651e-01)\tEntropy 2.2954e+00 (2.2960e+00)\n",
            "Epoch: [16][125/390]\tTotal Loss -1.0479e+01 (-1.0524e+01)\tConsistency Loss 1.0047e+00 (9.5568e-01)\tEntropy 2.2968e+00 (2.2960e+00)\n",
            "Epoch: [16][150/390]\tTotal Loss -1.0499e+01 (-1.0525e+01)\tConsistency Loss 9.7802e-01 (9.5510e-01)\tEntropy 2.2953e+00 (2.2961e+00)\n",
            "Epoch: [16][175/390]\tTotal Loss -1.0546e+01 (-1.0520e+01)\tConsistency Loss 9.4840e-01 (9.6003e-01)\tEntropy 2.2988e+00 (2.2961e+00)\n",
            "Epoch: [16][200/390]\tTotal Loss -1.0512e+01 (-1.0522e+01)\tConsistency Loss 9.7685e-01 (9.5861e-01)\tEntropy 2.2978e+00 (2.2961e+00)\n",
            "Epoch: [16][225/390]\tTotal Loss -1.0627e+01 (-1.0523e+01)\tConsistency Loss 8.5998e-01 (9.5726e-01)\tEntropy 2.2975e+00 (2.2961e+00)\n",
            "Epoch: [16][250/390]\tTotal Loss -1.0591e+01 (-1.0523e+01)\tConsistency Loss 8.6411e-01 (9.5679e-01)\tEntropy 2.2911e+00 (2.2961e+00)\n",
            "Epoch: [16][275/390]\tTotal Loss -1.0622e+01 (-1.0522e+01)\tConsistency Loss 8.6309e-01 (9.5852e-01)\tEntropy 2.2969e+00 (2.2961e+00)\n",
            "Epoch: [16][300/390]\tTotal Loss -1.0619e+01 (-1.0524e+01)\tConsistency Loss 8.7767e-01 (9.5624e-01)\tEntropy 2.2993e+00 (2.2961e+00)\n",
            "Epoch: [16][325/390]\tTotal Loss -1.0488e+01 (-1.0523e+01)\tConsistency Loss 9.9574e-01 (9.5702e-01)\tEntropy 2.2967e+00 (2.2960e+00)\n",
            "Epoch: [16][350/390]\tTotal Loss -1.0466e+01 (-1.0523e+01)\tConsistency Loss 1.0324e+00 (9.5723e-01)\tEntropy 2.2997e+00 (2.2961e+00)\n",
            "Epoch: [16][375/390]\tTotal Loss -1.0560e+01 (-1.0522e+01)\tConsistency Loss 9.4050e-01 (9.5831e-01)\tEntropy 2.3001e+00 (2.2961e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.2983601093292236, 'consistency': 0.7001668810844421, 'total_loss': -1.5981932282447815}], 'lowest_loss_head': 0, 'lowest_loss': -1.5981932282447815}\n",
            "No new lowest loss on validation set: -1.6031 -> -1.5982\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6127, 'ARI': 0.41910838429237424, 'NMI': 0.512588018263383, 'ACC Top-5': 0.9261, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 18/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [17][  0/390]\tTotal Loss -1.0526e+01 (-1.0526e+01)\tConsistency Loss 9.3548e-01 (9.3548e-01)\tEntropy 2.2922e+00 (2.2922e+00)\n",
            "Epoch: [17][ 25/390]\tTotal Loss -1.0494e+01 (-1.0510e+01)\tConsistency Loss 9.9772e-01 (9.7205e-01)\tEntropy 2.2984e+00 (2.2965e+00)\n",
            "Epoch: [17][ 50/390]\tTotal Loss -1.0587e+01 (-1.0515e+01)\tConsistency Loss 9.0983e-01 (9.6442e-01)\tEntropy 2.2993e+00 (2.2959e+00)\n",
            "Epoch: [17][ 75/390]\tTotal Loss -1.0581e+01 (-1.0533e+01)\tConsistency Loss 9.0892e-01 (9.4686e-01)\tEntropy 2.2980e+00 (2.2960e+00)\n",
            "Epoch: [17][100/390]\tTotal Loss -1.0587e+01 (-1.0525e+01)\tConsistency Loss 9.0847e-01 (9.5528e-01)\tEntropy 2.2991e+00 (2.2960e+00)\n",
            "Epoch: [17][125/390]\tTotal Loss -1.0500e+01 (-1.0524e+01)\tConsistency Loss 9.8260e-01 (9.5666e-01)\tEntropy 2.2965e+00 (2.2962e+00)\n",
            "Epoch: [17][150/390]\tTotal Loss -1.0373e+01 (-1.0521e+01)\tConsistency Loss 1.0901e+00 (9.5927e-01)\tEntropy 2.2925e+00 (2.2961e+00)\n",
            "Epoch: [17][175/390]\tTotal Loss -1.0459e+01 (-1.0519e+01)\tConsistency Loss 9.8224e-01 (9.6185e-01)\tEntropy 2.2883e+00 (2.2961e+00)\n",
            "Epoch: [17][200/390]\tTotal Loss -1.0588e+01 (-1.0521e+01)\tConsistency Loss 9.0039e-01 (9.5918e-01)\tEntropy 2.2977e+00 (2.2961e+00)\n",
            "Epoch: [17][225/390]\tTotal Loss -1.0636e+01 (-1.0518e+01)\tConsistency Loss 8.4281e-01 (9.6257e-01)\tEntropy 2.2958e+00 (2.2961e+00)\n",
            "Epoch: [17][250/390]\tTotal Loss -1.0583e+01 (-1.0519e+01)\tConsistency Loss 9.1171e-01 (9.6156e-01)\tEntropy 2.2989e+00 (2.2962e+00)\n",
            "Epoch: [17][275/390]\tTotal Loss -1.0680e+01 (-1.0519e+01)\tConsistency Loss 8.2593e-01 (9.6207e-01)\tEntropy 2.3013e+00 (2.2963e+00)\n",
            "Epoch: [17][300/390]\tTotal Loss -1.0358e+01 (-1.0520e+01)\tConsistency Loss 1.1159e+00 (9.6158e-01)\tEntropy 2.2948e+00 (2.2962e+00)\n",
            "Epoch: [17][325/390]\tTotal Loss -1.0553e+01 (-1.0520e+01)\tConsistency Loss 9.0382e-01 (9.6090e-01)\tEntropy 2.2914e+00 (2.2963e+00)\n",
            "Epoch: [17][350/390]\tTotal Loss -1.0670e+01 (-1.0522e+01)\tConsistency Loss 8.3457e-01 (9.5927e-01)\tEntropy 2.3008e+00 (2.2963e+00)\n",
            "Epoch: [17][375/390]\tTotal Loss -1.0670e+01 (-1.0524e+01)\tConsistency Loss 8.0606e-01 (9.5756e-01)\tEntropy 2.2953e+00 (2.2963e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.2999496459960938, 'consistency': 0.7023101449012756, 'total_loss': -1.5976395010948181}], 'lowest_loss_head': 0, 'lowest_loss': -1.5976395010948181}\n",
            "No new lowest loss on validation set: -1.6031 -> -1.5976\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6165, 'ARI': 0.42230462082335724, 'NMI': 0.5168812092863356, 'ACC Top-5': 0.9328, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 19/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [18][  0/390]\tTotal Loss -1.0315e+01 (-1.0315e+01)\tConsistency Loss 1.1798e+00 (1.1798e+00)\tEntropy 2.2990e+00 (2.2990e+00)\n",
            "Epoch: [18][ 25/390]\tTotal Loss -1.0561e+01 (-1.0497e+01)\tConsistency Loss 9.2720e-01 (9.8443e-01)\tEntropy 2.2976e+00 (2.2963e+00)\n",
            "Epoch: [18][ 50/390]\tTotal Loss -1.0534e+01 (-1.0507e+01)\tConsistency Loss 9.3429e-01 (9.7355e-01)\tEntropy 2.2936e+00 (2.2961e+00)\n",
            "Epoch: [18][ 75/390]\tTotal Loss -1.0504e+01 (-1.0522e+01)\tConsistency Loss 9.8883e-01 (9.5899e-01)\tEntropy 2.2986e+00 (2.2962e+00)\n",
            "Epoch: [18][100/390]\tTotal Loss -1.0606e+01 (-1.0530e+01)\tConsistency Loss 8.6610e-01 (9.5243e-01)\tEntropy 2.2943e+00 (2.2964e+00)\n",
            "Epoch: [18][125/390]\tTotal Loss -1.0698e+01 (-1.0531e+01)\tConsistency Loss 7.6896e-01 (9.5002e-01)\tEntropy 2.2935e+00 (2.2961e+00)\n",
            "Epoch: [18][150/390]\tTotal Loss -1.0481e+01 (-1.0527e+01)\tConsistency Loss 1.0133e+00 (9.5328e-01)\tEntropy 2.2988e+00 (2.2960e+00)\n",
            "Epoch: [18][175/390]\tTotal Loss -1.0387e+01 (-1.0520e+01)\tConsistency Loss 1.1111e+00 (9.5993e-01)\tEntropy 2.2996e+00 (2.2960e+00)\n",
            "Epoch: [18][200/390]\tTotal Loss -1.0541e+01 (-1.0520e+01)\tConsistency Loss 9.2640e-01 (9.5987e-01)\tEntropy 2.2935e+00 (2.2960e+00)\n",
            "Epoch: [18][225/390]\tTotal Loss -1.0470e+01 (-1.0516e+01)\tConsistency Loss 1.0082e+00 (9.6352e-01)\tEntropy 2.2956e+00 (2.2959e+00)\n",
            "Epoch: [18][250/390]\tTotal Loss -1.0616e+01 (-1.0516e+01)\tConsistency Loss 8.7639e-01 (9.6368e-01)\tEntropy 2.2984e+00 (2.2960e+00)\n",
            "Epoch: [18][275/390]\tTotal Loss -1.0609e+01 (-1.0521e+01)\tConsistency Loss 8.8107e-01 (9.5875e-01)\tEntropy 2.2981e+00 (2.2960e+00)\n",
            "Epoch: [18][300/390]\tTotal Loss -1.0481e+01 (-1.0523e+01)\tConsistency Loss 1.0041e+00 (9.5741e-01)\tEntropy 2.2970e+00 (2.2960e+00)\n",
            "Epoch: [18][325/390]\tTotal Loss -1.0486e+01 (-1.0522e+01)\tConsistency Loss 9.8566e-01 (9.5811e-01)\tEntropy 2.2943e+00 (2.2961e+00)\n",
            "Epoch: [18][350/390]\tTotal Loss -1.0694e+01 (-1.0522e+01)\tConsistency Loss 7.6621e-01 (9.5793e-01)\tEntropy 2.2920e+00 (2.2961e+00)\n",
            "Epoch: [18][375/390]\tTotal Loss -1.0762e+01 (-1.0525e+01)\tConsistency Loss 7.1620e-01 (9.5571e-01)\tEntropy 2.2956e+00 (2.2961e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.299464464187622, 'consistency': 0.6843633651733398, 'total_loss': -1.6151010990142822}], 'lowest_loss_head': 0, 'lowest_loss': -1.6151010990142822}\n",
            "New lowest loss on validation set: -1.6031 -> -1.6151\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6337, 'ARI': 0.4436232005553565, 'NMI': 0.527642810890946, 'ACC Top-5': 0.928, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 20/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [19][  0/390]\tTotal Loss -1.0588e+01 (-1.0588e+01)\tConsistency Loss 9.0630e-01 (9.0630e-01)\tEntropy 2.2988e+00 (2.2988e+00)\n",
            "Epoch: [19][ 25/390]\tTotal Loss -1.0494e+01 (-1.0536e+01)\tConsistency Loss 9.9871e-01 (9.4201e-01)\tEntropy 2.2985e+00 (2.2956e+00)\n",
            "Epoch: [19][ 50/390]\tTotal Loss -1.0534e+01 (-1.0536e+01)\tConsistency Loss 9.5878e-01 (9.4483e-01)\tEntropy 2.2985e+00 (2.2962e+00)\n",
            "Epoch: [19][ 75/390]\tTotal Loss -1.0495e+01 (-1.0537e+01)\tConsistency Loss 9.5118e-01 (9.4506e-01)\tEntropy 2.2893e+00 (2.2965e+00)\n",
            "Epoch: [19][100/390]\tTotal Loss -1.0624e+01 (-1.0541e+01)\tConsistency Loss 8.6251e-01 (9.4105e-01)\tEntropy 2.2974e+00 (2.2965e+00)\n",
            "Epoch: [19][125/390]\tTotal Loss -1.0494e+01 (-1.0538e+01)\tConsistency Loss 1.0043e+00 (9.4464e-01)\tEntropy 2.2997e+00 (2.2966e+00)\n",
            "Epoch: [19][150/390]\tTotal Loss -1.0447e+01 (-1.0537e+01)\tConsistency Loss 1.0195e+00 (9.4501e-01)\tEntropy 2.2933e+00 (2.2964e+00)\n",
            "Epoch: [19][175/390]\tTotal Loss -1.0743e+01 (-1.0535e+01)\tConsistency Loss 7.5700e-01 (9.4784e-01)\tEntropy 2.3001e+00 (2.2965e+00)\n",
            "Epoch: [19][200/390]\tTotal Loss -1.0590e+01 (-1.0536e+01)\tConsistency Loss 9.0930e-01 (9.4651e-01)\tEntropy 2.2998e+00 (2.2966e+00)\n",
            "Epoch: [19][225/390]\tTotal Loss -1.0436e+01 (-1.0537e+01)\tConsistency Loss 1.0559e+00 (9.4581e-01)\tEntropy 2.2985e+00 (2.2966e+00)\n",
            "Epoch: [19][250/390]\tTotal Loss -1.0451e+01 (-1.0535e+01)\tConsistency Loss 1.0475e+00 (9.4746e-01)\tEntropy 2.2997e+00 (2.2965e+00)\n",
            "Epoch: [19][275/390]\tTotal Loss -1.0527e+01 (-1.0535e+01)\tConsistency Loss 9.7288e-01 (9.4735e-01)\tEntropy 2.3001e+00 (2.2965e+00)\n",
            "Epoch: [19][300/390]\tTotal Loss -1.0476e+01 (-1.0535e+01)\tConsistency Loss 1.0239e+00 (9.4716e-01)\tEntropy 2.3000e+00 (2.2965e+00)\n",
            "Epoch: [19][325/390]\tTotal Loss -1.0533e+01 (-1.0537e+01)\tConsistency Loss 9.4602e-01 (9.4584e-01)\tEntropy 2.2958e+00 (2.2965e+00)\n",
            "Epoch: [19][350/390]\tTotal Loss -1.0601e+01 (-1.0536e+01)\tConsistency Loss 8.9498e-01 (9.4671e-01)\tEntropy 2.2991e+00 (2.2965e+00)\n",
            "Epoch: [19][375/390]\tTotal Loss -1.0407e+01 (-1.0536e+01)\tConsistency Loss 1.0425e+00 (9.4651e-01)\tEntropy 2.2900e+00 (2.2965e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.2996652126312256, 'consistency': 0.6901255249977112, 'total_loss': -1.6095396876335144}], 'lowest_loss_head': 0, 'lowest_loss': -1.6095396876335144}\n",
            "No new lowest loss on validation set: -1.6151 -> -1.6095\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6257, 'ARI': 0.44141040002762133, 'NMI': 0.5262109892289771, 'ACC Top-5': 0.924, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 21/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [20][  0/390]\tTotal Loss -1.0537e+01 (-1.0537e+01)\tConsistency Loss 9.5576e-01 (9.5576e-01)\tEntropy 2.2985e+00 (2.2985e+00)\n",
            "Epoch: [20][ 25/390]\tTotal Loss -1.0636e+01 (-1.0552e+01)\tConsistency Loss 8.5122e-01 (9.3383e-01)\tEntropy 2.2975e+00 (2.2972e+00)\n",
            "Epoch: [20][ 50/390]\tTotal Loss -1.0455e+01 (-1.0532e+01)\tConsistency Loss 1.0266e+00 (9.5181e-01)\tEntropy 2.2963e+00 (2.2967e+00)\n",
            "Epoch: [20][ 75/390]\tTotal Loss -1.0492e+01 (-1.0546e+01)\tConsistency Loss 9.9170e-01 (9.3840e-01)\tEntropy 2.2968e+00 (2.2969e+00)\n",
            "Epoch: [20][100/390]\tTotal Loss -1.0748e+01 (-1.0552e+01)\tConsistency Loss 7.4713e-01 (9.3241e-01)\tEntropy 2.2990e+00 (2.2968e+00)\n",
            "Epoch: [20][125/390]\tTotal Loss -1.0750e+01 (-1.0550e+01)\tConsistency Loss 7.1810e-01 (9.3279e-01)\tEntropy 2.2936e+00 (2.2967e+00)\n",
            "Epoch: [20][150/390]\tTotal Loss -1.0485e+01 (-1.0548e+01)\tConsistency Loss 9.9977e-01 (9.3478e-01)\tEntropy 2.2969e+00 (2.2966e+00)\n",
            "Epoch: [20][175/390]\tTotal Loss -1.0502e+01 (-1.0545e+01)\tConsistency Loss 9.6561e-01 (9.3751e-01)\tEntropy 2.2934e+00 (2.2965e+00)\n",
            "Epoch: [20][200/390]\tTotal Loss -1.0605e+01 (-1.0545e+01)\tConsistency Loss 8.9572e-01 (9.3739e-01)\tEntropy 2.3001e+00 (2.2965e+00)\n",
            "Epoch: [20][225/390]\tTotal Loss -1.0485e+01 (-1.0546e+01)\tConsistency Loss 9.6749e-01 (9.3613e-01)\tEntropy 2.2904e+00 (2.2964e+00)\n",
            "Epoch: [20][250/390]\tTotal Loss -1.0531e+01 (-1.0544e+01)\tConsistency Loss 9.6562e-01 (9.3843e-01)\tEntropy 2.2994e+00 (2.2964e+00)\n",
            "Epoch: [20][275/390]\tTotal Loss -1.0476e+01 (-1.0542e+01)\tConsistency Loss 1.0048e+00 (9.4008e-01)\tEntropy 2.2961e+00 (2.2964e+00)\n",
            "Epoch: [20][300/390]\tTotal Loss -1.0566e+01 (-1.0544e+01)\tConsistency Loss 9.1506e-01 (9.3871e-01)\tEntropy 2.2962e+00 (2.2965e+00)\n",
            "Epoch: [20][325/390]\tTotal Loss -1.0373e+01 (-1.0544e+01)\tConsistency Loss 1.1167e+00 (9.3828e-01)\tEntropy 2.2979e+00 (2.2965e+00)\n",
            "Epoch: [20][350/390]\tTotal Loss -1.0621e+01 (-1.0545e+01)\tConsistency Loss 8.5503e-01 (9.3781e-01)\tEntropy 2.2952e+00 (2.2965e+00)\n",
            "Epoch: [20][375/390]\tTotal Loss -1.0514e+01 (-1.0544e+01)\tConsistency Loss 9.6038e-01 (9.3864e-01)\tEntropy 2.2948e+00 (2.2965e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.2977616786956787, 'consistency': 0.6937031745910645, 'total_loss': -1.6040585041046143}], 'lowest_loss_head': 0, 'lowest_loss': -1.6040585041046143}\n",
            "No new lowest loss on validation set: -1.6151 -> -1.6041\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6187, 'ARI': 0.4256371386810875, 'NMI': 0.517077780307596, 'ACC Top-5': 0.923, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 22/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [21][  0/390]\tTotal Loss -1.0619e+01 (-1.0619e+01)\tConsistency Loss 8.5518e-01 (8.5518e-01)\tEntropy 2.2949e+00 (2.2949e+00)\n",
            "Epoch: [21][ 25/390]\tTotal Loss -1.0611e+01 (-1.0547e+01)\tConsistency Loss 8.7775e-01 (9.3378e-01)\tEntropy 2.2978e+00 (2.2962e+00)\n",
            "Epoch: [21][ 50/390]\tTotal Loss -1.0617e+01 (-1.0551e+01)\tConsistency Loss 8.7451e-01 (9.3090e-01)\tEntropy 2.2984e+00 (2.2963e+00)\n",
            "Epoch: [21][ 75/390]\tTotal Loss -1.0649e+01 (-1.0543e+01)\tConsistency Loss 8.3552e-01 (9.3950e-01)\tEntropy 2.2970e+00 (2.2965e+00)\n",
            "Epoch: [21][100/390]\tTotal Loss -1.0459e+01 (-1.0544e+01)\tConsistency Loss 1.0349e+00 (9.3895e-01)\tEntropy 2.2987e+00 (2.2966e+00)\n",
            "Epoch: [21][125/390]\tTotal Loss -1.0680e+01 (-1.0550e+01)\tConsistency Loss 7.9309e-01 (9.3377e-01)\tEntropy 2.2947e+00 (2.2967e+00)\n",
            "Epoch: [21][150/390]\tTotal Loss -1.0588e+01 (-1.0545e+01)\tConsistency Loss 8.8174e-01 (9.3793e-01)\tEntropy 2.2940e+00 (2.2967e+00)\n",
            "Epoch: [21][175/390]\tTotal Loss -1.0529e+01 (-1.0547e+01)\tConsistency Loss 9.6844e-01 (9.3624e-01)\tEntropy 2.2994e+00 (2.2967e+00)\n",
            "Epoch: [21][200/390]\tTotal Loss -1.0414e+01 (-1.0548e+01)\tConsistency Loss 1.0893e+00 (9.3608e-01)\tEntropy 2.3008e+00 (2.2968e+00)\n",
            "Epoch: [21][225/390]\tTotal Loss -1.0511e+01 (-1.0550e+01)\tConsistency Loss 9.6346e-01 (9.3343e-01)\tEntropy 2.2948e+00 (2.2968e+00)\n",
            "Epoch: [21][250/390]\tTotal Loss -1.0485e+01 (-1.0546e+01)\tConsistency Loss 1.0134e+00 (9.3742e-01)\tEntropy 2.2997e+00 (2.2967e+00)\n",
            "Epoch: [21][275/390]\tTotal Loss -1.0602e+01 (-1.0546e+01)\tConsistency Loss 8.8384e-01 (9.3726e-01)\tEntropy 2.2972e+00 (2.2966e+00)\n",
            "Epoch: [21][300/390]\tTotal Loss -1.0632e+01 (-1.0547e+01)\tConsistency Loss 8.3889e-01 (9.3627e-01)\tEntropy 2.2941e+00 (2.2966e+00)\n",
            "Epoch: [21][325/390]\tTotal Loss -1.0551e+01 (-1.0543e+01)\tConsistency Loss 9.2601e-01 (9.3975e-01)\tEntropy 2.2955e+00 (2.2966e+00)\n",
            "Epoch: [21][350/390]\tTotal Loss -1.0581e+01 (-1.0544e+01)\tConsistency Loss 9.0562e-01 (9.3902e-01)\tEntropy 2.2973e+00 (2.2967e+00)\n",
            "Epoch: [21][375/390]\tTotal Loss -1.0548e+01 (-1.0544e+01)\tConsistency Loss 9.4732e-01 (9.3950e-01)\tEntropy 2.2990e+00 (2.2966e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.297400951385498, 'consistency': 0.6887665390968323, 'total_loss': -1.6086344122886658}], 'lowest_loss_head': 0, 'lowest_loss': -1.6086344122886658}\n",
            "No new lowest loss on validation set: -1.6151 -> -1.6086\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6241, 'ARI': 0.4380627734268551, 'NMI': 0.5222023718318309, 'ACC Top-5': 0.9134, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 23/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [22][  0/390]\tTotal Loss -1.0637e+01 (-1.0637e+01)\tConsistency Loss 8.3546e-01 (8.3546e-01)\tEntropy 2.2945e+00 (2.2945e+00)\n",
            "Epoch: [22][ 25/390]\tTotal Loss -1.0496e+01 (-1.0534e+01)\tConsistency Loss 9.6999e-01 (9.4610e-01)\tEntropy 2.2932e+00 (2.2961e+00)\n",
            "Epoch: [22][ 50/390]\tTotal Loss -1.0441e+01 (-1.0543e+01)\tConsistency Loss 1.0519e+00 (9.3820e-01)\tEntropy 2.2986e+00 (2.2963e+00)\n",
            "Epoch: [22][ 75/390]\tTotal Loss -1.0602e+01 (-1.0550e+01)\tConsistency Loss 9.0097e-01 (9.3089e-01)\tEntropy 2.3006e+00 (2.2963e+00)\n",
            "Epoch: [22][100/390]\tTotal Loss -1.0497e+01 (-1.0547e+01)\tConsistency Loss 9.8728e-01 (9.3413e-01)\tEntropy 2.2968e+00 (2.2963e+00)\n",
            "Epoch: [22][125/390]\tTotal Loss -1.0515e+01 (-1.0546e+01)\tConsistency Loss 9.6593e-01 (9.3613e-01)\tEntropy 2.2961e+00 (2.2964e+00)\n",
            "Epoch: [22][150/390]\tTotal Loss -1.0494e+01 (-1.0548e+01)\tConsistency Loss 9.9694e-01 (9.3422e-01)\tEntropy 2.2981e+00 (2.2965e+00)\n",
            "Epoch: [22][175/390]\tTotal Loss -1.0536e+01 (-1.0550e+01)\tConsistency Loss 9.6727e-01 (9.3203e-01)\tEntropy 2.3007e+00 (2.2965e+00)\n",
            "Epoch: [22][200/390]\tTotal Loss -1.0558e+01 (-1.0549e+01)\tConsistency Loss 9.1945e-01 (9.3338e-01)\tEntropy 2.2955e+00 (2.2965e+00)\n",
            "Epoch: [22][225/390]\tTotal Loss -1.0537e+01 (-1.0548e+01)\tConsistency Loss 9.4010e-01 (9.3381e-01)\tEntropy 2.2953e+00 (2.2964e+00)\n",
            "Epoch: [22][250/390]\tTotal Loss -1.0349e+01 (-1.0547e+01)\tConsistency Loss 1.1229e+00 (9.3542e-01)\tEntropy 2.2945e+00 (2.2965e+00)\n",
            "Epoch: [22][275/390]\tTotal Loss -1.0454e+01 (-1.0546e+01)\tConsistency Loss 1.0520e+00 (9.3670e-01)\tEntropy 2.3011e+00 (2.2965e+00)\n",
            "Epoch: [22][300/390]\tTotal Loss -1.0554e+01 (-1.0546e+01)\tConsistency Loss 9.2777e-01 (9.3661e-01)\tEntropy 2.2964e+00 (2.2965e+00)\n",
            "Epoch: [22][325/390]\tTotal Loss -1.0559e+01 (-1.0547e+01)\tConsistency Loss 9.4767e-01 (9.3526e-01)\tEntropy 2.3013e+00 (2.2965e+00)\n",
            "Epoch: [22][350/390]\tTotal Loss -1.0579e+01 (-1.0547e+01)\tConsistency Loss 9.0007e-01 (9.3492e-01)\tEntropy 2.2958e+00 (2.2965e+00)\n",
            "Epoch: [22][375/390]\tTotal Loss -1.0380e+01 (-1.0547e+01)\tConsistency Loss 1.1075e+00 (9.3491e-01)\tEntropy 2.2976e+00 (2.2964e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.3001701831817627, 'consistency': 0.6900981068611145, 'total_loss': -1.6100720763206482}], 'lowest_loss_head': 0, 'lowest_loss': -1.6100720763206482}\n",
            "No new lowest loss on validation set: -1.6151 -> -1.6101\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6259, 'ARI': 0.43711719156439705, 'NMI': 0.5240472083036543, 'ACC Top-5': 0.924, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 24/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [23][  0/390]\tTotal Loss -1.0699e+01 (-1.0699e+01)\tConsistency Loss 7.9519e-01 (7.9519e-01)\tEntropy 2.2988e+00 (2.2988e+00)\n",
            "Epoch: [23][ 25/390]\tTotal Loss -1.0718e+01 (-1.0581e+01)\tConsistency Loss 7.7378e-01 (9.0365e-01)\tEntropy 2.2983e+00 (2.2969e+00)\n",
            "Epoch: [23][ 50/390]\tTotal Loss -1.0617e+01 (-1.0578e+01)\tConsistency Loss 8.7643e-01 (9.0501e-01)\tEntropy 2.2987e+00 (2.2966e+00)\n",
            "Epoch: [23][ 75/390]\tTotal Loss -1.0720e+01 (-1.0563e+01)\tConsistency Loss 7.6926e-01 (9.1791e-01)\tEntropy 2.2979e+00 (2.2962e+00)\n",
            "Epoch: [23][100/390]\tTotal Loss -1.0690e+01 (-1.0559e+01)\tConsistency Loss 7.7766e-01 (9.2286e-01)\tEntropy 2.2935e+00 (2.2964e+00)\n",
            "Epoch: [23][125/390]\tTotal Loss -1.0521e+01 (-1.0557e+01)\tConsistency Loss 9.6940e-01 (9.2482e-01)\tEntropy 2.2982e+00 (2.2963e+00)\n",
            "Epoch: [23][150/390]\tTotal Loss -1.0320e+01 (-1.0551e+01)\tConsistency Loss 1.1587e+00 (9.3006e-01)\tEntropy 2.2957e+00 (2.2963e+00)\n",
            "Epoch: [23][175/390]\tTotal Loss -1.0579e+01 (-1.0555e+01)\tConsistency Loss 9.0702e-01 (9.2655e-01)\tEntropy 2.2972e+00 (2.2963e+00)\n",
            "Epoch: [23][200/390]\tTotal Loss -1.0504e+01 (-1.0552e+01)\tConsistency Loss 9.8500e-01 (9.3010e-01)\tEntropy 2.2979e+00 (2.2964e+00)\n",
            "Epoch: [23][225/390]\tTotal Loss -1.0606e+01 (-1.0549e+01)\tConsistency Loss 8.8241e-01 (9.3258e-01)\tEntropy 2.2977e+00 (2.2964e+00)\n",
            "Epoch: [23][250/390]\tTotal Loss -1.0611e+01 (-1.0553e+01)\tConsistency Loss 8.8159e-01 (9.2919e-01)\tEntropy 2.2986e+00 (2.2964e+00)\n",
            "Epoch: [23][275/390]\tTotal Loss -1.0543e+01 (-1.0552e+01)\tConsistency Loss 9.4190e-01 (9.3033e-01)\tEntropy 2.2969e+00 (2.2965e+00)\n",
            "Epoch: [23][300/390]\tTotal Loss -1.0477e+01 (-1.0551e+01)\tConsistency Loss 1.0123e+00 (9.3154e-01)\tEntropy 2.2978e+00 (2.2965e+00)\n",
            "Epoch: [23][325/390]\tTotal Loss -1.0227e+01 (-1.0550e+01)\tConsistency Loss 1.2543e+00 (9.3229e-01)\tEntropy 2.2963e+00 (2.2964e+00)\n",
            "Epoch: [23][350/390]\tTotal Loss -1.0534e+01 (-1.0550e+01)\tConsistency Loss 9.6190e-01 (9.3245e-01)\tEntropy 2.2991e+00 (2.2964e+00)\n",
            "Epoch: [23][375/390]\tTotal Loss -1.0429e+01 (-1.0550e+01)\tConsistency Loss 1.0699e+00 (9.3290e-01)\tEntropy 2.2997e+00 (2.2965e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.295651435852051, 'consistency': 0.6830321550369263, 'total_loss': -1.6126192808151245}], 'lowest_loss_head': 0, 'lowest_loss': -1.6126192808151245}\n",
            "No new lowest loss on validation set: -1.6151 -> -1.6126\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6082, 'ARI': 0.42402049652039875, 'NMI': 0.5180613862500864, 'ACC Top-5': 0.9196, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 25/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [24][  0/390]\tTotal Loss -1.0506e+01 (-1.0506e+01)\tConsistency Loss 9.8067e-01 (9.8067e-01)\tEntropy 2.2973e+00 (2.2973e+00)\n",
            "Epoch: [24][ 25/390]\tTotal Loss -1.0713e+01 (-1.0566e+01)\tConsistency Loss 7.8533e-01 (9.1845e-01)\tEntropy 2.2996e+00 (2.2968e+00)\n",
            "Epoch: [24][ 50/390]\tTotal Loss -1.0643e+01 (-1.0560e+01)\tConsistency Loss 8.5728e-01 (9.2065e-01)\tEntropy 2.3000e+00 (2.2961e+00)\n",
            "Epoch: [24][ 75/390]\tTotal Loss -1.0469e+01 (-1.0563e+01)\tConsistency Loss 1.0091e+00 (9.1644e-01)\tEntropy 2.2957e+00 (2.2959e+00)\n",
            "Epoch: [24][100/390]\tTotal Loss -1.0563e+01 (-1.0564e+01)\tConsistency Loss 9.1202e-01 (9.1562e-01)\tEntropy 2.2949e+00 (2.2960e+00)\n",
            "Epoch: [24][125/390]\tTotal Loss -1.0789e+01 (-1.0568e+01)\tConsistency Loss 6.8808e-01 (9.1209e-01)\tEntropy 2.2954e+00 (2.2960e+00)\n",
            "Epoch: [24][150/390]\tTotal Loss -1.0674e+01 (-1.0564e+01)\tConsistency Loss 8.0586e-01 (9.1646e-01)\tEntropy 2.2961e+00 (2.2960e+00)\n",
            "Epoch: [24][175/390]\tTotal Loss -1.0543e+01 (-1.0558e+01)\tConsistency Loss 9.5589e-01 (9.2142e-01)\tEntropy 2.2997e+00 (2.2960e+00)\n",
            "Epoch: [24][200/390]\tTotal Loss -1.0616e+01 (-1.0555e+01)\tConsistency Loss 8.6721e-01 (9.2533e-01)\tEntropy 2.2967e+00 (2.2961e+00)\n",
            "Epoch: [24][225/390]\tTotal Loss -1.0508e+01 (-1.0555e+01)\tConsistency Loss 9.7092e-01 (9.2563e-01)\tEntropy 2.2959e+00 (2.2961e+00)\n",
            "Epoch: [24][250/390]\tTotal Loss -1.0507e+01 (-1.0554e+01)\tConsistency Loss 9.8415e-01 (9.2641e-01)\tEntropy 2.2982e+00 (2.2960e+00)\n",
            "Epoch: [24][275/390]\tTotal Loss -1.0526e+01 (-1.0550e+01)\tConsistency Loss 9.5641e-01 (9.3002e-01)\tEntropy 2.2965e+00 (2.2961e+00)\n",
            "Epoch: [24][300/390]\tTotal Loss -1.0463e+01 (-1.0551e+01)\tConsistency Loss 1.0069e+00 (9.3034e-01)\tEntropy 2.2940e+00 (2.2962e+00)\n",
            "Epoch: [24][325/390]\tTotal Loss -1.0493e+01 (-1.0549e+01)\tConsistency Loss 9.9753e-01 (9.3163e-01)\tEntropy 2.2980e+00 (2.2962e+00)\n",
            "Epoch: [24][350/390]\tTotal Loss -1.0737e+01 (-1.0550e+01)\tConsistency Loss 7.5249e-01 (9.3130e-01)\tEntropy 2.2979e+00 (2.2962e+00)\n",
            "Epoch: [24][375/390]\tTotal Loss -1.0464e+01 (-1.0551e+01)\tConsistency Loss 1.0271e+00 (9.3064e-01)\tEntropy 2.2982e+00 (2.2962e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.298759698867798, 'consistency': 0.676461935043335, 'total_loss': -1.622297763824463}], 'lowest_loss_head': 0, 'lowest_loss': -1.622297763824463}\n",
            "New lowest loss on validation set: -1.6151 -> -1.6223\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6254, 'ARI': 0.4346138191941079, 'NMI': 0.5225899679688494, 'ACC Top-5': 0.9185, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 26/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [25][  0/390]\tTotal Loss -1.0481e+01 (-1.0481e+01)\tConsistency Loss 9.9317e-01 (9.9317e-01)\tEntropy 2.2948e+00 (2.2948e+00)\n",
            "Epoch: [25][ 25/390]\tTotal Loss -1.0554e+01 (-1.0542e+01)\tConsistency Loss 9.1061e-01 (9.3902e-01)\tEntropy 2.2930e+00 (2.2962e+00)\n",
            "Epoch: [25][ 50/390]\tTotal Loss -1.0496e+01 (-1.0547e+01)\tConsistency Loss 9.8805e-01 (9.3437e-01)\tEntropy 2.2967e+00 (2.2962e+00)\n",
            "Epoch: [25][ 75/390]\tTotal Loss -1.0485e+01 (-1.0553e+01)\tConsistency Loss 9.8188e-01 (9.2891e-01)\tEntropy 2.2934e+00 (2.2964e+00)\n",
            "Epoch: [25][100/390]\tTotal Loss -1.0580e+01 (-1.0555e+01)\tConsistency Loss 8.8475e-01 (9.2826e-01)\tEntropy 2.2929e+00 (2.2966e+00)\n",
            "Epoch: [25][125/390]\tTotal Loss -1.0493e+01 (-1.0553e+01)\tConsistency Loss 1.0032e+00 (9.3069e-01)\tEntropy 2.2993e+00 (2.2967e+00)\n",
            "Epoch: [25][150/390]\tTotal Loss -1.0559e+01 (-1.0551e+01)\tConsistency Loss 9.2854e-01 (9.3185e-01)\tEntropy 2.2976e+00 (2.2966e+00)\n",
            "Epoch: [25][175/390]\tTotal Loss -1.0567e+01 (-1.0551e+01)\tConsistency Loss 9.1624e-01 (9.3197e-01)\tEntropy 2.2966e+00 (2.2966e+00)\n",
            "Epoch: [25][200/390]\tTotal Loss -1.0517e+01 (-1.0553e+01)\tConsistency Loss 9.8214e-01 (9.3051e-01)\tEntropy 2.2998e+00 (2.2967e+00)\n",
            "Epoch: [25][225/390]\tTotal Loss -1.0513e+01 (-1.0554e+01)\tConsistency Loss 9.6561e-01 (9.2919e-01)\tEntropy 2.2958e+00 (2.2967e+00)\n",
            "Epoch: [25][250/390]\tTotal Loss -1.0420e+01 (-1.0553e+01)\tConsistency Loss 1.0344e+00 (9.2966e-01)\tEntropy 2.2908e+00 (2.2966e+00)\n",
            "Epoch: [25][275/390]\tTotal Loss -1.0612e+01 (-1.0553e+01)\tConsistency Loss 8.8696e-01 (9.3030e-01)\tEntropy 2.2998e+00 (2.2966e+00)\n",
            "Epoch: [25][300/390]\tTotal Loss -1.0570e+01 (-1.0554e+01)\tConsistency Loss 9.0945e-01 (9.2907e-01)\tEntropy 2.2960e+00 (2.2965e+00)\n",
            "Epoch: [25][325/390]\tTotal Loss -1.0580e+01 (-1.0554e+01)\tConsistency Loss 9.1025e-01 (9.2842e-01)\tEntropy 2.2980e+00 (2.2965e+00)\n",
            "Epoch: [25][350/390]\tTotal Loss -1.0387e+01 (-1.0554e+01)\tConsistency Loss 1.0817e+00 (9.2867e-01)\tEntropy 2.2937e+00 (2.2965e+00)\n",
            "Epoch: [25][375/390]\tTotal Loss -1.0570e+01 (-1.0554e+01)\tConsistency Loss 9.1855e-01 (9.2868e-01)\tEntropy 2.2977e+00 (2.2965e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.300002098083496, 'consistency': 0.6805373430252075, 'total_loss': -1.6194647550582886}], 'lowest_loss_head': 0, 'lowest_loss': -1.6194647550582886}\n",
            "No new lowest loss on validation set: -1.6223 -> -1.6195\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6254, 'ARI': 0.4383508688061747, 'NMI': 0.5270362768014666, 'ACC Top-5': 0.917, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 27/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [26][  0/390]\tTotal Loss -1.0740e+01 (-1.0740e+01)\tConsistency Loss 7.4280e-01 (7.4280e-01)\tEntropy 2.2966e+00 (2.2966e+00)\n",
            "Epoch: [26][ 25/390]\tTotal Loss -1.0646e+01 (-1.0580e+01)\tConsistency Loss 8.0503e-01 (9.0271e-01)\tEntropy 2.2903e+00 (2.2965e+00)\n",
            "Epoch: [26][ 50/390]\tTotal Loss -1.0458e+01 (-1.0563e+01)\tConsistency Loss 1.0095e+00 (9.2282e-01)\tEntropy 2.2935e+00 (2.2971e+00)\n",
            "Epoch: [26][ 75/390]\tTotal Loss -1.0677e+01 (-1.0569e+01)\tConsistency Loss 8.1665e-01 (9.1437e-01)\tEntropy 2.2987e+00 (2.2968e+00)\n",
            "Epoch: [26][100/390]\tTotal Loss -1.0431e+01 (-1.0561e+01)\tConsistency Loss 1.0650e+00 (9.2215e-01)\tEntropy 2.2991e+00 (2.2966e+00)\n",
            "Epoch: [26][125/390]\tTotal Loss -1.0609e+01 (-1.0561e+01)\tConsistency Loss 8.7675e-01 (9.2226e-01)\tEntropy 2.2971e+00 (2.2967e+00)\n",
            "Epoch: [26][150/390]\tTotal Loss -1.0406e+01 (-1.0555e+01)\tConsistency Loss 1.0827e+00 (9.2856e-01)\tEntropy 2.2976e+00 (2.2967e+00)\n",
            "Epoch: [26][175/390]\tTotal Loss -1.0602e+01 (-1.0554e+01)\tConsistency Loss 8.7316e-01 (9.2973e-01)\tEntropy 2.2951e+00 (2.2968e+00)\n",
            "Epoch: [26][200/390]\tTotal Loss -1.0552e+01 (-1.0548e+01)\tConsistency Loss 9.4004e-01 (9.3591e-01)\tEntropy 2.2985e+00 (2.2967e+00)\n",
            "Epoch: [26][225/390]\tTotal Loss -1.0469e+01 (-1.0546e+01)\tConsistency Loss 1.0229e+00 (9.3686e-01)\tEntropy 2.2984e+00 (2.2967e+00)\n",
            "Epoch: [26][250/390]\tTotal Loss -1.0596e+01 (-1.0548e+01)\tConsistency Loss 8.5646e-01 (9.3544e-01)\tEntropy 2.2904e+00 (2.2966e+00)\n",
            "Epoch: [26][275/390]\tTotal Loss -1.0462e+01 (-1.0550e+01)\tConsistency Loss 1.0289e+00 (9.3297e-01)\tEntropy 2.2982e+00 (2.2966e+00)\n",
            "Epoch: [26][300/390]\tTotal Loss -1.0520e+01 (-1.0549e+01)\tConsistency Loss 9.6592e-01 (9.3434e-01)\tEntropy 2.2972e+00 (2.2966e+00)\n",
            "Epoch: [26][325/390]\tTotal Loss -1.0466e+01 (-1.0548e+01)\tConsistency Loss 1.0302e+00 (9.3441e-01)\tEntropy 2.2993e+00 (2.2965e+00)\n",
            "Epoch: [26][350/390]\tTotal Loss -1.0680e+01 (-1.0547e+01)\tConsistency Loss 7.9940e-01 (9.3500e-01)\tEntropy 2.2958e+00 (2.2965e+00)\n",
            "Epoch: [26][375/390]\tTotal Loss -1.0432e+01 (-1.0547e+01)\tConsistency Loss 1.0607e+00 (9.3578e-01)\tEntropy 2.2985e+00 (2.2965e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.29655122756958, 'consistency': 0.6842995882034302, 'total_loss': -1.61225163936615}], 'lowest_loss_head': 0, 'lowest_loss': -1.61225163936615}\n",
            "No new lowest loss on validation set: -1.6223 -> -1.6123\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6205, 'ARI': 0.42583784609230296, 'NMI': 0.5193954127079646, 'ACC Top-5': 0.9353, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 2), (4, 3), (5, 8), (6, 7), (7, 4), (8, 0), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 28/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [27][  0/390]\tTotal Loss -1.0619e+01 (-1.0619e+01)\tConsistency Loss 8.6650e-01 (8.6650e-01)\tEntropy 2.2971e+00 (2.2971e+00)\n",
            "Epoch: [27][ 25/390]\tTotal Loss -1.0588e+01 (-1.0561e+01)\tConsistency Loss 9.0674e-01 (9.2223e-01)\tEntropy 2.2989e+00 (2.2967e+00)\n",
            "Epoch: [27][ 50/390]\tTotal Loss -1.0595e+01 (-1.0553e+01)\tConsistency Loss 9.1015e-01 (9.2974e-01)\tEntropy 2.3010e+00 (2.2966e+00)\n",
            "Epoch: [27][ 75/390]\tTotal Loss -1.0361e+01 (-1.0564e+01)\tConsistency Loss 1.1337e+00 (9.1836e-01)\tEntropy 2.2990e+00 (2.2965e+00)\n",
            "Epoch: [27][100/390]\tTotal Loss -1.0596e+01 (-1.0562e+01)\tConsistency Loss 8.9790e-01 (9.2119e-01)\tEntropy 2.2989e+00 (2.2966e+00)\n",
            "Epoch: [27][125/390]\tTotal Loss -1.0569e+01 (-1.0557e+01)\tConsistency Loss 9.3357e-01 (9.2583e-01)\tEntropy 2.3004e+00 (2.2965e+00)\n",
            "Epoch: [27][150/390]\tTotal Loss -1.0619e+01 (-1.0556e+01)\tConsistency Loss 8.8276e-01 (9.2815e-01)\tEntropy 2.3003e+00 (2.2968e+00)\n",
            "Epoch: [27][175/390]\tTotal Loss -1.0697e+01 (-1.0555e+01)\tConsistency Loss 7.9956e-01 (9.2895e-01)\tEntropy 2.2992e+00 (2.2968e+00)\n",
            "Epoch: [27][200/390]\tTotal Loss -1.0508e+01 (-1.0555e+01)\tConsistency Loss 9.8682e-01 (9.2893e-01)\tEntropy 2.2989e+00 (2.2968e+00)\n",
            "Epoch: [27][225/390]\tTotal Loss -1.0560e+01 (-1.0554e+01)\tConsistency Loss 9.2939e-01 (9.2997e-01)\tEntropy 2.2978e+00 (2.2967e+00)\n",
            "Epoch: [27][250/390]\tTotal Loss -1.0557e+01 (-1.0558e+01)\tConsistency Loss 9.0992e-01 (9.2553e-01)\tEntropy 2.2934e+00 (2.2968e+00)\n",
            "Epoch: [27][275/390]\tTotal Loss -1.0591e+01 (-1.0559e+01)\tConsistency Loss 9.0764e-01 (9.2441e-01)\tEntropy 2.2998e+00 (2.2967e+00)\n",
            "Epoch: [27][300/390]\tTotal Loss -1.0433e+01 (-1.0556e+01)\tConsistency Loss 1.0253e+00 (9.2646e-01)\tEntropy 2.2916e+00 (2.2965e+00)\n",
            "Epoch: [27][325/390]\tTotal Loss -1.0505e+01 (-1.0557e+01)\tConsistency Loss 9.6308e-01 (9.2539e-01)\tEntropy 2.2935e+00 (2.2965e+00)\n",
            "Epoch: [27][350/390]\tTotal Loss -1.0437e+01 (-1.0557e+01)\tConsistency Loss 1.0509e+00 (9.2535e-01)\tEntropy 2.2975e+00 (2.2965e+00)\n",
            "Epoch: [27][375/390]\tTotal Loss -1.0570e+01 (-1.0559e+01)\tConsistency Loss 9.0959e-01 (9.2428e-01)\tEntropy 2.2959e+00 (2.2966e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.3002309799194336, 'consistency': 0.6826250553131104, 'total_loss': -1.6176059246063232}], 'lowest_loss_head': 0, 'lowest_loss': -1.6176059246063232}\n",
            "No new lowest loss on validation set: -1.6223 -> -1.6176\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6231, 'ARI': 0.43212402614165835, 'NMI': 0.5222164358922774, 'ACC Top-5': 0.9412, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 2), (4, 3), (5, 8), (6, 7), (7, 4), (8, 0), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 29/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [28][  0/390]\tTotal Loss -1.0570e+01 (-1.0570e+01)\tConsistency Loss 9.1852e-01 (9.1852e-01)\tEntropy 2.2978e+00 (2.2978e+00)\n",
            "Epoch: [28][ 25/390]\tTotal Loss -1.0465e+01 (-1.0572e+01)\tConsistency Loss 1.0157e+00 (9.1345e-01)\tEntropy 2.2961e+00 (2.2972e+00)\n",
            "Epoch: [28][ 50/390]\tTotal Loss -1.0566e+01 (-1.0566e+01)\tConsistency Loss 9.1355e-01 (9.2021e-01)\tEntropy 2.2958e+00 (2.2973e+00)\n",
            "Epoch: [28][ 75/390]\tTotal Loss -1.0611e+01 (-1.0567e+01)\tConsistency Loss 8.7926e-01 (9.1811e-01)\tEntropy 2.2980e+00 (2.2971e+00)\n",
            "Epoch: [28][100/390]\tTotal Loss -1.0549e+01 (-1.0569e+01)\tConsistency Loss 9.3581e-01 (9.1645e-01)\tEntropy 2.2970e+00 (2.2971e+00)\n",
            "Epoch: [28][125/390]\tTotal Loss -1.0576e+01 (-1.0569e+01)\tConsistency Loss 9.0652e-01 (9.1606e-01)\tEntropy 2.2964e+00 (2.2970e+00)\n",
            "Epoch: [28][150/390]\tTotal Loss -1.0535e+01 (-1.0567e+01)\tConsistency Loss 9.1334e-01 (9.1796e-01)\tEntropy 2.2896e+00 (2.2969e+00)\n",
            "Epoch: [28][175/390]\tTotal Loss -1.0589e+01 (-1.0563e+01)\tConsistency Loss 8.8458e-01 (9.2116e-01)\tEntropy 2.2947e+00 (2.2969e+00)\n",
            "Epoch: [28][200/390]\tTotal Loss -1.0452e+01 (-1.0561e+01)\tConsistency Loss 1.0277e+00 (9.2305e-01)\tEntropy 2.2960e+00 (2.2969e+00)\n",
            "Epoch: [28][225/390]\tTotal Loss -1.0356e+01 (-1.0561e+01)\tConsistency Loss 1.1058e+00 (9.2330e-01)\tEntropy 2.2923e+00 (2.2968e+00)\n",
            "Epoch: [28][250/390]\tTotal Loss -1.0421e+01 (-1.0563e+01)\tConsistency Loss 1.0506e+00 (9.2084e-01)\tEntropy 2.2943e+00 (2.2968e+00)\n",
            "Epoch: [28][275/390]\tTotal Loss -1.0529e+01 (-1.0563e+01)\tConsistency Loss 9.5464e-01 (9.2093e-01)\tEntropy 2.2968e+00 (2.2969e+00)\n",
            "Epoch: [28][300/390]\tTotal Loss -1.0544e+01 (-1.0562e+01)\tConsistency Loss 9.3626e-01 (9.2164e-01)\tEntropy 2.2960e+00 (2.2968e+00)\n",
            "Epoch: [28][325/390]\tTotal Loss -1.0540e+01 (-1.0562e+01)\tConsistency Loss 9.4809e-01 (9.2262e-01)\tEntropy 2.2976e+00 (2.2969e+00)\n",
            "Epoch: [28][350/390]\tTotal Loss -1.0474e+01 (-1.0562e+01)\tConsistency Loss 1.0041e+00 (9.2296e-01)\tEntropy 2.2956e+00 (2.2969e+00)\n",
            "Epoch: [28][375/390]\tTotal Loss -1.0620e+01 (-1.0563e+01)\tConsistency Loss 8.6790e-01 (9.2206e-01)\tEntropy 2.2975e+00 (2.2969e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.3014779090881348, 'consistency': 0.6836252808570862, 'total_loss': -1.6178526282310486}], 'lowest_loss_head': 0, 'lowest_loss': -1.6178526282310486}\n",
            "No new lowest loss on validation set: -1.6223 -> -1.6179\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6121, 'ARI': 0.4217341428230887, 'NMI': 0.516397033625968, 'ACC Top-5': 0.9204, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 30/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [29][  0/390]\tTotal Loss -1.0526e+01 (-1.0526e+01)\tConsistency Loss 9.4057e-01 (9.4057e-01)\tEntropy 2.2933e+00 (2.2933e+00)\n",
            "Epoch: [29][ 25/390]\tTotal Loss -1.0634e+01 (-1.0577e+01)\tConsistency Loss 8.5801e-01 (9.0850e-01)\tEntropy 2.2985e+00 (2.2971e+00)\n",
            "Epoch: [29][ 50/390]\tTotal Loss -1.0586e+01 (-1.0564e+01)\tConsistency Loss 8.9688e-01 (9.2120e-01)\tEntropy 2.2967e+00 (2.2971e+00)\n",
            "Epoch: [29][ 75/390]\tTotal Loss -1.0464e+01 (-1.0558e+01)\tConsistency Loss 1.0231e+00 (9.2726e-01)\tEntropy 2.2974e+00 (2.2970e+00)\n",
            "Epoch: [29][100/390]\tTotal Loss -1.0426e+01 (-1.0556e+01)\tConsistency Loss 1.0315e+00 (9.2978e-01)\tEntropy 2.2914e+00 (2.2971e+00)\n",
            "Epoch: [29][125/390]\tTotal Loss -1.0588e+01 (-1.0558e+01)\tConsistency Loss 8.9042e-01 (9.2706e-01)\tEntropy 2.2957e+00 (2.2970e+00)\n",
            "Epoch: [29][150/390]\tTotal Loss -1.0637e+01 (-1.0562e+01)\tConsistency Loss 8.4904e-01 (9.2309e-01)\tEntropy 2.2972e+00 (2.2969e+00)\n",
            "Epoch: [29][175/390]\tTotal Loss -1.0519e+01 (-1.0561e+01)\tConsistency Loss 9.7978e-01 (9.2288e-01)\tEntropy 2.2997e+00 (2.2968e+00)\n",
            "Epoch: [29][200/390]\tTotal Loss -1.0620e+01 (-1.0563e+01)\tConsistency Loss 8.3819e-01 (9.2152e-01)\tEntropy 2.2916e+00 (2.2969e+00)\n",
            "Epoch: [29][225/390]\tTotal Loss -1.0505e+01 (-1.0562e+01)\tConsistency Loss 9.8024e-01 (9.2227e-01)\tEntropy 2.2971e+00 (2.2969e+00)\n",
            "Epoch: [29][250/390]\tTotal Loss -1.0710e+01 (-1.0565e+01)\tConsistency Loss 7.8062e-01 (9.1991e-01)\tEntropy 2.2981e+00 (2.2969e+00)\n",
            "Epoch: [29][275/390]\tTotal Loss -1.0539e+01 (-1.0564e+01)\tConsistency Loss 9.5192e-01 (9.1991e-01)\tEntropy 2.2981e+00 (2.2968e+00)\n",
            "Epoch: [29][300/390]\tTotal Loss -1.0648e+01 (-1.0566e+01)\tConsistency Loss 8.1182e-01 (9.1787e-01)\tEntropy 2.2920e+00 (2.2968e+00)\n",
            "Epoch: [29][325/390]\tTotal Loss -1.0547e+01 (-1.0565e+01)\tConsistency Loss 9.3640e-01 (9.1890e-01)\tEntropy 2.2967e+00 (2.2969e+00)\n",
            "Epoch: [29][350/390]\tTotal Loss -1.0567e+01 (-1.0567e+01)\tConsistency Loss 9.2874e-01 (9.1739e-01)\tEntropy 2.2991e+00 (2.2969e+00)\n",
            "Epoch: [29][375/390]\tTotal Loss -1.0498e+01 (-1.0566e+01)\tConsistency Loss 9.7927e-01 (9.1857e-01)\tEntropy 2.2954e+00 (2.2969e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.300029754638672, 'consistency': 0.6824595928192139, 'total_loss': -1.617570161819458}], 'lowest_loss_head': 0, 'lowest_loss': -1.617570161819458}\n",
            "No new lowest loss on validation set: -1.6223 -> -1.6176\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6185, 'ARI': 0.4263835119218247, 'NMI': 0.5197413768451212, 'ACC Top-5': 0.9443, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 2), (4, 3), (5, 8), (6, 7), (7, 4), (8, 0), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 31/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [30][  0/390]\tTotal Loss -1.0511e+01 (-1.0511e+01)\tConsistency Loss 9.7186e-01 (9.7186e-01)\tEntropy 2.2967e+00 (2.2967e+00)\n",
            "Epoch: [30][ 25/390]\tTotal Loss -1.0405e+01 (-1.0555e+01)\tConsistency Loss 1.0717e+00 (9.3023e-01)\tEntropy 2.2953e+00 (2.2971e+00)\n",
            "Epoch: [30][ 50/390]\tTotal Loss -1.0532e+01 (-1.0569e+01)\tConsistency Loss 9.3374e-01 (9.1395e-01)\tEntropy 2.2931e+00 (2.2966e+00)\n",
            "Epoch: [30][ 75/390]\tTotal Loss -1.0605e+01 (-1.0573e+01)\tConsistency Loss 8.8545e-01 (9.0918e-01)\tEntropy 2.2981e+00 (2.2964e+00)\n",
            "Epoch: [30][100/390]\tTotal Loss -1.0641e+01 (-1.0575e+01)\tConsistency Loss 8.4106e-01 (9.0682e-01)\tEntropy 2.2964e+00 (2.2964e+00)\n",
            "Epoch: [30][125/390]\tTotal Loss -1.0702e+01 (-1.0574e+01)\tConsistency Loss 7.9068e-01 (9.0815e-01)\tEntropy 2.2984e+00 (2.2964e+00)\n",
            "Epoch: [30][150/390]\tTotal Loss -1.0550e+01 (-1.0574e+01)\tConsistency Loss 9.4052e-01 (9.0805e-01)\tEntropy 2.2981e+00 (2.2963e+00)\n",
            "Epoch: [30][175/390]\tTotal Loss -1.0486e+01 (-1.0574e+01)\tConsistency Loss 1.0030e+00 (9.0835e-01)\tEntropy 2.2979e+00 (2.2965e+00)\n",
            "Epoch: [30][200/390]\tTotal Loss -1.0759e+01 (-1.0572e+01)\tConsistency Loss 7.2340e-01 (9.1094e-01)\tEntropy 2.2965e+00 (2.2966e+00)\n",
            "Epoch: [30][225/390]\tTotal Loss -1.0576e+01 (-1.0571e+01)\tConsistency Loss 8.9857e-01 (9.1179e-01)\tEntropy 2.2950e+00 (2.2966e+00)\n",
            "Epoch: [30][250/390]\tTotal Loss -1.0571e+01 (-1.0571e+01)\tConsistency Loss 9.0666e-01 (9.1165e-01)\tEntropy 2.2955e+00 (2.2966e+00)\n",
            "Epoch: [30][275/390]\tTotal Loss -1.0527e+01 (-1.0569e+01)\tConsistency Loss 9.4725e-01 (9.1344e-01)\tEntropy 2.2949e+00 (2.2965e+00)\n",
            "Epoch: [30][300/390]\tTotal Loss -1.0534e+01 (-1.0572e+01)\tConsistency Loss 9.4939e-01 (9.1123e-01)\tEntropy 2.2967e+00 (2.2966e+00)\n",
            "Epoch: [30][325/390]\tTotal Loss -1.0538e+01 (-1.0571e+01)\tConsistency Loss 9.3534e-01 (9.1195e-01)\tEntropy 2.2947e+00 (2.2967e+00)\n",
            "Epoch: [30][350/390]\tTotal Loss -1.0595e+01 (-1.0572e+01)\tConsistency Loss 9.0883e-01 (9.1122e-01)\tEntropy 2.3007e+00 (2.2967e+00)\n",
            "Epoch: [30][375/390]\tTotal Loss -1.0406e+01 (-1.0572e+01)\tConsistency Loss 1.0381e+00 (9.1162e-01)\tEntropy 2.2889e+00 (2.2966e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.2996249198913574, 'consistency': 0.6815075278282166, 'total_loss': -1.6181173920631409}], 'lowest_loss_head': 0, 'lowest_loss': -1.6181173920631409}\n",
            "No new lowest loss on validation set: -1.6223 -> -1.6181\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6237, 'ARI': 0.43676277300350247, 'NMI': 0.522515338043008, 'ACC Top-5': 0.9092, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 32/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [31][  0/390]\tTotal Loss -1.0627e+01 (-1.0627e+01)\tConsistency Loss 8.5338e-01 (8.5338e-01)\tEntropy 2.2960e+00 (2.2960e+00)\n",
            "Epoch: [31][ 25/390]\tTotal Loss -1.0592e+01 (-1.0570e+01)\tConsistency Loss 9.0776e-01 (9.1529e-01)\tEntropy 2.2999e+00 (2.2971e+00)\n",
            "Epoch: [31][ 50/390]\tTotal Loss -1.0645e+01 (-1.0574e+01)\tConsistency Loss 8.1702e-01 (9.1076e-01)\tEntropy 2.2925e+00 (2.2969e+00)\n",
            "Epoch: [31][ 75/390]\tTotal Loss -1.0565e+01 (-1.0569e+01)\tConsistency Loss 9.1552e-01 (9.1204e-01)\tEntropy 2.2961e+00 (2.2963e+00)\n",
            "Epoch: [31][100/390]\tTotal Loss -1.0472e+01 (-1.0569e+01)\tConsistency Loss 9.9993e-01 (9.1137e-01)\tEntropy 2.2944e+00 (2.2962e+00)\n",
            "Epoch: [31][125/390]\tTotal Loss -1.0448e+01 (-1.0575e+01)\tConsistency Loss 1.0143e+00 (9.0745e-01)\tEntropy 2.2925e+00 (2.2966e+00)\n",
            "Epoch: [31][150/390]\tTotal Loss -1.0662e+01 (-1.0574e+01)\tConsistency Loss 8.3697e-01 (9.0891e-01)\tEntropy 2.2998e+00 (2.2966e+00)\n",
            "Epoch: [31][175/390]\tTotal Loss -1.0441e+01 (-1.0577e+01)\tConsistency Loss 1.0427e+00 (9.0586e-01)\tEntropy 2.2967e+00 (2.2965e+00)\n",
            "Epoch: [31][200/390]\tTotal Loss -1.0513e+01 (-1.0573e+01)\tConsistency Loss 9.8198e-01 (9.0932e-01)\tEntropy 2.2990e+00 (2.2965e+00)\n",
            "Epoch: [31][225/390]\tTotal Loss -1.0804e+01 (-1.0572e+01)\tConsistency Loss 6.9516e-01 (9.1130e-01)\tEntropy 2.2998e+00 (2.2966e+00)\n",
            "Epoch: [31][250/390]\tTotal Loss -1.0501e+01 (-1.0570e+01)\tConsistency Loss 9.5986e-01 (9.1236e-01)\tEntropy 2.2922e+00 (2.2965e+00)\n",
            "Epoch: [31][275/390]\tTotal Loss -1.0532e+01 (-1.0568e+01)\tConsistency Loss 9.5756e-01 (9.1471e-01)\tEntropy 2.2980e+00 (2.2966e+00)\n",
            "Epoch: [31][300/390]\tTotal Loss -1.0547e+01 (-1.0567e+01)\tConsistency Loss 9.4816e-01 (9.1584e-01)\tEntropy 2.2990e+00 (2.2965e+00)\n",
            "Epoch: [31][325/390]\tTotal Loss -1.0618e+01 (-1.0566e+01)\tConsistency Loss 8.6917e-01 (9.1715e-01)\tEntropy 2.2974e+00 (2.2966e+00)\n",
            "Epoch: [31][350/390]\tTotal Loss -1.0522e+01 (-1.0565e+01)\tConsistency Loss 9.6462e-01 (9.1796e-01)\tEntropy 2.2973e+00 (2.2966e+00)\n",
            "Epoch: [31][375/390]\tTotal Loss -1.0412e+01 (-1.0566e+01)\tConsistency Loss 1.0501e+00 (9.1771e-01)\tEntropy 2.2924e+00 (2.2967e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.2989566326141357, 'consistency': 0.6819679141044617, 'total_loss': -1.616988718509674}], 'lowest_loss_head': 0, 'lowest_loss': -1.616988718509674}\n",
            "No new lowest loss on validation set: -1.6223 -> -1.6170\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.616, 'ARI': 0.4265729991251785, 'NMI': 0.5148638350856203, 'ACC Top-5': 0.9361, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 2), (4, 3), (5, 8), (6, 7), (7, 4), (8, 0), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 33/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [32][  0/390]\tTotal Loss -1.0313e+01 (-1.0313e+01)\tConsistency Loss 1.1694e+00 (1.1694e+00)\tEntropy 2.2965e+00 (2.2965e+00)\n",
            "Epoch: [32][ 25/390]\tTotal Loss -1.0341e+01 (-1.0545e+01)\tConsistency Loss 1.1127e+00 (9.3977e-01)\tEntropy 2.2908e+00 (2.2970e+00)\n",
            "Epoch: [32][ 50/390]\tTotal Loss -1.0492e+01 (-1.0556e+01)\tConsistency Loss 9.9868e-01 (9.2917e-01)\tEntropy 2.2981e+00 (2.2969e+00)\n",
            "Epoch: [32][ 75/390]\tTotal Loss -1.0430e+01 (-1.0557e+01)\tConsistency Loss 1.0627e+00 (9.2673e-01)\tEntropy 2.2986e+00 (2.2967e+00)\n",
            "Epoch: [32][100/390]\tTotal Loss -1.0478e+01 (-1.0560e+01)\tConsistency Loss 9.8021e-01 (9.2199e-01)\tEntropy 2.2916e+00 (2.2964e+00)\n",
            "Epoch: [32][125/390]\tTotal Loss -1.0598e+01 (-1.0562e+01)\tConsistency Loss 8.7494e-01 (9.2084e-01)\tEntropy 2.2946e+00 (2.2967e+00)\n",
            "Epoch: [32][150/390]\tTotal Loss -1.0530e+01 (-1.0564e+01)\tConsistency Loss 9.5490e-01 (9.2008e-01)\tEntropy 2.2970e+00 (2.2968e+00)\n",
            "Epoch: [32][175/390]\tTotal Loss -1.0586e+01 (-1.0569e+01)\tConsistency Loss 8.9797e-01 (9.1576e-01)\tEntropy 2.2969e+00 (2.2969e+00)\n",
            "Epoch: [32][200/390]\tTotal Loss -1.0575e+01 (-1.0570e+01)\tConsistency Loss 8.7715e-01 (9.1412e-01)\tEntropy 2.2904e+00 (2.2968e+00)\n",
            "Epoch: [32][225/390]\tTotal Loss -1.0636e+01 (-1.0567e+01)\tConsistency Loss 8.3576e-01 (9.1705e-01)\tEntropy 2.2943e+00 (2.2968e+00)\n",
            "Epoch: [32][250/390]\tTotal Loss -1.0322e+01 (-1.0567e+01)\tConsistency Loss 1.1495e+00 (9.1763e-01)\tEntropy 2.2943e+00 (2.2969e+00)\n",
            "Epoch: [32][275/390]\tTotal Loss -1.0616e+01 (-1.0567e+01)\tConsistency Loss 8.5537e-01 (9.1731e-01)\tEntropy 2.2942e+00 (2.2969e+00)\n",
            "Epoch: [32][300/390]\tTotal Loss -1.0480e+01 (-1.0568e+01)\tConsistency Loss 1.0093e+00 (9.1681e-01)\tEntropy 2.2979e+00 (2.2969e+00)\n",
            "Epoch: [32][325/390]\tTotal Loss -1.0679e+01 (-1.0568e+01)\tConsistency Loss 7.9047e-01 (9.1669e-01)\tEntropy 2.2938e+00 (2.2970e+00)\n",
            "Epoch: [32][350/390]\tTotal Loss -1.0540e+01 (-1.0570e+01)\tConsistency Loss 9.5002e-01 (9.1492e-01)\tEntropy 2.2980e+00 (2.2970e+00)\n",
            "Epoch: [32][375/390]\tTotal Loss -1.0569e+01 (-1.0572e+01)\tConsistency Loss 9.1933e-01 (9.1282e-01)\tEntropy 2.2977e+00 (2.2970e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.30147647857666, 'consistency': 0.6735148429870605, 'total_loss': -1.6279616355895996}], 'lowest_loss_head': 0, 'lowest_loss': -1.6279616355895996}\n",
            "New lowest loss on validation set: -1.6223 -> -1.6280\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6246, 'ARI': 0.4346863477983936, 'NMI': 0.5216780908874682, 'ACC Top-5': 0.931, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 2), (4, 3), (5, 8), (6, 7), (7, 4), (8, 0), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 34/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [33][  0/390]\tTotal Loss -1.0556e+01 (-1.0556e+01)\tConsistency Loss 9.3861e-01 (9.3861e-01)\tEntropy 2.2989e+00 (2.2989e+00)\n",
            "Epoch: [33][ 25/390]\tTotal Loss -1.0576e+01 (-1.0579e+01)\tConsistency Loss 8.8755e-01 (9.0366e-01)\tEntropy 2.2926e+00 (2.2966e+00)\n",
            "Epoch: [33][ 50/390]\tTotal Loss -1.0471e+01 (-1.0585e+01)\tConsistency Loss 1.0095e+00 (9.0075e-01)\tEntropy 2.2961e+00 (2.2971e+00)\n",
            "Epoch: [33][ 75/390]\tTotal Loss -1.0534e+01 (-1.0585e+01)\tConsistency Loss 9.4649e-01 (9.0042e-01)\tEntropy 2.2962e+00 (2.2971e+00)\n",
            "Epoch: [33][100/390]\tTotal Loss -1.0605e+01 (-1.0581e+01)\tConsistency Loss 8.7817e-01 (9.0518e-01)\tEntropy 2.2966e+00 (2.2972e+00)\n",
            "Epoch: [33][125/390]\tTotal Loss -1.0487e+01 (-1.0576e+01)\tConsistency Loss 9.7979e-01 (9.0879e-01)\tEntropy 2.2934e+00 (2.2970e+00)\n",
            "Epoch: [33][150/390]\tTotal Loss -1.0545e+01 (-1.0573e+01)\tConsistency Loss 9.4509e-01 (9.1228e-01)\tEntropy 2.2980e+00 (2.2970e+00)\n",
            "Epoch: [33][175/390]\tTotal Loss -1.0700e+01 (-1.0570e+01)\tConsistency Loss 7.8062e-01 (9.1469e-01)\tEntropy 2.2961e+00 (2.2970e+00)\n",
            "Epoch: [33][200/390]\tTotal Loss -1.0687e+01 (-1.0571e+01)\tConsistency Loss 8.0523e-01 (9.1432e-01)\tEntropy 2.2984e+00 (2.2971e+00)\n",
            "Epoch: [33][225/390]\tTotal Loss -1.0561e+01 (-1.0571e+01)\tConsistency Loss 9.3484e-01 (9.1430e-01)\tEntropy 2.2991e+00 (2.2971e+00)\n",
            "Epoch: [33][250/390]\tTotal Loss -1.0556e+01 (-1.0569e+01)\tConsistency Loss 9.3757e-01 (9.1720e-01)\tEntropy 2.2988e+00 (2.2973e+00)\n",
            "Epoch: [33][275/390]\tTotal Loss -1.0649e+01 (-1.0570e+01)\tConsistency Loss 8.3149e-01 (9.1662e-01)\tEntropy 2.2960e+00 (2.2973e+00)\n",
            "Epoch: [33][300/390]\tTotal Loss -1.0729e+01 (-1.0569e+01)\tConsistency Loss 7.4360e-01 (9.1714e-01)\tEntropy 2.2946e+00 (2.2973e+00)\n",
            "Epoch: [33][325/390]\tTotal Loss -1.0595e+01 (-1.0570e+01)\tConsistency Loss 8.8563e-01 (9.1537e-01)\tEntropy 2.2961e+00 (2.2971e+00)\n",
            "Epoch: [33][350/390]\tTotal Loss -1.0456e+01 (-1.0570e+01)\tConsistency Loss 1.0021e+00 (9.1601e-01)\tEntropy 2.2917e+00 (2.2971e+00)\n",
            "Epoch: [33][375/390]\tTotal Loss -1.0659e+01 (-1.0570e+01)\tConsistency Loss 8.4315e-01 (9.1525e-01)\tEntropy 2.3004e+00 (2.2971e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.301335573196411, 'consistency': 0.6788887977600098, 'total_loss': -1.6224467754364014}], 'lowest_loss_head': 0, 'lowest_loss': -1.6224467754364014}\n",
            "No new lowest loss on validation set: -1.6280 -> -1.6224\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6169, 'ARI': 0.4273101393369027, 'NMI': 0.5155840145508708, 'ACC Top-5': 0.916, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 35/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [34][  0/390]\tTotal Loss -1.0513e+01 (-1.0513e+01)\tConsistency Loss 9.4946e-01 (9.4946e-01)\tEntropy 2.2924e+00 (2.2924e+00)\n",
            "Epoch: [34][ 25/390]\tTotal Loss -1.0540e+01 (-1.0554e+01)\tConsistency Loss 9.6064e-01 (9.3196e-01)\tEntropy 2.3001e+00 (2.2973e+00)\n",
            "Epoch: [34][ 50/390]\tTotal Loss -1.0579e+01 (-1.0569e+01)\tConsistency Loss 9.0390e-01 (9.1507e-01)\tEntropy 2.2965e+00 (2.2969e+00)\n",
            "Epoch: [34][ 75/390]\tTotal Loss -1.0602e+01 (-1.0579e+01)\tConsistency Loss 8.8536e-01 (9.0732e-01)\tEntropy 2.2974e+00 (2.2972e+00)\n",
            "Epoch: [34][100/390]\tTotal Loss -1.0672e+01 (-1.0582e+01)\tConsistency Loss 8.1146e-01 (9.0263e-01)\tEntropy 2.2968e+00 (2.2969e+00)\n",
            "Epoch: [34][125/390]\tTotal Loss -1.0605e+01 (-1.0574e+01)\tConsistency Loss 8.7714e-01 (9.0996e-01)\tEntropy 2.2965e+00 (2.2968e+00)\n",
            "Epoch: [34][150/390]\tTotal Loss -1.0561e+01 (-1.0580e+01)\tConsistency Loss 9.1812e-01 (9.0415e-01)\tEntropy 2.2958e+00 (2.2968e+00)\n",
            "Epoch: [34][175/390]\tTotal Loss -1.0694e+01 (-1.0579e+01)\tConsistency Loss 7.7801e-01 (9.0414e-01)\tEntropy 2.2944e+00 (2.2967e+00)\n",
            "Epoch: [34][200/390]\tTotal Loss -1.0531e+01 (-1.0578e+01)\tConsistency Loss 9.4474e-01 (9.0544e-01)\tEntropy 2.2952e+00 (2.2968e+00)\n",
            "Epoch: [34][225/390]\tTotal Loss -1.0584e+01 (-1.0578e+01)\tConsistency Loss 9.0522e-01 (9.0602e-01)\tEntropy 2.2979e+00 (2.2968e+00)\n",
            "Epoch: [34][250/390]\tTotal Loss -1.0489e+01 (-1.0580e+01)\tConsistency Loss 9.9375e-01 (9.0371e-01)\tEntropy 2.2965e+00 (2.2968e+00)\n",
            "Epoch: [34][275/390]\tTotal Loss -1.0615e+01 (-1.0580e+01)\tConsistency Loss 8.7232e-01 (9.0400e-01)\tEntropy 2.2975e+00 (2.2968e+00)\n",
            "Epoch: [34][300/390]\tTotal Loss -1.0514e+01 (-1.0581e+01)\tConsistency Loss 9.7099e-01 (9.0278e-01)\tEntropy 2.2970e+00 (2.2968e+00)\n",
            "Epoch: [34][325/390]\tTotal Loss -1.0534e+01 (-1.0581e+01)\tConsistency Loss 9.6529e-01 (9.0302e-01)\tEntropy 2.2998e+00 (2.2968e+00)\n",
            "Epoch: [34][350/390]\tTotal Loss -1.0632e+01 (-1.0581e+01)\tConsistency Loss 8.5286e-01 (9.0306e-01)\tEntropy 2.2969e+00 (2.2969e+00)\n",
            "Epoch: [34][375/390]\tTotal Loss -1.0658e+01 (-1.0579e+01)\tConsistency Loss 8.1687e-01 (9.0540e-01)\tEntropy 2.2950e+00 (2.2969e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.300713062286377, 'consistency': 0.6734636425971985, 'total_loss': -1.6272494196891785}], 'lowest_loss_head': 0, 'lowest_loss': -1.6272494196891785}\n",
            "No new lowest loss on validation set: -1.6280 -> -1.6272\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6217, 'ARI': 0.43624050953389276, 'NMI': 0.5254790509248223, 'ACC Top-5': 0.908, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 36/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [35][  0/390]\tTotal Loss -1.0630e+01 (-1.0630e+01)\tConsistency Loss 8.6170e-01 (8.6170e-01)\tEntropy 2.2983e+00 (2.2983e+00)\n",
            "Epoch: [35][ 25/390]\tTotal Loss -1.0642e+01 (-1.0603e+01)\tConsistency Loss 8.5230e-01 (8.8423e-01)\tEntropy 2.2989e+00 (2.2975e+00)\n",
            "Epoch: [35][ 50/390]\tTotal Loss -1.0578e+01 (-1.0598e+01)\tConsistency Loss 9.2077e-01 (8.8741e-01)\tEntropy 2.2998e+00 (2.2970e+00)\n",
            "Epoch: [35][ 75/390]\tTotal Loss -1.0600e+01 (-1.0589e+01)\tConsistency Loss 9.0224e-01 (8.9582e-01)\tEntropy 2.3005e+00 (2.2970e+00)\n",
            "Epoch: [35][100/390]\tTotal Loss -1.0673e+01 (-1.0594e+01)\tConsistency Loss 8.1521e-01 (8.8935e-01)\tEntropy 2.2976e+00 (2.2967e+00)\n",
            "Epoch: [35][125/390]\tTotal Loss -1.0495e+01 (-1.0589e+01)\tConsistency Loss 9.9206e-01 (8.9419e-01)\tEntropy 2.2974e+00 (2.2967e+00)\n",
            "Epoch: [35][150/390]\tTotal Loss -1.0463e+01 (-1.0588e+01)\tConsistency Loss 1.0154e+00 (8.9575e-01)\tEntropy 2.2957e+00 (2.2968e+00)\n",
            "Epoch: [35][175/390]\tTotal Loss -1.0645e+01 (-1.0591e+01)\tConsistency Loss 8.5695e-01 (8.9257e-01)\tEntropy 2.3003e+00 (2.2967e+00)\n",
            "Epoch: [35][200/390]\tTotal Loss -1.0644e+01 (-1.0590e+01)\tConsistency Loss 8.5033e-01 (8.9327e-01)\tEntropy 2.2989e+00 (2.2967e+00)\n",
            "Epoch: [35][225/390]\tTotal Loss -1.0613e+01 (-1.0588e+01)\tConsistency Loss 8.4571e-01 (8.9522e-01)\tEntropy 2.2917e+00 (2.2966e+00)\n",
            "Epoch: [35][250/390]\tTotal Loss -1.0659e+01 (-1.0588e+01)\tConsistency Loss 8.1933e-01 (8.9558e-01)\tEntropy 2.2956e+00 (2.2966e+00)\n",
            "Epoch: [35][275/390]\tTotal Loss -1.0593e+01 (-1.0588e+01)\tConsistency Loss 8.9163e-01 (8.9515e-01)\tEntropy 2.2970e+00 (2.2966e+00)\n",
            "Epoch: [35][300/390]\tTotal Loss -1.0707e+01 (-1.0588e+01)\tConsistency Loss 7.8860e-01 (8.9518e-01)\tEntropy 2.2991e+00 (2.2967e+00)\n",
            "Epoch: [35][325/390]\tTotal Loss -1.0627e+01 (-1.0587e+01)\tConsistency Loss 8.5718e-01 (8.9659e-01)\tEntropy 2.2968e+00 (2.2967e+00)\n",
            "Epoch: [35][350/390]\tTotal Loss -1.0549e+01 (-1.0583e+01)\tConsistency Loss 9.5324e-01 (9.0072e-01)\tEntropy 2.3004e+00 (2.2967e+00)\n",
            "Epoch: [35][375/390]\tTotal Loss -1.0609e+01 (-1.0582e+01)\tConsistency Loss 8.7309e-01 (9.0099e-01)\tEntropy 2.2965e+00 (2.2967e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.297609806060791, 'consistency': 0.676827609539032, 'total_loss': -1.620782196521759}], 'lowest_loss_head': 0, 'lowest_loss': -1.620782196521759}\n",
            "No new lowest loss on validation set: -1.6280 -> -1.6208\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.624, 'ARI': 0.43365217845111614, 'NMI': 0.5210524764800448, 'ACC Top-5': 0.9162, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 37/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [36][  0/390]\tTotal Loss -1.0740e+01 (-1.0740e+01)\tConsistency Loss 7.1803e-01 (7.1803e-01)\tEntropy 2.2916e+00 (2.2916e+00)\n",
            "Epoch: [36][ 25/390]\tTotal Loss -1.0564e+01 (-1.0572e+01)\tConsistency Loss 9.3182e-01 (9.0999e-01)\tEntropy 2.2992e+00 (2.2963e+00)\n",
            "Epoch: [36][ 50/390]\tTotal Loss -1.0708e+01 (-1.0580e+01)\tConsistency Loss 7.7406e-01 (9.0399e-01)\tEntropy 2.2965e+00 (2.2968e+00)\n",
            "Epoch: [36][ 75/390]\tTotal Loss -1.0590e+01 (-1.0583e+01)\tConsistency Loss 8.7609e-01 (9.0014e-01)\tEntropy 2.2931e+00 (2.2966e+00)\n",
            "Epoch: [36][100/390]\tTotal Loss -1.0688e+01 (-1.0583e+01)\tConsistency Loss 7.9028e-01 (9.0039e-01)\tEntropy 2.2956e+00 (2.2967e+00)\n",
            "Epoch: [36][125/390]\tTotal Loss -1.0531e+01 (-1.0583e+01)\tConsistency Loss 9.5879e-01 (9.0055e-01)\tEntropy 2.2979e+00 (2.2967e+00)\n",
            "Epoch: [36][150/390]\tTotal Loss -1.0630e+01 (-1.0576e+01)\tConsistency Loss 8.6400e-01 (9.0756e-01)\tEntropy 2.2988e+00 (2.2967e+00)\n",
            "Epoch: [36][175/390]\tTotal Loss -1.0339e+01 (-1.0573e+01)\tConsistency Loss 1.1341e+00 (9.0953e-01)\tEntropy 2.2946e+00 (2.2966e+00)\n",
            "Epoch: [36][200/390]\tTotal Loss -1.0507e+01 (-1.0574e+01)\tConsistency Loss 9.6340e-01 (9.0914e-01)\tEntropy 2.2942e+00 (2.2966e+00)\n",
            "Epoch: [36][225/390]\tTotal Loss -1.0692e+01 (-1.0578e+01)\tConsistency Loss 7.8296e-01 (9.0493e-01)\tEntropy 2.2950e+00 (2.2967e+00)\n",
            "Epoch: [36][250/390]\tTotal Loss -1.0669e+01 (-1.0577e+01)\tConsistency Loss 8.1864e-01 (9.0540e-01)\tEntropy 2.2976e+00 (2.2966e+00)\n",
            "Epoch: [36][275/390]\tTotal Loss -1.0642e+01 (-1.0580e+01)\tConsistency Loss 8.3921e-01 (9.0247e-01)\tEntropy 2.2963e+00 (2.2966e+00)\n",
            "Epoch: [36][300/390]\tTotal Loss -1.0541e+01 (-1.0580e+01)\tConsistency Loss 9.4791e-01 (9.0336e-01)\tEntropy 2.2979e+00 (2.2966e+00)\n",
            "Epoch: [36][325/390]\tTotal Loss -1.0566e+01 (-1.0581e+01)\tConsistency Loss 9.1434e-01 (9.0234e-01)\tEntropy 2.2962e+00 (2.2966e+00)\n",
            "Epoch: [36][350/390]\tTotal Loss -1.0458e+01 (-1.0580e+01)\tConsistency Loss 1.0126e+00 (9.0375e-01)\tEntropy 2.2941e+00 (2.2967e+00)\n",
            "Epoch: [36][375/390]\tTotal Loss -1.0451e+01 (-1.0581e+01)\tConsistency Loss 1.0454e+00 (9.0279e-01)\tEntropy 2.2993e+00 (2.2967e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.3000502586364746, 'consistency': 0.6756669878959656, 'total_loss': -1.624383270740509}], 'lowest_loss_head': 0, 'lowest_loss': -1.624383270740509}\n",
            "No new lowest loss on validation set: -1.6280 -> -1.6244\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6265, 'ARI': 0.43632306420111033, 'NMI': 0.5244955196721836, 'ACC Top-5': 0.919, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 38/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [37][  0/390]\tTotal Loss -1.0509e+01 (-1.0509e+01)\tConsistency Loss 9.5647e-01 (9.5647e-01)\tEntropy 2.2930e+00 (2.2930e+00)\n",
            "Epoch: [37][ 25/390]\tTotal Loss -1.0585e+01 (-1.0584e+01)\tConsistency Loss 9.2612e-01 (9.0235e-01)\tEntropy 2.3021e+00 (2.2972e+00)\n",
            "Epoch: [37][ 50/390]\tTotal Loss -1.0589e+01 (-1.0586e+01)\tConsistency Loss 9.0137e-01 (9.0089e-01)\tEntropy 2.2980e+00 (2.2973e+00)\n",
            "Epoch: [37][ 75/390]\tTotal Loss -1.0669e+01 (-1.0593e+01)\tConsistency Loss 8.3050e-01 (8.9389e-01)\tEntropy 2.2998e+00 (2.2974e+00)\n",
            "Epoch: [37][100/390]\tTotal Loss -1.0691e+01 (-1.0593e+01)\tConsistency Loss 7.8755e-01 (8.9371e-01)\tEntropy 2.2956e+00 (2.2973e+00)\n",
            "Epoch: [37][125/390]\tTotal Loss -1.0790e+01 (-1.0596e+01)\tConsistency Loss 7.0575e-01 (8.9069e-01)\tEntropy 2.2992e+00 (2.2973e+00)\n",
            "Epoch: [37][150/390]\tTotal Loss -1.0679e+01 (-1.0596e+01)\tConsistency Loss 8.0141e-01 (8.9050e-01)\tEntropy 2.2961e+00 (2.2973e+00)\n",
            "Epoch: [37][175/390]\tTotal Loss -1.0627e+01 (-1.0589e+01)\tConsistency Loss 8.6406e-01 (8.9648e-01)\tEntropy 2.2982e+00 (2.2971e+00)\n",
            "Epoch: [37][200/390]\tTotal Loss -1.0701e+01 (-1.0587e+01)\tConsistency Loss 7.7897e-01 (8.9781e-01)\tEntropy 2.2961e+00 (2.2970e+00)\n",
            "Epoch: [37][225/390]\tTotal Loss -1.0450e+01 (-1.0590e+01)\tConsistency Loss 1.0395e+00 (8.9594e-01)\tEntropy 2.2978e+00 (2.2971e+00)\n",
            "Epoch: [37][250/390]\tTotal Loss -1.0511e+01 (-1.0588e+01)\tConsistency Loss 9.8624e-01 (8.9702e-01)\tEntropy 2.2995e+00 (2.2971e+00)\n",
            "Epoch: [37][275/390]\tTotal Loss -1.0626e+01 (-1.0587e+01)\tConsistency Loss 8.5172e-01 (8.9775e-01)\tEntropy 2.2956e+00 (2.2970e+00)\n",
            "Epoch: [37][300/390]\tTotal Loss -1.0524e+01 (-1.0586e+01)\tConsistency Loss 9.7284e-01 (8.9918e-01)\tEntropy 2.2994e+00 (2.2970e+00)\n",
            "Epoch: [37][325/390]\tTotal Loss -1.0777e+01 (-1.0587e+01)\tConsistency Loss 7.0749e-01 (8.9846e-01)\tEntropy 2.2969e+00 (2.2971e+00)\n",
            "Epoch: [37][350/390]\tTotal Loss -1.0643e+01 (-1.0588e+01)\tConsistency Loss 8.3953e-01 (8.9775e-01)\tEntropy 2.2964e+00 (2.2971e+00)\n",
            "Epoch: [37][375/390]\tTotal Loss -1.0619e+01 (-1.0587e+01)\tConsistency Loss 8.7801e-01 (8.9843e-01)\tEntropy 2.2995e+00 (2.2971e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.300400495529175, 'consistency': 0.671099066734314, 'total_loss': -1.6293014287948608}], 'lowest_loss_head': 0, 'lowest_loss': -1.6293014287948608}\n",
            "New lowest loss on validation set: -1.6280 -> -1.6293\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6265, 'ARI': 0.433989248719623, 'NMI': 0.5213244744099115, 'ACC Top-5': 0.94, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 2), (4, 3), (5, 8), (6, 7), (7, 4), (8, 0), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 39/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [38][  0/390]\tTotal Loss -1.0625e+01 (-1.0625e+01)\tConsistency Loss 8.2725e-01 (8.2725e-01)\tEntropy 2.2905e+00 (2.2905e+00)\n",
            "Epoch: [38][ 25/390]\tTotal Loss -1.0597e+01 (-1.0598e+01)\tConsistency Loss 8.8936e-01 (8.8442e-01)\tEntropy 2.2973e+00 (2.2964e+00)\n",
            "Epoch: [38][ 50/390]\tTotal Loss -1.0611e+01 (-1.0589e+01)\tConsistency Loss 8.5971e-01 (8.9129e-01)\tEntropy 2.2942e+00 (2.2961e+00)\n",
            "Epoch: [38][ 75/390]\tTotal Loss -1.0527e+01 (-1.0575e+01)\tConsistency Loss 9.6984e-01 (9.0512e-01)\tEntropy 2.2993e+00 (2.2960e+00)\n",
            "Epoch: [38][100/390]\tTotal Loss -1.0645e+01 (-1.0573e+01)\tConsistency Loss 8.2330e-01 (9.0781e-01)\tEntropy 2.2936e+00 (2.2962e+00)\n",
            "Epoch: [38][125/390]\tTotal Loss -1.0712e+01 (-1.0580e+01)\tConsistency Loss 7.6007e-01 (9.0260e-01)\tEntropy 2.2944e+00 (2.2965e+00)\n",
            "Epoch: [38][150/390]\tTotal Loss -1.0553e+01 (-1.0580e+01)\tConsistency Loss 9.1715e-01 (9.0120e-01)\tEntropy 2.2941e+00 (2.2963e+00)\n",
            "Epoch: [38][175/390]\tTotal Loss -1.0480e+01 (-1.0579e+01)\tConsistency Loss 1.0242e+00 (9.0326e-01)\tEntropy 2.3008e+00 (2.2965e+00)\n",
            "Epoch: [38][200/390]\tTotal Loss -1.0573e+01 (-1.0577e+01)\tConsistency Loss 8.9032e-01 (9.0556e-01)\tEntropy 2.2928e+00 (2.2965e+00)\n",
            "Epoch: [38][225/390]\tTotal Loss -1.0634e+01 (-1.0578e+01)\tConsistency Loss 8.5736e-01 (9.0476e-01)\tEntropy 2.2982e+00 (2.2965e+00)\n",
            "Epoch: [38][250/390]\tTotal Loss -1.0651e+01 (-1.0580e+01)\tConsistency Loss 8.4641e-01 (9.0343e-01)\tEntropy 2.2995e+00 (2.2967e+00)\n",
            "Epoch: [38][275/390]\tTotal Loss -1.0597e+01 (-1.0580e+01)\tConsistency Loss 8.8393e-01 (9.0423e-01)\tEntropy 2.2962e+00 (2.2968e+00)\n",
            "Epoch: [38][300/390]\tTotal Loss -1.0639e+01 (-1.0581e+01)\tConsistency Loss 8.5698e-01 (9.0342e-01)\tEntropy 2.2992e+00 (2.2968e+00)\n",
            "Epoch: [38][325/390]\tTotal Loss -1.0461e+01 (-1.0584e+01)\tConsistency Loss 1.0249e+00 (9.0020e-01)\tEntropy 2.2971e+00 (2.2969e+00)\n",
            "Epoch: [38][350/390]\tTotal Loss -1.0669e+01 (-1.0583e+01)\tConsistency Loss 8.0059e-01 (9.0112e-01)\tEntropy 2.2940e+00 (2.2969e+00)\n",
            "Epoch: [38][375/390]\tTotal Loss -1.0552e+01 (-1.0583e+01)\tConsistency Loss 9.3555e-01 (9.0137e-01)\tEntropy 2.2975e+00 (2.2969e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.2998006343841553, 'consistency': 0.6704843044281006, 'total_loss': -1.6293163299560547}], 'lowest_loss_head': 0, 'lowest_loss': -1.6293163299560547}\n",
            "New lowest loss on validation set: -1.6293 -> -1.6293\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6273, 'ARI': 0.4446561270102966, 'NMI': 0.5270079355804059, 'ACC Top-5': 0.9306, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 2), (4, 3), (5, 8), (6, 7), (7, 4), (8, 0), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 40/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [39][  0/390]\tTotal Loss -1.0592e+01 (-1.0592e+01)\tConsistency Loss 9.0692e-01 (9.0692e-01)\tEntropy 2.2997e+00 (2.2997e+00)\n",
            "Epoch: [39][ 25/390]\tTotal Loss -1.0633e+01 (-1.0589e+01)\tConsistency Loss 8.5030e-01 (8.9980e-01)\tEntropy 2.2966e+00 (2.2977e+00)\n",
            "Epoch: [39][ 50/390]\tTotal Loss -1.0578e+01 (-1.0588e+01)\tConsistency Loss 8.9086e-01 (8.9837e-01)\tEntropy 2.2937e+00 (2.2973e+00)\n",
            "Epoch: [39][ 75/390]\tTotal Loss -1.0636e+01 (-1.0594e+01)\tConsistency Loss 8.3685e-01 (8.9206e-01)\tEntropy 2.2947e+00 (2.2971e+00)\n",
            "Epoch: [39][100/390]\tTotal Loss -1.0646e+01 (-1.0597e+01)\tConsistency Loss 8.4337e-01 (8.8906e-01)\tEntropy 2.2978e+00 (2.2972e+00)\n",
            "Epoch: [39][125/390]\tTotal Loss -1.0716e+01 (-1.0593e+01)\tConsistency Loss 7.8204e-01 (8.9252e-01)\tEntropy 2.2996e+00 (2.2970e+00)\n",
            "Epoch: [39][150/390]\tTotal Loss -1.0511e+01 (-1.0593e+01)\tConsistency Loss 9.8654e-01 (8.9174e-01)\tEntropy 2.2995e+00 (2.2970e+00)\n",
            "Epoch: [39][175/390]\tTotal Loss -1.0628e+01 (-1.0594e+01)\tConsistency Loss 8.5940e-01 (8.9006e-01)\tEntropy 2.2974e+00 (2.2968e+00)\n",
            "Epoch: [39][200/390]\tTotal Loss -1.0625e+01 (-1.0594e+01)\tConsistency Loss 8.6722e-01 (8.9001e-01)\tEntropy 2.2984e+00 (2.2968e+00)\n",
            "Epoch: [39][225/390]\tTotal Loss -1.0703e+01 (-1.0594e+01)\tConsistency Loss 7.8288e-01 (8.9053e-01)\tEntropy 2.2971e+00 (2.2969e+00)\n",
            "Epoch: [39][250/390]\tTotal Loss -1.0589e+01 (-1.0591e+01)\tConsistency Loss 8.8543e-01 (8.9293e-01)\tEntropy 2.2949e+00 (2.2969e+00)\n",
            "Epoch: [39][275/390]\tTotal Loss -1.0720e+01 (-1.0593e+01)\tConsistency Loss 7.8023e-01 (8.9162e-01)\tEntropy 2.3001e+00 (2.2969e+00)\n",
            "Epoch: [39][300/390]\tTotal Loss -1.0440e+01 (-1.0593e+01)\tConsistency Loss 1.0244e+00 (8.9191e-01)\tEntropy 2.2929e+00 (2.2969e+00)\n",
            "Epoch: [39][325/390]\tTotal Loss -1.0753e+01 (-1.0594e+01)\tConsistency Loss 7.4685e-01 (8.9073e-01)\tEntropy 2.3000e+00 (2.2969e+00)\n",
            "Epoch: [39][350/390]\tTotal Loss -1.0570e+01 (-1.0592e+01)\tConsistency Loss 9.2810e-01 (8.9273e-01)\tEntropy 2.2997e+00 (2.2970e+00)\n",
            "Epoch: [39][375/390]\tTotal Loss -1.0617e+01 (-1.0590e+01)\tConsistency Loss 8.8482e-01 (8.9525e-01)\tEntropy 2.3003e+00 (2.2970e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.3007922172546387, 'consistency': 0.6809602975845337, 'total_loss': -1.619831919670105}], 'lowest_loss_head': 0, 'lowest_loss': -1.619831919670105}\n",
            "No new lowest loss on validation set: -1.6293 -> -1.6198\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6202, 'ARI': 0.4293600590705556, 'NMI': 0.5174359568732962, 'ACC Top-5': 0.9364, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 2), (4, 3), (5, 8), (6, 7), (7, 4), (8, 0), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 41/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [40][  0/390]\tTotal Loss -1.0615e+01 (-1.0615e+01)\tConsistency Loss 8.7101e-01 (8.7101e-01)\tEntropy 2.2972e+00 (2.2972e+00)\n",
            "Epoch: [40][ 25/390]\tTotal Loss -1.0730e+01 (-1.0588e+01)\tConsistency Loss 7.6687e-01 (8.9503e-01)\tEntropy 2.2994e+00 (2.2967e+00)\n",
            "Epoch: [40][ 50/390]\tTotal Loss -1.0676e+01 (-1.0608e+01)\tConsistency Loss 8.2231e-01 (8.7592e-01)\tEntropy 2.2996e+00 (2.2967e+00)\n",
            "Epoch: [40][ 75/390]\tTotal Loss -1.0557e+01 (-1.0595e+01)\tConsistency Loss 9.0537e-01 (8.8813e-01)\tEntropy 2.2926e+00 (2.2967e+00)\n",
            "Epoch: [40][100/390]\tTotal Loss -1.0534e+01 (-1.0606e+01)\tConsistency Loss 9.3656e-01 (8.7811e-01)\tEntropy 2.2942e+00 (2.2967e+00)\n",
            "Epoch: [40][125/390]\tTotal Loss -1.0637e+01 (-1.0597e+01)\tConsistency Loss 8.4944e-01 (8.8748e-01)\tEntropy 2.2973e+00 (2.2969e+00)\n",
            "Epoch: [40][150/390]\tTotal Loss -1.0628e+01 (-1.0598e+01)\tConsistency Loss 8.6008e-01 (8.8723e-01)\tEntropy 2.2976e+00 (2.2970e+00)\n",
            "Epoch: [40][175/390]\tTotal Loss -1.0483e+01 (-1.0591e+01)\tConsistency Loss 9.8967e-01 (8.9426e-01)\tEntropy 2.2946e+00 (2.2971e+00)\n",
            "Epoch: [40][200/390]\tTotal Loss -1.0458e+01 (-1.0589e+01)\tConsistency Loss 1.0288e+00 (8.9670e-01)\tEntropy 2.2974e+00 (2.2970e+00)\n",
            "Epoch: [40][225/390]\tTotal Loss -1.0465e+01 (-1.0589e+01)\tConsistency Loss 1.0232e+00 (8.9592e-01)\tEntropy 2.2977e+00 (2.2970e+00)\n",
            "Epoch: [40][250/390]\tTotal Loss -1.0497e+01 (-1.0589e+01)\tConsistency Loss 1.0095e+00 (8.9571e-01)\tEntropy 2.3013e+00 (2.2970e+00)\n",
            "Epoch: [40][275/390]\tTotal Loss -1.0560e+01 (-1.0589e+01)\tConsistency Loss 9.2934e-01 (8.9670e-01)\tEntropy 2.2979e+00 (2.2971e+00)\n",
            "Epoch: [40][300/390]\tTotal Loss -1.0583e+01 (-1.0588e+01)\tConsistency Loss 8.9394e-01 (8.9753e-01)\tEntropy 2.2953e+00 (2.2970e+00)\n",
            "Epoch: [40][325/390]\tTotal Loss -1.0567e+01 (-1.0586e+01)\tConsistency Loss 9.0267e-01 (8.9951e-01)\tEntropy 2.2940e+00 (2.2970e+00)\n",
            "Epoch: [40][350/390]\tTotal Loss -1.0597e+01 (-1.0586e+01)\tConsistency Loss 8.9203e-01 (8.9942e-01)\tEntropy 2.2978e+00 (2.2970e+00)\n",
            "Epoch: [40][375/390]\tTotal Loss -1.0715e+01 (-1.0586e+01)\tConsistency Loss 7.6547e-01 (8.9961e-01)\tEntropy 2.2962e+00 (2.2971e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.29988169670105, 'consistency': 0.6733710169792175, 'total_loss': -1.6265106797218323}], 'lowest_loss_head': 0, 'lowest_loss': -1.6265106797218323}\n",
            "No new lowest loss on validation set: -1.6293 -> -1.6265\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6218, 'ARI': 0.4339685173796407, 'NMI': 0.5219722992411332, 'ACC Top-5': 0.9144, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 42/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [41][  0/390]\tTotal Loss -1.0616e+01 (-1.0616e+01)\tConsistency Loss 8.7268e-01 (8.7268e-01)\tEntropy 2.2977e+00 (2.2977e+00)\n",
            "Epoch: [41][ 25/390]\tTotal Loss -1.0673e+01 (-1.0615e+01)\tConsistency Loss 8.0911e-01 (8.6567e-01)\tEntropy 2.2965e+00 (2.2961e+00)\n",
            "Epoch: [41][ 50/390]\tTotal Loss -1.0508e+01 (-1.0586e+01)\tConsistency Loss 9.6776e-01 (8.9475e-01)\tEntropy 2.2952e+00 (2.2962e+00)\n",
            "Epoch: [41][ 75/390]\tTotal Loss -1.0522e+01 (-1.0578e+01)\tConsistency Loss 9.7425e-01 (9.0485e-01)\tEntropy 2.2992e+00 (2.2966e+00)\n",
            "Epoch: [41][100/390]\tTotal Loss -1.0674e+01 (-1.0594e+01)\tConsistency Loss 8.2317e-01 (8.9153e-01)\tEntropy 2.2995e+00 (2.2970e+00)\n",
            "Epoch: [41][125/390]\tTotal Loss -1.0723e+01 (-1.0592e+01)\tConsistency Loss 7.6115e-01 (8.9301e-01)\tEntropy 2.2969e+00 (2.2971e+00)\n",
            "Epoch: [41][150/390]\tTotal Loss -1.0571e+01 (-1.0595e+01)\tConsistency Loss 8.9387e-01 (8.9107e-01)\tEntropy 2.2930e+00 (2.2971e+00)\n",
            "Epoch: [41][175/390]\tTotal Loss -1.0562e+01 (-1.0597e+01)\tConsistency Loss 9.1040e-01 (8.8831e-01)\tEntropy 2.2945e+00 (2.2970e+00)\n",
            "Epoch: [41][200/390]\tTotal Loss -1.0669e+01 (-1.0599e+01)\tConsistency Loss 8.2453e-01 (8.8623e-01)\tEntropy 2.2987e+00 (2.2971e+00)\n",
            "Epoch: [41][225/390]\tTotal Loss -1.0539e+01 (-1.0599e+01)\tConsistency Loss 9.5036e-01 (8.8532e-01)\tEntropy 2.2979e+00 (2.2970e+00)\n",
            "Epoch: [41][250/390]\tTotal Loss -1.0439e+01 (-1.0596e+01)\tConsistency Loss 1.0388e+00 (8.8860e-01)\tEntropy 2.2955e+00 (2.2969e+00)\n",
            "Epoch: [41][275/390]\tTotal Loss -1.0629e+01 (-1.0593e+01)\tConsistency Loss 8.5681e-01 (8.9164e-01)\tEntropy 2.2971e+00 (2.2969e+00)\n",
            "Epoch: [41][300/390]\tTotal Loss -1.0619e+01 (-1.0588e+01)\tConsistency Loss 8.4876e-01 (8.9575e-01)\tEntropy 2.2935e+00 (2.2968e+00)\n",
            "Epoch: [41][325/390]\tTotal Loss -1.0636e+01 (-1.0586e+01)\tConsistency Loss 8.5262e-01 (8.9740e-01)\tEntropy 2.2976e+00 (2.2968e+00)\n",
            "Epoch: [41][350/390]\tTotal Loss -1.0507e+01 (-1.0586e+01)\tConsistency Loss 9.8748e-01 (8.9852e-01)\tEntropy 2.2988e+00 (2.2968e+00)\n",
            "Epoch: [41][375/390]\tTotal Loss -1.0642e+01 (-1.0586e+01)\tConsistency Loss 8.4510e-01 (8.9859e-01)\tEntropy 2.2975e+00 (2.2968e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.3003273010253906, 'consistency': 0.670835018157959, 'total_loss': -1.6294922828674316}], 'lowest_loss_head': 0, 'lowest_loss': -1.6294922828674316}\n",
            "New lowest loss on validation set: -1.6293 -> -1.6295\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6246, 'ARI': 0.43768487203405143, 'NMI': 0.5259993523460623, 'ACC Top-5': 0.912, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 43/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [42][  0/390]\tTotal Loss -1.0549e+01 (-1.0549e+01)\tConsistency Loss 9.2556e-01 (9.2556e-01)\tEntropy 2.2949e+00 (2.2949e+00)\n",
            "Epoch: [42][ 25/390]\tTotal Loss -1.0415e+01 (-1.0611e+01)\tConsistency Loss 1.0614e+00 (8.7524e-01)\tEntropy 2.2952e+00 (2.2973e+00)\n",
            "Epoch: [42][ 50/390]\tTotal Loss -1.0504e+01 (-1.0592e+01)\tConsistency Loss 9.7430e-01 (8.9662e-01)\tEntropy 2.2956e+00 (2.2977e+00)\n",
            "Epoch: [42][ 75/390]\tTotal Loss -1.0636e+01 (-1.0590e+01)\tConsistency Loss 8.5511e-01 (8.9737e-01)\tEntropy 2.2981e+00 (2.2975e+00)\n",
            "Epoch: [42][100/390]\tTotal Loss -1.0617e+01 (-1.0598e+01)\tConsistency Loss 8.8874e-01 (8.8984e-01)\tEntropy 2.3012e+00 (2.2975e+00)\n",
            "Epoch: [42][125/390]\tTotal Loss -1.0667e+01 (-1.0597e+01)\tConsistency Loss 8.3291e-01 (8.8884e-01)\tEntropy 2.3001e+00 (2.2972e+00)\n",
            "Epoch: [42][150/390]\tTotal Loss -1.0662e+01 (-1.0602e+01)\tConsistency Loss 8.3173e-01 (8.8467e-01)\tEntropy 2.2987e+00 (2.2973e+00)\n",
            "Epoch: [42][175/390]\tTotal Loss -1.0606e+01 (-1.0601e+01)\tConsistency Loss 8.8041e-01 (8.8517e-01)\tEntropy 2.2973e+00 (2.2973e+00)\n",
            "Epoch: [42][200/390]\tTotal Loss -1.0583e+01 (-1.0598e+01)\tConsistency Loss 8.9738e-01 (8.8692e-01)\tEntropy 2.2961e+00 (2.2971e+00)\n",
            "Epoch: [42][225/390]\tTotal Loss -1.0594e+01 (-1.0602e+01)\tConsistency Loss 8.8078e-01 (8.8368e-01)\tEntropy 2.2950e+00 (2.2971e+00)\n",
            "Epoch: [42][250/390]\tTotal Loss -1.0787e+01 (-1.0601e+01)\tConsistency Loss 7.0090e-01 (8.8448e-01)\tEntropy 2.2975e+00 (2.2971e+00)\n",
            "Epoch: [42][275/390]\tTotal Loss -1.0622e+01 (-1.0602e+01)\tConsistency Loss 8.6491e-01 (8.8409e-01)\tEntropy 2.2974e+00 (2.2971e+00)\n",
            "Epoch: [42][300/390]\tTotal Loss -1.0695e+01 (-1.0601e+01)\tConsistency Loss 8.0236e-01 (8.8438e-01)\tEntropy 2.2994e+00 (2.2972e+00)\n",
            "Epoch: [42][325/390]\tTotal Loss -1.0602e+01 (-1.0602e+01)\tConsistency Loss 8.8540e-01 (8.8321e-01)\tEntropy 2.2974e+00 (2.2970e+00)\n",
            "Epoch: [42][350/390]\tTotal Loss -1.0698e+01 (-1.0603e+01)\tConsistency Loss 7.7574e-01 (8.8224e-01)\tEntropy 2.2947e+00 (2.2970e+00)\n",
            "Epoch: [42][375/390]\tTotal Loss -1.0664e+01 (-1.0603e+01)\tConsistency Loss 8.3935e-01 (8.8263e-01)\tEntropy 2.3006e+00 (2.2970e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.2980332374572754, 'consistency': 0.6828580498695374, 'total_loss': -1.615175187587738}], 'lowest_loss_head': 0, 'lowest_loss': -1.615175187587738}\n",
            "No new lowest loss on validation set: -1.6295 -> -1.6152\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6236, 'ARI': 0.43520386524240473, 'NMI': 0.5217150903071098, 'ACC Top-5': 0.904, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 44/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [43][  0/390]\tTotal Loss -1.0567e+01 (-1.0567e+01)\tConsistency Loss 9.2015e-01 (9.2015e-01)\tEntropy 2.2974e+00 (2.2974e+00)\n",
            "Epoch: [43][ 25/390]\tTotal Loss -1.0444e+01 (-1.0551e+01)\tConsistency Loss 1.0532e+00 (9.3538e-01)\tEntropy 2.2995e+00 (2.2973e+00)\n",
            "Epoch: [43][ 50/390]\tTotal Loss -1.0580e+01 (-1.0558e+01)\tConsistency Loss 8.9418e-01 (9.2759e-01)\tEntropy 2.2949e+00 (2.2971e+00)\n",
            "Epoch: [43][ 75/390]\tTotal Loss -1.0638e+01 (-1.0552e+01)\tConsistency Loss 8.6616e-01 (9.3342e-01)\tEntropy 2.3009e+00 (2.2971e+00)\n",
            "Epoch: [43][100/390]\tTotal Loss -1.0606e+01 (-1.0561e+01)\tConsistency Loss 8.8769e-01 (9.2467e-01)\tEntropy 2.2987e+00 (2.2972e+00)\n",
            "Epoch: [43][125/390]\tTotal Loss -1.0649e+01 (-1.0571e+01)\tConsistency Loss 8.4178e-01 (9.1611e-01)\tEntropy 2.2981e+00 (2.2973e+00)\n",
            "Epoch: [43][150/390]\tTotal Loss -1.0596e+01 (-1.0572e+01)\tConsistency Loss 8.8321e-01 (9.1458e-01)\tEntropy 2.2958e+00 (2.2973e+00)\n",
            "Epoch: [43][175/390]\tTotal Loss -1.0452e+01 (-1.0576e+01)\tConsistency Loss 1.0218e+00 (9.1020e-01)\tEntropy 2.2947e+00 (2.2973e+00)\n",
            "Epoch: [43][200/390]\tTotal Loss -1.0588e+01 (-1.0580e+01)\tConsistency Loss 8.7462e-01 (9.0628e-01)\tEntropy 2.2925e+00 (2.2972e+00)\n",
            "Epoch: [43][225/390]\tTotal Loss -1.0576e+01 (-1.0581e+01)\tConsistency Loss 9.2535e-01 (9.0583e-01)\tEntropy 2.3003e+00 (2.2973e+00)\n",
            "Epoch: [43][250/390]\tTotal Loss -1.0551e+01 (-1.0582e+01)\tConsistency Loss 9.1744e-01 (9.0465e-01)\tEntropy 2.2936e+00 (2.2972e+00)\n",
            "Epoch: [43][275/390]\tTotal Loss -1.0646e+01 (-1.0583e+01)\tConsistency Loss 8.4521e-01 (9.0256e-01)\tEntropy 2.2982e+00 (2.2972e+00)\n",
            "Epoch: [43][300/390]\tTotal Loss -1.0635e+01 (-1.0586e+01)\tConsistency Loss 8.4990e-01 (8.9989e-01)\tEntropy 2.2969e+00 (2.2971e+00)\n",
            "Epoch: [43][325/390]\tTotal Loss -1.0693e+01 (-1.0585e+01)\tConsistency Loss 7.9655e-01 (9.0048e-01)\tEntropy 2.2978e+00 (2.2971e+00)\n",
            "Epoch: [43][350/390]\tTotal Loss -1.0493e+01 (-1.0585e+01)\tConsistency Loss 9.7417e-01 (9.0063e-01)\tEntropy 2.2935e+00 (2.2971e+00)\n",
            "Epoch: [43][375/390]\tTotal Loss -1.0614e+01 (-1.0585e+01)\tConsistency Loss 8.8391e-01 (9.0031e-01)\tEntropy 2.2996e+00 (2.2971e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.3012642860412598, 'consistency': 0.6711757183074951, 'total_loss': -1.6300885677337646}], 'lowest_loss_head': 0, 'lowest_loss': -1.6300885677337646}\n",
            "New lowest loss on validation set: -1.6295 -> -1.6301\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6183, 'ARI': 0.43035071938817265, 'NMI': 0.5174425249999814, 'ACC Top-5': 0.9311, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 2), (4, 3), (5, 8), (6, 7), (7, 4), (8, 0), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 45/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [44][  0/390]\tTotal Loss -1.0617e+01 (-1.0617e+01)\tConsistency Loss 8.7110e-01 (8.7110e-01)\tEntropy 2.2975e+00 (2.2975e+00)\n",
            "Epoch: [44][ 25/390]\tTotal Loss -1.0634e+01 (-1.0631e+01)\tConsistency Loss 8.6658e-01 (8.5243e-01)\tEntropy 2.3001e+00 (2.2967e+00)\n",
            "Epoch: [44][ 50/390]\tTotal Loss -1.0623e+01 (-1.0618e+01)\tConsistency Loss 8.6749e-01 (8.6570e-01)\tEntropy 2.2982e+00 (2.2967e+00)\n",
            "Epoch: [44][ 75/390]\tTotal Loss -1.0645e+01 (-1.0617e+01)\tConsistency Loss 8.5236e-01 (8.6763e-01)\tEntropy 2.2994e+00 (2.2969e+00)\n",
            "Epoch: [44][100/390]\tTotal Loss -1.0624e+01 (-1.0617e+01)\tConsistency Loss 8.7818e-01 (8.6808e-01)\tEntropy 2.3005e+00 (2.2970e+00)\n",
            "Epoch: [44][125/390]\tTotal Loss -1.0530e+01 (-1.0611e+01)\tConsistency Loss 9.7375e-01 (8.7281e-01)\tEntropy 2.3008e+00 (2.2967e+00)\n",
            "Epoch: [44][150/390]\tTotal Loss -1.0577e+01 (-1.0606e+01)\tConsistency Loss 9.0077e-01 (8.7749e-01)\tEntropy 2.2956e+00 (2.2968e+00)\n",
            "Epoch: [44][175/390]\tTotal Loss -1.0717e+01 (-1.0605e+01)\tConsistency Loss 7.4983e-01 (8.7899e-01)\tEntropy 2.2934e+00 (2.2967e+00)\n",
            "Epoch: [44][200/390]\tTotal Loss -1.0749e+01 (-1.0602e+01)\tConsistency Loss 7.3050e-01 (8.8110e-01)\tEntropy 2.2959e+00 (2.2967e+00)\n",
            "Epoch: [44][225/390]\tTotal Loss -1.0462e+01 (-1.0600e+01)\tConsistency Loss 1.0157e+00 (8.8366e-01)\tEntropy 2.2954e+00 (2.2967e+00)\n",
            "Epoch: [44][250/390]\tTotal Loss -1.0556e+01 (-1.0601e+01)\tConsistency Loss 9.3063e-01 (8.8327e-01)\tEntropy 2.2972e+00 (2.2968e+00)\n",
            "Epoch: [44][275/390]\tTotal Loss -1.0653e+01 (-1.0600e+01)\tConsistency Loss 8.1850e-01 (8.8436e-01)\tEntropy 2.2943e+00 (2.2968e+00)\n",
            "Epoch: [44][300/390]\tTotal Loss -1.0472e+01 (-1.0597e+01)\tConsistency Loss 1.0139e+00 (8.8720e-01)\tEntropy 2.2972e+00 (2.2968e+00)\n",
            "Epoch: [44][325/390]\tTotal Loss -1.0462e+01 (-1.0597e+01)\tConsistency Loss 1.0360e+00 (8.8757e-01)\tEntropy 2.2995e+00 (2.2968e+00)\n",
            "Epoch: [44][350/390]\tTotal Loss -1.0671e+01 (-1.0597e+01)\tConsistency Loss 8.3258e-01 (8.8730e-01)\tEntropy 2.3007e+00 (2.2969e+00)\n",
            "Epoch: [44][375/390]\tTotal Loss -1.0501e+01 (-1.0597e+01)\tConsistency Loss 9.8701e-01 (8.8662e-01)\tEntropy 2.2976e+00 (2.2968e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.302002429962158, 'consistency': 0.6740116477012634, 'total_loss': -1.6279907822608948}], 'lowest_loss_head': 0, 'lowest_loss': -1.6279907822608948}\n",
            "No new lowest loss on validation set: -1.6301 -> -1.6280\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6253, 'ARI': 0.4383478171252244, 'NMI': 0.526691052194593, 'ACC Top-5': 0.9147, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 46/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [45][  0/390]\tTotal Loss -1.0528e+01 (-1.0528e+01)\tConsistency Loss 9.5287e-01 (9.5287e-01)\tEntropy 2.2961e+00 (2.2961e+00)\n",
            "Epoch: [45][ 25/390]\tTotal Loss -1.0548e+01 (-1.0573e+01)\tConsistency Loss 9.3850e-01 (9.1183e-01)\tEntropy 2.2973e+00 (2.2970e+00)\n",
            "Epoch: [45][ 50/390]\tTotal Loss -1.0592e+01 (-1.0577e+01)\tConsistency Loss 8.9688e-01 (9.0817e-01)\tEntropy 2.2979e+00 (2.2970e+00)\n",
            "Epoch: [45][ 75/390]\tTotal Loss -1.0493e+01 (-1.0582e+01)\tConsistency Loss 9.9982e-01 (9.0430e-01)\tEntropy 2.2985e+00 (2.2972e+00)\n",
            "Epoch: [45][100/390]\tTotal Loss -1.0543e+01 (-1.0580e+01)\tConsistency Loss 9.4326e-01 (9.0554e-01)\tEntropy 2.2972e+00 (2.2971e+00)\n",
            "Epoch: [45][125/390]\tTotal Loss -1.0557e+01 (-1.0586e+01)\tConsistency Loss 9.2783e-01 (8.9988e-01)\tEntropy 2.2969e+00 (2.2971e+00)\n",
            "Epoch: [45][150/390]\tTotal Loss -1.0604e+01 (-1.0588e+01)\tConsistency Loss 8.7637e-01 (8.9733e-01)\tEntropy 2.2960e+00 (2.2971e+00)\n",
            "Epoch: [45][175/390]\tTotal Loss -1.0537e+01 (-1.0589e+01)\tConsistency Loss 9.6429e-01 (8.9648e-01)\tEntropy 2.3003e+00 (2.2971e+00)\n",
            "Epoch: [45][200/390]\tTotal Loss -1.0564e+01 (-1.0589e+01)\tConsistency Loss 9.3046e-01 (8.9635e-01)\tEntropy 2.2989e+00 (2.2972e+00)\n",
            "Epoch: [45][225/390]\tTotal Loss -1.0667e+01 (-1.0588e+01)\tConsistency Loss 8.3741e-01 (8.9722e-01)\tEntropy 2.3008e+00 (2.2971e+00)\n",
            "Epoch: [45][250/390]\tTotal Loss -1.0587e+01 (-1.0590e+01)\tConsistency Loss 9.0457e-01 (8.9555e-01)\tEntropy 2.2983e+00 (2.2970e+00)\n",
            "Epoch: [45][275/390]\tTotal Loss -1.0509e+01 (-1.0591e+01)\tConsistency Loss 9.8161e-01 (8.9415e-01)\tEntropy 2.2981e+00 (2.2971e+00)\n",
            "Epoch: [45][300/390]\tTotal Loss -1.0425e+01 (-1.0592e+01)\tConsistency Loss 1.0516e+00 (8.9361e-01)\tEntropy 2.2953e+00 (2.2971e+00)\n",
            "Epoch: [45][325/390]\tTotal Loss -1.0549e+01 (-1.0592e+01)\tConsistency Loss 9.3659e-01 (8.9404e-01)\tEntropy 2.2971e+00 (2.2972e+00)\n",
            "Epoch: [45][350/390]\tTotal Loss -1.0719e+01 (-1.0594e+01)\tConsistency Loss 7.6641e-01 (8.9156e-01)\tEntropy 2.2970e+00 (2.2971e+00)\n",
            "Epoch: [45][375/390]\tTotal Loss -1.0590e+01 (-1.0595e+01)\tConsistency Loss 9.0016e-01 (8.9074e-01)\tEntropy 2.2979e+00 (2.2971e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.2997794151306152, 'consistency': 0.6692359447479248, 'total_loss': -1.6305434703826904}], 'lowest_loss_head': 0, 'lowest_loss': -1.6305434703826904}\n",
            "New lowest loss on validation set: -1.6301 -> -1.6305\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6266, 'ARI': 0.427042348847978, 'NMI': 0.5176352118578724, 'ACC Top-5': 0.938, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 2), (4, 3), (5, 8), (6, 7), (7, 4), (8, 0), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 47/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [46][  0/390]\tTotal Loss -1.0517e+01 (-1.0517e+01)\tConsistency Loss 9.8688e-01 (9.8688e-01)\tEntropy 2.3007e+00 (2.3007e+00)\n",
            "Epoch: [46][ 25/390]\tTotal Loss -1.0637e+01 (-1.0604e+01)\tConsistency Loss 8.5566e-01 (8.8253e-01)\tEntropy 2.2986e+00 (2.2974e+00)\n",
            "Epoch: [46][ 50/390]\tTotal Loss -1.0482e+01 (-1.0597e+01)\tConsistency Loss 9.6455e-01 (8.8935e-01)\tEntropy 2.2893e+00 (2.2973e+00)\n",
            "Epoch: [46][ 75/390]\tTotal Loss -1.0581e+01 (-1.0591e+01)\tConsistency Loss 9.1463e-01 (8.9309e-01)\tEntropy 2.2992e+00 (2.2967e+00)\n",
            "Epoch: [46][100/390]\tTotal Loss -1.0531e+01 (-1.0585e+01)\tConsistency Loss 9.6785e-01 (8.9910e-01)\tEntropy 2.2997e+00 (2.2969e+00)\n",
            "Epoch: [46][125/390]\tTotal Loss -1.0616e+01 (-1.0591e+01)\tConsistency Loss 8.7757e-01 (8.9416e-01)\tEntropy 2.2988e+00 (2.2969e+00)\n",
            "Epoch: [46][150/390]\tTotal Loss -1.0554e+01 (-1.0585e+01)\tConsistency Loss 9.3133e-01 (8.9994e-01)\tEntropy 2.2970e+00 (2.2970e+00)\n",
            "Epoch: [46][175/390]\tTotal Loss -1.0703e+01 (-1.0591e+01)\tConsistency Loss 7.9597e-01 (8.9458e-01)\tEntropy 2.2998e+00 (2.2970e+00)\n",
            "Epoch: [46][200/390]\tTotal Loss -1.0697e+01 (-1.0593e+01)\tConsistency Loss 7.9766e-01 (8.9196e-01)\tEntropy 2.2990e+00 (2.2970e+00)\n",
            "Epoch: [46][225/390]\tTotal Loss -1.0663e+01 (-1.0594e+01)\tConsistency Loss 8.2828e-01 (8.9196e-01)\tEntropy 2.2983e+00 (2.2971e+00)\n",
            "Epoch: [46][250/390]\tTotal Loss -1.0662e+01 (-1.0595e+01)\tConsistency Loss 8.4192e-01 (8.9063e-01)\tEntropy 2.3009e+00 (2.2971e+00)\n",
            "Epoch: [46][275/390]\tTotal Loss -1.0668e+01 (-1.0594e+01)\tConsistency Loss 8.3150e-01 (8.9044e-01)\tEntropy 2.2999e+00 (2.2970e+00)\n",
            "Epoch: [46][300/390]\tTotal Loss -1.0520e+01 (-1.0594e+01)\tConsistency Loss 9.7688e-01 (8.9070e-01)\tEntropy 2.2993e+00 (2.2970e+00)\n",
            "Epoch: [46][325/390]\tTotal Loss -1.0684e+01 (-1.0594e+01)\tConsistency Loss 8.1200e-01 (8.9054e-01)\tEntropy 2.2992e+00 (2.2969e+00)\n",
            "Epoch: [46][350/390]\tTotal Loss -1.0607e+01 (-1.0595e+01)\tConsistency Loss 8.7973e-01 (8.8894e-01)\tEntropy 2.2974e+00 (2.2969e+00)\n",
            "Epoch: [46][375/390]\tTotal Loss -1.0630e+01 (-1.0597e+01)\tConsistency Loss 8.6831e-01 (8.8733e-01)\tEntropy 2.2997e+00 (2.2969e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.299652576446533, 'consistency': 0.673999547958374, 'total_loss': -1.6256530284881592}], 'lowest_loss_head': 0, 'lowest_loss': -1.6256530284881592}\n",
            "No new lowest loss on validation set: -1.6305 -> -1.6257\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6263, 'ARI': 0.4408539872420432, 'NMI': 0.5272606158443705, 'ACC Top-5': 0.9356, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 2), (4, 3), (5, 8), (6, 7), (7, 4), (8, 0), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 48/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [47][  0/390]\tTotal Loss -1.0543e+01 (-1.0543e+01)\tConsistency Loss 9.5127e-01 (9.5127e-01)\tEntropy 2.2989e+00 (2.2989e+00)\n",
            "Epoch: [47][ 25/390]\tTotal Loss -1.0648e+01 (-1.0601e+01)\tConsistency Loss 8.3419e-01 (8.8428e-01)\tEntropy 2.2964e+00 (2.2971e+00)\n",
            "Epoch: [47][ 50/390]\tTotal Loss -1.0678e+01 (-1.0608e+01)\tConsistency Loss 8.0601e-01 (8.7924e-01)\tEntropy 2.2968e+00 (2.2975e+00)\n",
            "Epoch: [47][ 75/390]\tTotal Loss -1.0557e+01 (-1.0603e+01)\tConsistency Loss 9.1917e-01 (8.8422e-01)\tEntropy 2.2952e+00 (2.2974e+00)\n",
            "Epoch: [47][100/390]\tTotal Loss -1.0678e+01 (-1.0606e+01)\tConsistency Loss 8.2506e-01 (8.7953e-01)\tEntropy 2.3006e+00 (2.2972e+00)\n",
            "Epoch: [47][125/390]\tTotal Loss -1.0639e+01 (-1.0607e+01)\tConsistency Loss 8.4655e-01 (8.7959e-01)\tEntropy 2.2971e+00 (2.2973e+00)\n",
            "Epoch: [47][150/390]\tTotal Loss -1.0403e+01 (-1.0606e+01)\tConsistency Loss 1.0735e+00 (8.8147e-01)\tEntropy 2.2953e+00 (2.2974e+00)\n",
            "Epoch: [47][175/390]\tTotal Loss -1.0322e+01 (-1.0603e+01)\tConsistency Loss 1.1482e+00 (8.8443e-01)\tEntropy 2.2941e+00 (2.2974e+00)\n",
            "Epoch: [47][200/390]\tTotal Loss -1.0606e+01 (-1.0603e+01)\tConsistency Loss 8.4102e-01 (8.8363e-01)\tEntropy 2.2894e+00 (2.2974e+00)\n",
            "Epoch: [47][225/390]\tTotal Loss -1.0580e+01 (-1.0600e+01)\tConsistency Loss 8.9676e-01 (8.8721e-01)\tEntropy 2.2954e+00 (2.2974e+00)\n",
            "Epoch: [47][250/390]\tTotal Loss -1.0746e+01 (-1.0599e+01)\tConsistency Loss 7.2905e-01 (8.8854e-01)\tEntropy 2.2951e+00 (2.2974e+00)\n",
            "Epoch: [47][275/390]\tTotal Loss -1.0617e+01 (-1.0599e+01)\tConsistency Loss 8.7091e-01 (8.8851e-01)\tEntropy 2.2975e+00 (2.2974e+00)\n",
            "Epoch: [47][300/390]\tTotal Loss -1.0512e+01 (-1.0598e+01)\tConsistency Loss 9.7939e-01 (8.8903e-01)\tEntropy 2.2983e+00 (2.2974e+00)\n",
            "Epoch: [47][325/390]\tTotal Loss -1.0578e+01 (-1.0599e+01)\tConsistency Loss 9.2784e-01 (8.8827e-01)\tEntropy 2.3011e+00 (2.2974e+00)\n",
            "Epoch: [47][350/390]\tTotal Loss -1.0571e+01 (-1.0599e+01)\tConsistency Loss 9.1269e-01 (8.8734e-01)\tEntropy 2.2968e+00 (2.2973e+00)\n",
            "Epoch: [47][375/390]\tTotal Loss -1.0651e+01 (-1.0599e+01)\tConsistency Loss 8.3157e-01 (8.8755e-01)\tEntropy 2.2965e+00 (2.2972e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.3013827800750732, 'consistency': 0.6743409037590027, 'total_loss': -1.6270418763160706}], 'lowest_loss_head': 0, 'lowest_loss': -1.6270418763160706}\n",
            "No new lowest loss on validation set: -1.6305 -> -1.6270\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6214, 'ARI': 0.4333917692228596, 'NMI': 0.5224632233448625, 'ACC Top-5': 0.9096, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 49/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [48][  0/390]\tTotal Loss -1.0684e+01 (-1.0684e+01)\tConsistency Loss 8.1921e-01 (8.1921e-01)\tEntropy 2.3006e+00 (2.3006e+00)\n",
            "Epoch: [48][ 25/390]\tTotal Loss -1.0543e+01 (-1.0610e+01)\tConsistency Loss 9.3337e-01 (8.7633e-01)\tEntropy 2.2953e+00 (2.2972e+00)\n",
            "Epoch: [48][ 50/390]\tTotal Loss -1.0554e+01 (-1.0599e+01)\tConsistency Loss 9.2458e-01 (8.8684e-01)\tEntropy 2.2956e+00 (2.2971e+00)\n",
            "Epoch: [48][ 75/390]\tTotal Loss -1.0589e+01 (-1.0596e+01)\tConsistency Loss 9.1043e-01 (8.9041e-01)\tEntropy 2.2998e+00 (2.2973e+00)\n",
            "Epoch: [48][100/390]\tTotal Loss -1.0516e+01 (-1.0588e+01)\tConsistency Loss 9.6977e-01 (8.9631e-01)\tEntropy 2.2972e+00 (2.2969e+00)\n",
            "Epoch: [48][125/390]\tTotal Loss -1.0486e+01 (-1.0590e+01)\tConsistency Loss 9.9313e-01 (8.9597e-01)\tEntropy 2.2958e+00 (2.2971e+00)\n",
            "Epoch: [48][150/390]\tTotal Loss -1.0574e+01 (-1.0592e+01)\tConsistency Loss 9.2139e-01 (8.9389e-01)\tEntropy 2.2991e+00 (2.2972e+00)\n",
            "Epoch: [48][175/390]\tTotal Loss -1.0559e+01 (-1.0593e+01)\tConsistency Loss 9.3904e-01 (8.9298e-01)\tEntropy 2.2996e+00 (2.2972e+00)\n",
            "Epoch: [48][200/390]\tTotal Loss -1.0536e+01 (-1.0593e+01)\tConsistency Loss 9.6302e-01 (8.9218e-01)\tEntropy 2.2997e+00 (2.2971e+00)\n",
            "Epoch: [48][225/390]\tTotal Loss -1.0696e+01 (-1.0593e+01)\tConsistency Loss 8.0158e-01 (8.9256e-01)\tEntropy 2.2994e+00 (2.2971e+00)\n",
            "Epoch: [48][250/390]\tTotal Loss -1.0699e+01 (-1.0589e+01)\tConsistency Loss 7.7357e-01 (8.9621e-01)\tEntropy 2.2946e+00 (2.2970e+00)\n",
            "Epoch: [48][275/390]\tTotal Loss -1.0698e+01 (-1.0592e+01)\tConsistency Loss 8.0445e-01 (8.9335e-01)\tEntropy 2.3004e+00 (2.2971e+00)\n",
            "Epoch: [48][300/390]\tTotal Loss -1.0691e+01 (-1.0595e+01)\tConsistency Loss 7.9809e-01 (8.9094e-01)\tEntropy 2.2978e+00 (2.2971e+00)\n",
            "Epoch: [48][325/390]\tTotal Loss -1.0541e+01 (-1.0593e+01)\tConsistency Loss 9.2009e-01 (8.9172e-01)\tEntropy 2.2922e+00 (2.2970e+00)\n",
            "Epoch: [48][350/390]\tTotal Loss -1.0576e+01 (-1.0591e+01)\tConsistency Loss 9.0983e-01 (8.9359e-01)\tEntropy 2.2971e+00 (2.2970e+00)\n",
            "Epoch: [48][375/390]\tTotal Loss -1.0604e+01 (-1.0592e+01)\tConsistency Loss 8.6515e-01 (8.9294e-01)\tEntropy 2.2939e+00 (2.2970e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.2984933853149414, 'consistency': 0.6765155792236328, 'total_loss': -1.6219778060913086}], 'lowest_loss_head': 0, 'lowest_loss': -1.6219778060913086}\n",
            "No new lowest loss on validation set: -1.6305 -> -1.6220\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6245, 'ARI': 0.4365623607019775, 'NMI': 0.5227201404057742, 'ACC Top-5': 0.9288, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 2), (4, 3), (5, 8), (6, 7), (7, 4), (8, 0), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 50/50\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [49][  0/390]\tTotal Loss -1.0497e+01 (-1.0497e+01)\tConsistency Loss 1.0040e+00 (1.0040e+00)\tEntropy 2.3002e+00 (2.3002e+00)\n",
            "Epoch: [49][ 25/390]\tTotal Loss -1.0618e+01 (-1.0627e+01)\tConsistency Loss 8.3802e-01 (8.6175e-01)\tEntropy 2.2912e+00 (2.2978e+00)\n",
            "Epoch: [49][ 50/390]\tTotal Loss -1.0613e+01 (-1.0616e+01)\tConsistency Loss 8.8576e-01 (8.7099e-01)\tEntropy 2.2997e+00 (2.2974e+00)\n",
            "Epoch: [49][ 75/390]\tTotal Loss -1.0499e+01 (-1.0612e+01)\tConsistency Loss 9.7276e-01 (8.7435e-01)\tEntropy 2.2944e+00 (2.2973e+00)\n",
            "Epoch: [49][100/390]\tTotal Loss -1.0694e+01 (-1.0617e+01)\tConsistency Loss 8.0002e-01 (8.7011e-01)\tEntropy 2.2987e+00 (2.2974e+00)\n",
            "Epoch: [49][125/390]\tTotal Loss -1.0702e+01 (-1.0611e+01)\tConsistency Loss 7.9297e-01 (8.7573e-01)\tEntropy 2.2989e+00 (2.2974e+00)\n",
            "Epoch: [49][150/390]\tTotal Loss -1.0545e+01 (-1.0606e+01)\tConsistency Loss 9.3847e-01 (8.8025e-01)\tEntropy 2.2966e+00 (2.2973e+00)\n",
            "Epoch: [49][175/390]\tTotal Loss -1.0461e+01 (-1.0604e+01)\tConsistency Loss 9.9887e-01 (8.8121e-01)\tEntropy 2.2919e+00 (2.2970e+00)\n",
            "Epoch: [49][200/390]\tTotal Loss -1.0537e+01 (-1.0603e+01)\tConsistency Loss 9.6281e-01 (8.8206e-01)\tEntropy 2.3000e+00 (2.2971e+00)\n",
            "Epoch: [49][225/390]\tTotal Loss -1.0407e+01 (-1.0602e+01)\tConsistency Loss 1.0817e+00 (8.8372e-01)\tEntropy 2.2978e+00 (2.2971e+00)\n",
            "Epoch: [49][250/390]\tTotal Loss -1.0429e+01 (-1.0600e+01)\tConsistency Loss 1.0543e+00 (8.8523e-01)\tEntropy 2.2967e+00 (2.2970e+00)\n",
            "Epoch: [49][275/390]\tTotal Loss -1.0550e+01 (-1.0599e+01)\tConsistency Loss 9.4602e-01 (8.8578e-01)\tEntropy 2.2992e+00 (2.2971e+00)\n",
            "Epoch: [49][300/390]\tTotal Loss -1.0593e+01 (-1.0600e+01)\tConsistency Loss 9.0755e-01 (8.8552e-01)\tEntropy 2.3001e+00 (2.2971e+00)\n",
            "Epoch: [49][325/390]\tTotal Loss -1.0846e+01 (-1.0600e+01)\tConsistency Loss 6.4953e-01 (8.8570e-01)\tEntropy 2.2990e+00 (2.2970e+00)\n",
            "Epoch: [49][350/390]\tTotal Loss -1.0782e+01 (-1.0601e+01)\tConsistency Loss 7.1542e-01 (8.8384e-01)\tEntropy 2.2996e+00 (2.2970e+00)\n",
            "Epoch: [49][375/390]\tTotal Loss -1.0561e+01 (-1.0600e+01)\tConsistency Loss 9.2589e-01 (8.8515e-01)\tEntropy 2.2975e+00 (2.2971e+00)\n",
            "Make prediction on validation set ...\n",
            "Evaluate based on SCAN loss ...\n",
            "{'scan': [{'entropy': 2.299288272857666, 'consistency': 0.6752289533615112, 'total_loss': -1.6240593194961548}], 'lowest_loss_head': 0, 'lowest_loss': -1.6240593194961548}\n",
            "No new lowest loss on validation set: -1.6305 -> -1.6241\n",
            "Lowest loss head is 0\n",
            "Evaluate with hungarian matching algorithm ...\n",
            "{'ACC': 0.6281, 'ARI': 0.43841656551374414, 'NMI': 0.5247787483516542, 'ACC Top-5': 0.9342, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 2), (4, 3), (5, 8), (6, 7), (7, 4), (8, 0), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[34mEvaluate best model based on SCAN metric at the end\u001b[0m\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "{'ACC': 0.6266, 'ARI': 0.427042348847978, 'NMI': 0.5176352118578724, 'ACC Top-5': 0.938, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 2), (4, 3), (5, 8), (6, 7), (7, 4), (8, 0), (9, 1)]}\n"
          ]
        }
      ],
      "source": [
        "!python/content/drive/MyDrive/EECS_6322/Final_Project/scan.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/EECS_6322/Final_Project/train_SLabeling.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoWQpI4wvRxh",
        "outputId": "f5b8e6d9-8840-4599-f425-26c979700ff2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m{'setup': 'selflabel', 'use_ema': False, 'confidence_threshold': 0.99, 'criterion': 'confidence-cross-entropy', 'criterion_kwargs': {'apply_class_balancing': True}, 'backbone': 'resnet18', 'num_heads': 1, 'train_db_name': 'cifar-10', 'val_db_name': 'cifar-10', 'num_classes': 10, 'augmentation_strategy': 'ours', 'augmentation_kwargs': {'crop_size': 32, 'normalize': {'mean': [0.4914, 0.4822, 0.4465], 'std': [0.2023, 0.1994, 0.201]}, 'num_strong_augs': 4, 'cutout_kwargs': {'n_holes': 1, 'length': 16, 'random': True}}, 'transformation_kwargs': {'crop_size': 32, 'normalize': {'mean': [0.4914, 0.4822, 0.4465], 'std': [0.2023, 0.1994, 0.201]}}, 'epochs': 50, 'optimizer': 'adam', 'optimizer_kwargs': {'lr': 0.0001, 'weight_decay': 0.0001}, 'batch_size': 1000, 'num_workers': 8, 'scheduler': 'constant', 'pretext_dir': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/pretext', 'pretext_checkpoint': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/pretext/checkpoint.pth.tar', 'pretext_model': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/pretext/model.pth.tar', 'topk_neighbors_train_path': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/pretext/topk-train-neighbors.npy', 'topk_neighbors_val_path': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/pretext/topk-val-neighbors.npy', 'scan_dir': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/scan', 'scan_checkpoint': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/scan/checkpoint.pth.tar', 'scan_model': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/scan/model.pth.tar', 'selflabel_dir': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/selflabel', 'selflabel_checkpoint': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/selflabel/checkpoint.pth.tar', 'selflabel_model': '/content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/selflabel/model.pth.tar'}\u001b[0m\n",
            "\u001b[34mRetrieve model\u001b[0m\n",
            "ClusteringModel(\n",
            "  (backbone): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  )\n",
            "  (cluster_head): ModuleList(\n",
            "    (0): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\u001b[34mGet loss\u001b[0m\n",
            "ConfidenceBasedCE(\n",
            "  (loss): MaskedCrossEntropyLoss()\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "\u001b[34mSet CuDNN benchmark\u001b[0m\n",
            "\u001b[34mRetrieve optimizer\u001b[0m\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0.0001\n",
            ")\n",
            "\u001b[34mRetrieve dataset\u001b[0m\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Files already downloaded and verified\n",
            "\u001b[33mTrain samples 50000 - Val samples 10000\u001b[0m\n",
            "\u001b[34mNo checkpoint file at /content/drive/MyDrive/EECS_6322/Unsupervised-Classification-master/results/cifar-10/selflabel/checkpoint.pth.tar\u001b[0m\n",
            "\u001b[34mStarting main loop\u001b[0m\n",
            "\u001b[33mEpoch 1/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "Epoch: [0][ 0/50]\tLoss 1.1684e-01 (1.1684e-01)\n",
            "Epoch: [0][25/50]\tLoss 3.4526e-02 (6.7602e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.625, 'ARI': 0.4374449872237295, 'NMI': 0.5286700562200973, 'ACC Top-5': 0.9201, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 2/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [1][ 0/50]\tLoss 7.8246e-02 (7.8246e-02)\n",
            "Epoch: [1][25/50]\tLoss 1.1821e-01 (8.5612e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6316, 'ARI': 0.4563144088325738, 'NMI': 0.5447861588095985, 'ACC Top-5': 0.9336, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 2), (4, 3), (5, 8), (6, 7), (7, 4), (8, 0), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 3/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [2][ 0/50]\tLoss 9.4338e-02 (9.4338e-02)\n",
            "Epoch: [2][25/50]\tLoss 1.1224e-01 (8.6285e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6358, 'ARI': 0.4666303438753995, 'NMI': 0.5551195877235864, 'ACC Top-5': 0.9463, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 4/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [3][ 0/50]\tLoss 1.1612e-01 (1.1612e-01)\n",
            "Epoch: [3][25/50]\tLoss 8.9247e-02 (8.4849e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.653, 'ARI': 0.4709558262333235, 'NMI': 0.5601350059272492, 'ACC Top-5': 0.9401, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 5/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [4][ 0/50]\tLoss 7.9267e-02 (7.9267e-02)\n",
            "Epoch: [4][25/50]\tLoss 9.7265e-02 (8.2722e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.66, 'ARI': 0.48131807349245626, 'NMI': 0.5669912846761863, 'ACC Top-5': 0.9418, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 6/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [5][ 0/50]\tLoss 7.8446e-02 (7.8446e-02)\n",
            "Epoch: [5][25/50]\tLoss 6.9740e-02 (1.0042e-01)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6645, 'ARI': 0.4856081082140106, 'NMI': 0.5675379952818688, 'ACC Top-5': 0.9486, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 7/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [6][ 0/50]\tLoss 8.4515e-02 (8.4515e-02)\n",
            "Epoch: [6][25/50]\tLoss 7.4992e-02 (9.1029e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6639, 'ARI': 0.48791743603765486, 'NMI': 0.5746680014726913, 'ACC Top-5': 0.9438, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 8/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [7][ 0/50]\tLoss 1.1291e-01 (1.1291e-01)\n",
            "Epoch: [7][25/50]\tLoss 7.0607e-02 (9.2859e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6684, 'ARI': 0.49363911931782756, 'NMI': 0.5742674471411586, 'ACC Top-5': 0.9468, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 9/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [8][ 0/50]\tLoss 1.2908e-01 (1.2908e-01)\n",
            "Epoch: [8][25/50]\tLoss 8.0203e-02 (9.4788e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6647, 'ARI': 0.4945308604645822, 'NMI': 0.5752762613348251, 'ACC Top-5': 0.9418, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 10/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [9][ 0/50]\tLoss 1.0538e-01 (1.0538e-01)\n",
            "Epoch: [9][25/50]\tLoss 9.4018e-02 (1.0220e-01)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6678, 'ARI': 0.49420124613334515, 'NMI': 0.5809081880912972, 'ACC Top-5': 0.9503, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 11/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [10][ 0/50]\tLoss 5.8168e-02 (5.8168e-02)\n",
            "Epoch: [10][25/50]\tLoss 1.2553e-01 (9.3235e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6613, 'ARI': 0.48659617844605546, 'NMI': 0.5765126294852756, 'ACC Top-5': 0.9456, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 12/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [11][ 0/50]\tLoss 8.4700e-02 (8.4700e-02)\n",
            "Epoch: [11][25/50]\tLoss 9.7670e-02 (9.7022e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.667, 'ARI': 0.49901733078241234, 'NMI': 0.5823234290110884, 'ACC Top-5': 0.9463, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 13/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [12][ 0/50]\tLoss 7.6017e-02 (7.6017e-02)\n",
            "Epoch: [12][25/50]\tLoss 7.9046e-02 (8.5369e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6677, 'ARI': 0.5033050218686764, 'NMI': 0.5834195902461182, 'ACC Top-5': 0.9373, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 14/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [13][ 0/50]\tLoss 8.6482e-02 (8.6482e-02)\n",
            "Epoch: [13][25/50]\tLoss 6.9104e-02 (9.2193e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6696, 'ARI': 0.5040804499498619, 'NMI': 0.586994559099774, 'ACC Top-5': 0.9409, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 15/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [14][ 0/50]\tLoss 9.9500e-02 (9.9500e-02)\n",
            "Epoch: [14][25/50]\tLoss 7.1936e-02 (9.4503e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6632, 'ARI': 0.49944298351061306, 'NMI': 0.5805147301410516, 'ACC Top-5': 0.9494, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 16/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [15][ 0/50]\tLoss 1.0894e-01 (1.0894e-01)\n",
            "Epoch: [15][25/50]\tLoss 8.1597e-02 (9.8096e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6692, 'ARI': 0.5025228672035926, 'NMI': 0.5871531003971986, 'ACC Top-5': 0.9565, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 17/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [16][ 0/50]\tLoss 7.5505e-02 (7.5505e-02)\n",
            "Epoch: [16][25/50]\tLoss 1.0551e-01 (8.9539e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6725, 'ARI': 0.5045522072780642, 'NMI': 0.5895602449753323, 'ACC Top-5': 0.9456, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 18/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [17][ 0/50]\tLoss 8.3650e-02 (8.3650e-02)\n",
            "Epoch: [17][25/50]\tLoss 8.9833e-02 (9.2033e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6763, 'ARI': 0.5108096392260275, 'NMI': 0.5945342435153343, 'ACC Top-5': 0.9469, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 19/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [18][ 0/50]\tLoss 8.5162e-02 (8.5162e-02)\n",
            "Epoch: [18][25/50]\tLoss 1.1328e-01 (9.4755e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6766, 'ARI': 0.5044189845609065, 'NMI': 0.591406365385495, 'ACC Top-5': 0.9464, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 20/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [19][ 0/50]\tLoss 8.2005e-02 (8.2005e-02)\n",
            "Epoch: [19][25/50]\tLoss 8.2031e-02 (9.4021e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.673, 'ARI': 0.5053144349290073, 'NMI': 0.5892901007493507, 'ACC Top-5': 0.9472, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 21/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [20][ 0/50]\tLoss 6.2845e-02 (6.2845e-02)\n",
            "Epoch: [20][25/50]\tLoss 1.1953e-01 (1.0623e-01)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6736, 'ARI': 0.5112430751399905, 'NMI': 0.5920221037142289, 'ACC Top-5': 0.9445, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 22/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [21][ 0/50]\tLoss 7.6861e-02 (7.6861e-02)\n",
            "Epoch: [21][25/50]\tLoss 1.1678e-01 (9.5339e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6742, 'ARI': 0.5106946889107932, 'NMI': 0.59269946877627, 'ACC Top-5': 0.9503, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 23/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [22][ 0/50]\tLoss 1.1196e-01 (1.1196e-01)\n",
            "Epoch: [22][25/50]\tLoss 9.2193e-02 (9.5772e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6752, 'ARI': 0.5140759410839406, 'NMI': 0.5947462428809231, 'ACC Top-5': 0.9373, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 8), (4, 3), (5, 0), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 24/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [23][ 0/50]\tLoss 7.9997e-02 (7.9997e-02)\n",
            "Epoch: [23][25/50]\tLoss 9.6550e-02 (9.8422e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6794, 'ARI': 0.5175000025420132, 'NMI': 0.5998377003599791, 'ACC Top-5': 0.9364, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 8), (4, 3), (5, 0), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 25/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [24][ 0/50]\tLoss 7.7169e-02 (7.7169e-02)\n",
            "Epoch: [24][25/50]\tLoss 1.2346e-01 (9.1251e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.681, 'ARI': 0.5170161885513401, 'NMI': 0.5978219675294184, 'ACC Top-5': 0.952, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 26/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [25][ 0/50]\tLoss 7.7568e-02 (7.7568e-02)\n",
            "Epoch: [25][25/50]\tLoss 6.0491e-02 (8.8545e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6803, 'ARI': 0.5123329275443756, 'NMI': 0.5957753760044436, 'ACC Top-5': 0.9464, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 8), (4, 3), (5, 0), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 27/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [26][ 0/50]\tLoss 1.0211e-01 (1.0211e-01)\n",
            "Epoch: [26][25/50]\tLoss 1.1198e-01 (9.7882e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6787, 'ARI': 0.5136916833916999, 'NMI': 0.598036081313851, 'ACC Top-5': 0.9513, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 28/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [27][ 0/50]\tLoss 8.4666e-02 (8.4666e-02)\n",
            "Epoch: [27][25/50]\tLoss 9.3544e-02 (9.7856e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6773, 'ARI': 0.5136604643092068, 'NMI': 0.5969142034305821, 'ACC Top-5': 0.9505, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 8), (4, 3), (5, 0), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 29/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [28][ 0/50]\tLoss 8.0490e-02 (8.0490e-02)\n",
            "Epoch: [28][25/50]\tLoss 9.4644e-02 (9.8128e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.683, 'ARI': 0.5192466957945231, 'NMI': 0.6015718431760042, 'ACC Top-5': 0.9412, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 30/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [29][ 0/50]\tLoss 8.9037e-02 (8.9037e-02)\n",
            "Epoch: [29][25/50]\tLoss 9.4782e-02 (9.9002e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6881, 'ARI': 0.5202215185291222, 'NMI': 0.6021936254611364, 'ACC Top-5': 0.9497, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 31/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [30][ 0/50]\tLoss 9.6341e-02 (9.6341e-02)\n",
            "Epoch: [30][25/50]\tLoss 9.1347e-02 (9.6005e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6906, 'ARI': 0.521917071049875, 'NMI': 0.6040754863502724, 'ACC Top-5': 0.9479, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 32/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [31][ 0/50]\tLoss 7.6197e-02 (7.6197e-02)\n",
            "Epoch: [31][25/50]\tLoss 1.3315e-01 (9.6807e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6869, 'ARI': 0.5217352357437337, 'NMI': 0.6080369608111426, 'ACC Top-5': 0.9575, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 33/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [32][ 0/50]\tLoss 9.8884e-02 (9.8884e-02)\n",
            "Epoch: [32][25/50]\tLoss 1.0436e-01 (9.7119e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6856, 'ARI': 0.5216847311464684, 'NMI': 0.6039209274995594, 'ACC Top-5': 0.9518, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 34/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [33][ 0/50]\tLoss 6.0666e-02 (6.0666e-02)\n",
            "Epoch: [33][25/50]\tLoss 1.2991e-01 (9.8950e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6867, 'ARI': 0.5244647989338233, 'NMI': 0.6075584151955788, 'ACC Top-5': 0.9556, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 35/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [34][ 0/50]\tLoss 9.0384e-02 (9.0384e-02)\n",
            "Epoch: [34][25/50]\tLoss 1.1830e-01 (1.0085e-01)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6857, 'ARI': 0.5249304062934742, 'NMI': 0.609722810815519, 'ACC Top-5': 0.9598, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 36/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [35][ 0/50]\tLoss 9.3096e-02 (9.3096e-02)\n",
            "Epoch: [35][25/50]\tLoss 1.0546e-01 (9.6654e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6817, 'ARI': 0.5192334611304104, 'NMI': 0.6052416716019863, 'ACC Top-5': 0.9538, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 8), (4, 3), (5, 0), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 37/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [36][ 0/50]\tLoss 7.4883e-02 (7.4883e-02)\n",
            "Epoch: [36][25/50]\tLoss 1.2471e-01 (9.2296e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6794, 'ARI': 0.513414142668065, 'NMI': 0.5959515158800324, 'ACC Top-5': 0.9543, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 38/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [37][ 0/50]\tLoss 1.4160e-01 (1.4160e-01)\n",
            "Epoch: [37][25/50]\tLoss 8.9631e-02 (1.0024e-01)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6845, 'ARI': 0.5144739360513862, 'NMI': 0.601330739604202, 'ACC Top-5': 0.9572, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 39/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [38][ 0/50]\tLoss 1.1333e-01 (1.1333e-01)\n",
            "Epoch: [38][25/50]\tLoss 9.2815e-02 (9.4320e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6826, 'ARI': 0.5208649963960891, 'NMI': 0.6092497047130515, 'ACC Top-5': 0.9559, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 40/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [39][ 0/50]\tLoss 1.3116e-01 (1.3116e-01)\n",
            "Epoch: [39][25/50]\tLoss 7.7930e-02 (9.3493e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6834, 'ARI': 0.519407843180152, 'NMI': 0.6026922767374734, 'ACC Top-5': 0.9588, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 41/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [40][ 0/50]\tLoss 8.6205e-02 (8.6205e-02)\n",
            "Epoch: [40][25/50]\tLoss 7.7855e-02 (1.0163e-01)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6866, 'ARI': 0.5235893692737734, 'NMI': 0.6095779226750555, 'ACC Top-5': 0.9483, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 42/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [41][ 0/50]\tLoss 9.4390e-02 (9.4390e-02)\n",
            "Epoch: [41][25/50]\tLoss 6.7418e-02 (9.4580e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6894, 'ARI': 0.5270477743577323, 'NMI': 0.610498425366761, 'ACC Top-5': 0.9455, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 8), (4, 3), (5, 0), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 43/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [42][ 0/50]\tLoss 5.4960e-02 (5.4960e-02)\n",
            "Epoch: [42][25/50]\tLoss 8.0398e-02 (9.1900e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6859, 'ARI': 0.5262914153006217, 'NMI': 0.6104795978358912, 'ACC Top-5': 0.9553, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 8), (4, 3), (5, 0), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 44/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [43][ 0/50]\tLoss 1.0293e-01 (1.0293e-01)\n",
            "Epoch: [43][25/50]\tLoss 9.2219e-02 (9.3081e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6912, 'ARI': 0.5261059695238425, 'NMI': 0.6058898006314313, 'ACC Top-5': 0.96, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 45/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [44][ 0/50]\tLoss 8.5862e-02 (8.5862e-02)\n",
            "Epoch: [44][25/50]\tLoss 7.7234e-02 (9.6903e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.7019, 'ARI': 0.5330968771699827, 'NMI': 0.6099150741229683, 'ACC Top-5': 0.9616, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 46/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [45][ 0/50]\tLoss 8.6988e-02 (8.6988e-02)\n",
            "Epoch: [45][25/50]\tLoss 1.1110e-01 (9.6158e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6873, 'ARI': 0.5194721744128019, 'NMI': 0.6046027530828603, 'ACC Top-5': 0.9544, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 47/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [46][ 0/50]\tLoss 8.1377e-02 (8.1377e-02)\n",
            "Epoch: [46][25/50]\tLoss 1.4588e-01 (9.9996e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6894, 'ARI': 0.5233575377211859, 'NMI': 0.6087522764611313, 'ACC Top-5': 0.9661, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 48/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [47][ 0/50]\tLoss 7.7029e-02 (7.7029e-02)\n",
            "Epoch: [47][25/50]\tLoss 1.1723e-01 (9.1764e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6964, 'ARI': 0.5341395427355363, 'NMI': 0.611833728425675, 'ACC Top-5': 0.9602, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 49/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [48][ 0/50]\tLoss 1.4452e-01 (1.4452e-01)\n",
            "Epoch: [48][25/50]\tLoss 8.7892e-02 (9.6673e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.681, 'ARI': 0.5223298568993117, 'NMI': 0.6082898282292976, 'ACC Top-5': 0.9542, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 8), (4, 3), (5, 0), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[33mEpoch 50/50\u001b[0m\n",
            "\u001b[33m----------\u001b[0m\n",
            "Adjusted learning rate to 0.00010\n",
            "Train ...\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: [49][ 0/50]\tLoss 9.5163e-02 (9.5163e-02)\n",
            "Epoch: [49][25/50]\tLoss 7.5876e-02 (9.8282e-02)\n",
            "Evaluate ...\n",
            "{'ACC': 0.6934, 'ARI': 0.5331771478030223, 'NMI': 0.6159733855498573, 'ACC Top-5': 0.9524, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n",
            "Checkpoint ...\n",
            "\u001b[34mEvaluate model at the end\u001b[0m\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "{'ACC': 0.6934, 'ARI': 0.5331771478030223, 'NMI': 0.6159733855498573, 'ACC Top-5': 0.9524, 'hungarian_match': [(0, 5), (1, 6), (2, 9), (3, 0), (4, 3), (5, 8), (6, 7), (7, 4), (8, 2), (9, 1)]}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}